// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: yarn_server_common_service_protos.proto

package org.apache.hadoop.yarn.proto;

public final class YarnServerCommonServiceProtos {
  private YarnServerCommonServiceProtos() {}
  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistry registry) {
  }
  public interface DistSchedRegisterResponseProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.RegisterApplicationMasterResponseProto register_response = 1;
    /**
     * <code>optional .hadoop.yarn.RegisterApplicationMasterResponseProto register_response = 1;</code>
     */
    boolean hasRegisterResponse();
    /**
     * <code>optional .hadoop.yarn.RegisterApplicationMasterResponseProto register_response = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto getRegisterResponse();
    /**
     * <code>optional .hadoop.yarn.RegisterApplicationMasterResponseProto register_response = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProtoOrBuilder getRegisterResponseOrBuilder();

    // optional .hadoop.yarn.ResourceProto max_alloc_capability = 2;
    /**
     * <code>optional .hadoop.yarn.ResourceProto max_alloc_capability = 2;</code>
     */
    boolean hasMaxAllocCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto max_alloc_capability = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getMaxAllocCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto max_alloc_capability = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getMaxAllocCapabilityOrBuilder();

    // optional .hadoop.yarn.ResourceProto min_alloc_capability = 3;
    /**
     * <code>optional .hadoop.yarn.ResourceProto min_alloc_capability = 3;</code>
     */
    boolean hasMinAllocCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto min_alloc_capability = 3;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getMinAllocCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto min_alloc_capability = 3;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getMinAllocCapabilityOrBuilder();

    // optional .hadoop.yarn.ResourceProto incr_alloc_capability = 4;
    /**
     * <code>optional .hadoop.yarn.ResourceProto incr_alloc_capability = 4;</code>
     */
    boolean hasIncrAllocCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto incr_alloc_capability = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getIncrAllocCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto incr_alloc_capability = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getIncrAllocCapabilityOrBuilder();

    // optional int32 container_token_expiry_interval = 5;
    /**
     * <code>optional int32 container_token_expiry_interval = 5;</code>
     */
    boolean hasContainerTokenExpiryInterval();
    /**
     * <code>optional int32 container_token_expiry_interval = 5;</code>
     */
    int getContainerTokenExpiryInterval();

    // optional int64 container_id_start = 6;
    /**
     * <code>optional int64 container_id_start = 6;</code>
     */
    boolean hasContainerIdStart();
    /**
     * <code>optional int64 container_id_start = 6;</code>
     */
    long getContainerIdStart();

    // repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 7;
    /**
     * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 7;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto> 
        getNodesForSchedulingList();
    /**
     * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 7;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodesForScheduling(int index);
    /**
     * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 7;</code>
     */
    int getNodesForSchedulingCount();
    /**
     * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 7;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> 
        getNodesForSchedulingOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 7;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodesForSchedulingOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.DistSchedRegisterResponseProto}
   */
  public static final class DistSchedRegisterResponseProto extends
      com.google.protobuf.GeneratedMessage
      implements DistSchedRegisterResponseProtoOrBuilder {
    // Use DistSchedRegisterResponseProto.newBuilder() to construct.
    private DistSchedRegisterResponseProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private DistSchedRegisterResponseProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final DistSchedRegisterResponseProto defaultInstance;
    public static DistSchedRegisterResponseProto getDefaultInstance() {
      return defaultInstance;
    }

    public DistSchedRegisterResponseProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private DistSchedRegisterResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = registerResponse_.toBuilder();
              }
              registerResponse_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(registerResponse_);
                registerResponse_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = maxAllocCapability_.toBuilder();
              }
              maxAllocCapability_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(maxAllocCapability_);
                maxAllocCapability_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = minAllocCapability_.toBuilder();
              }
              minAllocCapability_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(minAllocCapability_);
                minAllocCapability_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
            case 34: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000008) == 0x00000008)) {
                subBuilder = incrAllocCapability_.toBuilder();
              }
              incrAllocCapability_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(incrAllocCapability_);
                incrAllocCapability_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000008;
              break;
            }
            case 40: {
              bitField0_ |= 0x00000010;
              containerTokenExpiryInterval_ = input.readInt32();
              break;
            }
            case 48: {
              bitField0_ |= 0x00000020;
              containerIdStart_ = input.readInt64();
              break;
            }
            case 58: {
              if (!((mutable_bitField0_ & 0x00000040) == 0x00000040)) {
                nodesForScheduling_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto>();
                mutable_bitField0_ |= 0x00000040;
              }
              nodesForScheduling_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000040) == 0x00000040)) {
          nodesForScheduling_ = java.util.Collections.unmodifiableList(nodesForScheduling_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_DistSchedRegisterResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_DistSchedRegisterResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedRegisterResponseProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedRegisterResponseProto.Builder.class);
    }

    public static com.google.protobuf.Parser<DistSchedRegisterResponseProto> PARSER =
        new com.google.protobuf.AbstractParser<DistSchedRegisterResponseProto>() {
      public DistSchedRegisterResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new DistSchedRegisterResponseProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<DistSchedRegisterResponseProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.RegisterApplicationMasterResponseProto register_response = 1;
    public static final int REGISTER_RESPONSE_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto registerResponse_;
    /**
     * <code>optional .hadoop.yarn.RegisterApplicationMasterResponseProto register_response = 1;</code>
     */
    public boolean hasRegisterResponse() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.RegisterApplicationMasterResponseProto register_response = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto getRegisterResponse() {
      return registerResponse_;
    }
    /**
     * <code>optional .hadoop.yarn.RegisterApplicationMasterResponseProto register_response = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProtoOrBuilder getRegisterResponseOrBuilder() {
      return registerResponse_;
    }

    // optional .hadoop.yarn.ResourceProto max_alloc_capability = 2;
    public static final int MAX_ALLOC_CAPABILITY_FIELD_NUMBER = 2;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto maxAllocCapability_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto max_alloc_capability = 2;</code>
     */
    public boolean hasMaxAllocCapability() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto max_alloc_capability = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getMaxAllocCapability() {
      return maxAllocCapability_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto max_alloc_capability = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getMaxAllocCapabilityOrBuilder() {
      return maxAllocCapability_;
    }

    // optional .hadoop.yarn.ResourceProto min_alloc_capability = 3;
    public static final int MIN_ALLOC_CAPABILITY_FIELD_NUMBER = 3;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto minAllocCapability_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto min_alloc_capability = 3;</code>
     */
    public boolean hasMinAllocCapability() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto min_alloc_capability = 3;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getMinAllocCapability() {
      return minAllocCapability_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto min_alloc_capability = 3;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getMinAllocCapabilityOrBuilder() {
      return minAllocCapability_;
    }

    // optional .hadoop.yarn.ResourceProto incr_alloc_capability = 4;
    public static final int INCR_ALLOC_CAPABILITY_FIELD_NUMBER = 4;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto incrAllocCapability_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto incr_alloc_capability = 4;</code>
     */
    public boolean hasIncrAllocCapability() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto incr_alloc_capability = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getIncrAllocCapability() {
      return incrAllocCapability_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto incr_alloc_capability = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getIncrAllocCapabilityOrBuilder() {
      return incrAllocCapability_;
    }

    // optional int32 container_token_expiry_interval = 5;
    public static final int CONTAINER_TOKEN_EXPIRY_INTERVAL_FIELD_NUMBER = 5;
    private int containerTokenExpiryInterval_;
    /**
     * <code>optional int32 container_token_expiry_interval = 5;</code>
     */
    public boolean hasContainerTokenExpiryInterval() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional int32 container_token_expiry_interval = 5;</code>
     */
    public int getContainerTokenExpiryInterval() {
      return containerTokenExpiryInterval_;
    }

    // optional int64 container_id_start = 6;
    public static final int CONTAINER_ID_START_FIELD_NUMBER = 6;
    private long containerIdStart_;
    /**
     * <code>optional int64 container_id_start = 6;</code>
     */
    public boolean hasContainerIdStart() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional int64 container_id_start = 6;</code>
     */
    public long getContainerIdStart() {
      return containerIdStart_;
    }

    // repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 7;
    public static final int NODES_FOR_SCHEDULING_FIELD_NUMBER = 7;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto> nodesForScheduling_;
    /**
     * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 7;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto> getNodesForSchedulingList() {
      return nodesForScheduling_;
    }
    /**
     * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 7;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> 
        getNodesForSchedulingOrBuilderList() {
      return nodesForScheduling_;
    }
    /**
     * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 7;</code>
     */
    public int getNodesForSchedulingCount() {
      return nodesForScheduling_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 7;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodesForScheduling(int index) {
      return nodesForScheduling_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 7;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodesForSchedulingOrBuilder(
        int index) {
      return nodesForScheduling_.get(index);
    }

    private void initFields() {
      registerResponse_ = org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto.getDefaultInstance();
      maxAllocCapability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      minAllocCapability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      incrAllocCapability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      containerTokenExpiryInterval_ = 0;
      containerIdStart_ = 0L;
      nodesForScheduling_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (hasRegisterResponse()) {
        if (!getRegisterResponse().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, registerResponse_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, maxAllocCapability_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(3, minAllocCapability_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeMessage(4, incrAllocCapability_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeInt32(5, containerTokenExpiryInterval_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeInt64(6, containerIdStart_);
      }
      for (int i = 0; i < nodesForScheduling_.size(); i++) {
        output.writeMessage(7, nodesForScheduling_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, registerResponse_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, maxAllocCapability_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, minAllocCapability_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, incrAllocCapability_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(5, containerTokenExpiryInterval_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(6, containerIdStart_);
      }
      for (int i = 0; i < nodesForScheduling_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(7, nodesForScheduling_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedRegisterResponseProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedRegisterResponseProto other = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedRegisterResponseProto) obj;

      boolean result = true;
      result = result && (hasRegisterResponse() == other.hasRegisterResponse());
      if (hasRegisterResponse()) {
        result = result && getRegisterResponse()
            .equals(other.getRegisterResponse());
      }
      result = result && (hasMaxAllocCapability() == other.hasMaxAllocCapability());
      if (hasMaxAllocCapability()) {
        result = result && getMaxAllocCapability()
            .equals(other.getMaxAllocCapability());
      }
      result = result && (hasMinAllocCapability() == other.hasMinAllocCapability());
      if (hasMinAllocCapability()) {
        result = result && getMinAllocCapability()
            .equals(other.getMinAllocCapability());
      }
      result = result && (hasIncrAllocCapability() == other.hasIncrAllocCapability());
      if (hasIncrAllocCapability()) {
        result = result && getIncrAllocCapability()
            .equals(other.getIncrAllocCapability());
      }
      result = result && (hasContainerTokenExpiryInterval() == other.hasContainerTokenExpiryInterval());
      if (hasContainerTokenExpiryInterval()) {
        result = result && (getContainerTokenExpiryInterval()
            == other.getContainerTokenExpiryInterval());
      }
      result = result && (hasContainerIdStart() == other.hasContainerIdStart());
      if (hasContainerIdStart()) {
        result = result && (getContainerIdStart()
            == other.getContainerIdStart());
      }
      result = result && getNodesForSchedulingList()
          .equals(other.getNodesForSchedulingList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasRegisterResponse()) {
        hash = (37 * hash) + REGISTER_RESPONSE_FIELD_NUMBER;
        hash = (53 * hash) + getRegisterResponse().hashCode();
      }
      if (hasMaxAllocCapability()) {
        hash = (37 * hash) + MAX_ALLOC_CAPABILITY_FIELD_NUMBER;
        hash = (53 * hash) + getMaxAllocCapability().hashCode();
      }
      if (hasMinAllocCapability()) {
        hash = (37 * hash) + MIN_ALLOC_CAPABILITY_FIELD_NUMBER;
        hash = (53 * hash) + getMinAllocCapability().hashCode();
      }
      if (hasIncrAllocCapability()) {
        hash = (37 * hash) + INCR_ALLOC_CAPABILITY_FIELD_NUMBER;
        hash = (53 * hash) + getIncrAllocCapability().hashCode();
      }
      if (hasContainerTokenExpiryInterval()) {
        hash = (37 * hash) + CONTAINER_TOKEN_EXPIRY_INTERVAL_FIELD_NUMBER;
        hash = (53 * hash) + getContainerTokenExpiryInterval();
      }
      if (hasContainerIdStart()) {
        hash = (37 * hash) + CONTAINER_ID_START_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getContainerIdStart());
      }
      if (getNodesForSchedulingCount() > 0) {
        hash = (37 * hash) + NODES_FOR_SCHEDULING_FIELD_NUMBER;
        hash = (53 * hash) + getNodesForSchedulingList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedRegisterResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedRegisterResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedRegisterResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedRegisterResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedRegisterResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedRegisterResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedRegisterResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedRegisterResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedRegisterResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedRegisterResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedRegisterResponseProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.DistSchedRegisterResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedRegisterResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_DistSchedRegisterResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_DistSchedRegisterResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedRegisterResponseProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedRegisterResponseProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedRegisterResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getRegisterResponseFieldBuilder();
          getMaxAllocCapabilityFieldBuilder();
          getMinAllocCapabilityFieldBuilder();
          getIncrAllocCapabilityFieldBuilder();
          getNodesForSchedulingFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (registerResponseBuilder_ == null) {
          registerResponse_ = org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto.getDefaultInstance();
        } else {
          registerResponseBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (maxAllocCapabilityBuilder_ == null) {
          maxAllocCapability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
        } else {
          maxAllocCapabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (minAllocCapabilityBuilder_ == null) {
          minAllocCapability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
        } else {
          minAllocCapabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        if (incrAllocCapabilityBuilder_ == null) {
          incrAllocCapability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
        } else {
          incrAllocCapabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        containerTokenExpiryInterval_ = 0;
        bitField0_ = (bitField0_ & ~0x00000010);
        containerIdStart_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000020);
        if (nodesForSchedulingBuilder_ == null) {
          nodesForScheduling_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000040);
        } else {
          nodesForSchedulingBuilder_.clear();
        }
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_DistSchedRegisterResponseProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedRegisterResponseProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedRegisterResponseProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedRegisterResponseProto build() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedRegisterResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedRegisterResponseProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedRegisterResponseProto result = new org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedRegisterResponseProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (registerResponseBuilder_ == null) {
          result.registerResponse_ = registerResponse_;
        } else {
          result.registerResponse_ = registerResponseBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (maxAllocCapabilityBuilder_ == null) {
          result.maxAllocCapability_ = maxAllocCapability_;
        } else {
          result.maxAllocCapability_ = maxAllocCapabilityBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (minAllocCapabilityBuilder_ == null) {
          result.minAllocCapability_ = minAllocCapability_;
        } else {
          result.minAllocCapability_ = minAllocCapabilityBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        if (incrAllocCapabilityBuilder_ == null) {
          result.incrAllocCapability_ = incrAllocCapability_;
        } else {
          result.incrAllocCapability_ = incrAllocCapabilityBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.containerTokenExpiryInterval_ = containerTokenExpiryInterval_;
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000020;
        }
        result.containerIdStart_ = containerIdStart_;
        if (nodesForSchedulingBuilder_ == null) {
          if (((bitField0_ & 0x00000040) == 0x00000040)) {
            nodesForScheduling_ = java.util.Collections.unmodifiableList(nodesForScheduling_);
            bitField0_ = (bitField0_ & ~0x00000040);
          }
          result.nodesForScheduling_ = nodesForScheduling_;
        } else {
          result.nodesForScheduling_ = nodesForSchedulingBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedRegisterResponseProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedRegisterResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedRegisterResponseProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedRegisterResponseProto.getDefaultInstance()) return this;
        if (other.hasRegisterResponse()) {
          mergeRegisterResponse(other.getRegisterResponse());
        }
        if (other.hasMaxAllocCapability()) {
          mergeMaxAllocCapability(other.getMaxAllocCapability());
        }
        if (other.hasMinAllocCapability()) {
          mergeMinAllocCapability(other.getMinAllocCapability());
        }
        if (other.hasIncrAllocCapability()) {
          mergeIncrAllocCapability(other.getIncrAllocCapability());
        }
        if (other.hasContainerTokenExpiryInterval()) {
          setContainerTokenExpiryInterval(other.getContainerTokenExpiryInterval());
        }
        if (other.hasContainerIdStart()) {
          setContainerIdStart(other.getContainerIdStart());
        }
        if (nodesForSchedulingBuilder_ == null) {
          if (!other.nodesForScheduling_.isEmpty()) {
            if (nodesForScheduling_.isEmpty()) {
              nodesForScheduling_ = other.nodesForScheduling_;
              bitField0_ = (bitField0_ & ~0x00000040);
            } else {
              ensureNodesForSchedulingIsMutable();
              nodesForScheduling_.addAll(other.nodesForScheduling_);
            }
            onChanged();
          }
        } else {
          if (!other.nodesForScheduling_.isEmpty()) {
            if (nodesForSchedulingBuilder_.isEmpty()) {
              nodesForSchedulingBuilder_.dispose();
              nodesForSchedulingBuilder_ = null;
              nodesForScheduling_ = other.nodesForScheduling_;
              bitField0_ = (bitField0_ & ~0x00000040);
              nodesForSchedulingBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getNodesForSchedulingFieldBuilder() : null;
            } else {
              nodesForSchedulingBuilder_.addAllMessages(other.nodesForScheduling_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (hasRegisterResponse()) {
          if (!getRegisterResponse().isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedRegisterResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedRegisterResponseProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.RegisterApplicationMasterResponseProto register_response = 1;
      private org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto registerResponse_ = org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto, org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto.Builder, org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProtoOrBuilder> registerResponseBuilder_;
      /**
       * <code>optional .hadoop.yarn.RegisterApplicationMasterResponseProto register_response = 1;</code>
       */
      public boolean hasRegisterResponse() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.RegisterApplicationMasterResponseProto register_response = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto getRegisterResponse() {
        if (registerResponseBuilder_ == null) {
          return registerResponse_;
        } else {
          return registerResponseBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.RegisterApplicationMasterResponseProto register_response = 1;</code>
       */
      public Builder setRegisterResponse(org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto value) {
        if (registerResponseBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          registerResponse_ = value;
          onChanged();
        } else {
          registerResponseBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.RegisterApplicationMasterResponseProto register_response = 1;</code>
       */
      public Builder setRegisterResponse(
          org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto.Builder builderForValue) {
        if (registerResponseBuilder_ == null) {
          registerResponse_ = builderForValue.build();
          onChanged();
        } else {
          registerResponseBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.RegisterApplicationMasterResponseProto register_response = 1;</code>
       */
      public Builder mergeRegisterResponse(org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto value) {
        if (registerResponseBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              registerResponse_ != org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto.getDefaultInstance()) {
            registerResponse_ =
              org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto.newBuilder(registerResponse_).mergeFrom(value).buildPartial();
          } else {
            registerResponse_ = value;
          }
          onChanged();
        } else {
          registerResponseBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.RegisterApplicationMasterResponseProto register_response = 1;</code>
       */
      public Builder clearRegisterResponse() {
        if (registerResponseBuilder_ == null) {
          registerResponse_ = org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto.getDefaultInstance();
          onChanged();
        } else {
          registerResponseBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.RegisterApplicationMasterResponseProto register_response = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto.Builder getRegisterResponseBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegisterResponseFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.RegisterApplicationMasterResponseProto register_response = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProtoOrBuilder getRegisterResponseOrBuilder() {
        if (registerResponseBuilder_ != null) {
          return registerResponseBuilder_.getMessageOrBuilder();
        } else {
          return registerResponse_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.RegisterApplicationMasterResponseProto register_response = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto, org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto.Builder, org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProtoOrBuilder> 
          getRegisterResponseFieldBuilder() {
        if (registerResponseBuilder_ == null) {
          registerResponseBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto, org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto.Builder, org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProtoOrBuilder>(
                  registerResponse_,
                  getParentForChildren(),
                  isClean());
          registerResponse_ = null;
        }
        return registerResponseBuilder_;
      }

      // optional .hadoop.yarn.ResourceProto max_alloc_capability = 2;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto maxAllocCapability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> maxAllocCapabilityBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto max_alloc_capability = 2;</code>
       */
      public boolean hasMaxAllocCapability() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto max_alloc_capability = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getMaxAllocCapability() {
        if (maxAllocCapabilityBuilder_ == null) {
          return maxAllocCapability_;
        } else {
          return maxAllocCapabilityBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto max_alloc_capability = 2;</code>
       */
      public Builder setMaxAllocCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (maxAllocCapabilityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          maxAllocCapability_ = value;
          onChanged();
        } else {
          maxAllocCapabilityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto max_alloc_capability = 2;</code>
       */
      public Builder setMaxAllocCapability(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (maxAllocCapabilityBuilder_ == null) {
          maxAllocCapability_ = builderForValue.build();
          onChanged();
        } else {
          maxAllocCapabilityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto max_alloc_capability = 2;</code>
       */
      public Builder mergeMaxAllocCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (maxAllocCapabilityBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              maxAllocCapability_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            maxAllocCapability_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(maxAllocCapability_).mergeFrom(value).buildPartial();
          } else {
            maxAllocCapability_ = value;
          }
          onChanged();
        } else {
          maxAllocCapabilityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto max_alloc_capability = 2;</code>
       */
      public Builder clearMaxAllocCapability() {
        if (maxAllocCapabilityBuilder_ == null) {
          maxAllocCapability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
          onChanged();
        } else {
          maxAllocCapabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto max_alloc_capability = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getMaxAllocCapabilityBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getMaxAllocCapabilityFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto max_alloc_capability = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getMaxAllocCapabilityOrBuilder() {
        if (maxAllocCapabilityBuilder_ != null) {
          return maxAllocCapabilityBuilder_.getMessageOrBuilder();
        } else {
          return maxAllocCapability_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto max_alloc_capability = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getMaxAllocCapabilityFieldBuilder() {
        if (maxAllocCapabilityBuilder_ == null) {
          maxAllocCapabilityBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  maxAllocCapability_,
                  getParentForChildren(),
                  isClean());
          maxAllocCapability_ = null;
        }
        return maxAllocCapabilityBuilder_;
      }

      // optional .hadoop.yarn.ResourceProto min_alloc_capability = 3;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto minAllocCapability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> minAllocCapabilityBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto min_alloc_capability = 3;</code>
       */
      public boolean hasMinAllocCapability() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto min_alloc_capability = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getMinAllocCapability() {
        if (minAllocCapabilityBuilder_ == null) {
          return minAllocCapability_;
        } else {
          return minAllocCapabilityBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto min_alloc_capability = 3;</code>
       */
      public Builder setMinAllocCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (minAllocCapabilityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          minAllocCapability_ = value;
          onChanged();
        } else {
          minAllocCapabilityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto min_alloc_capability = 3;</code>
       */
      public Builder setMinAllocCapability(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (minAllocCapabilityBuilder_ == null) {
          minAllocCapability_ = builderForValue.build();
          onChanged();
        } else {
          minAllocCapabilityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto min_alloc_capability = 3;</code>
       */
      public Builder mergeMinAllocCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (minAllocCapabilityBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              minAllocCapability_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            minAllocCapability_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(minAllocCapability_).mergeFrom(value).buildPartial();
          } else {
            minAllocCapability_ = value;
          }
          onChanged();
        } else {
          minAllocCapabilityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto min_alloc_capability = 3;</code>
       */
      public Builder clearMinAllocCapability() {
        if (minAllocCapabilityBuilder_ == null) {
          minAllocCapability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
          onChanged();
        } else {
          minAllocCapabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto min_alloc_capability = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getMinAllocCapabilityBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getMinAllocCapabilityFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto min_alloc_capability = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getMinAllocCapabilityOrBuilder() {
        if (minAllocCapabilityBuilder_ != null) {
          return minAllocCapabilityBuilder_.getMessageOrBuilder();
        } else {
          return minAllocCapability_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto min_alloc_capability = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getMinAllocCapabilityFieldBuilder() {
        if (minAllocCapabilityBuilder_ == null) {
          minAllocCapabilityBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  minAllocCapability_,
                  getParentForChildren(),
                  isClean());
          minAllocCapability_ = null;
        }
        return minAllocCapabilityBuilder_;
      }

      // optional .hadoop.yarn.ResourceProto incr_alloc_capability = 4;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto incrAllocCapability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> incrAllocCapabilityBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto incr_alloc_capability = 4;</code>
       */
      public boolean hasIncrAllocCapability() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto incr_alloc_capability = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getIncrAllocCapability() {
        if (incrAllocCapabilityBuilder_ == null) {
          return incrAllocCapability_;
        } else {
          return incrAllocCapabilityBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto incr_alloc_capability = 4;</code>
       */
      public Builder setIncrAllocCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (incrAllocCapabilityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          incrAllocCapability_ = value;
          onChanged();
        } else {
          incrAllocCapabilityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto incr_alloc_capability = 4;</code>
       */
      public Builder setIncrAllocCapability(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (incrAllocCapabilityBuilder_ == null) {
          incrAllocCapability_ = builderForValue.build();
          onChanged();
        } else {
          incrAllocCapabilityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto incr_alloc_capability = 4;</code>
       */
      public Builder mergeIncrAllocCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (incrAllocCapabilityBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008) &&
              incrAllocCapability_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            incrAllocCapability_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(incrAllocCapability_).mergeFrom(value).buildPartial();
          } else {
            incrAllocCapability_ = value;
          }
          onChanged();
        } else {
          incrAllocCapabilityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto incr_alloc_capability = 4;</code>
       */
      public Builder clearIncrAllocCapability() {
        if (incrAllocCapabilityBuilder_ == null) {
          incrAllocCapability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
          onChanged();
        } else {
          incrAllocCapabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto incr_alloc_capability = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getIncrAllocCapabilityBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getIncrAllocCapabilityFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto incr_alloc_capability = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getIncrAllocCapabilityOrBuilder() {
        if (incrAllocCapabilityBuilder_ != null) {
          return incrAllocCapabilityBuilder_.getMessageOrBuilder();
        } else {
          return incrAllocCapability_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto incr_alloc_capability = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getIncrAllocCapabilityFieldBuilder() {
        if (incrAllocCapabilityBuilder_ == null) {
          incrAllocCapabilityBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  incrAllocCapability_,
                  getParentForChildren(),
                  isClean());
          incrAllocCapability_ = null;
        }
        return incrAllocCapabilityBuilder_;
      }

      // optional int32 container_token_expiry_interval = 5;
      private int containerTokenExpiryInterval_ ;
      /**
       * <code>optional int32 container_token_expiry_interval = 5;</code>
       */
      public boolean hasContainerTokenExpiryInterval() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional int32 container_token_expiry_interval = 5;</code>
       */
      public int getContainerTokenExpiryInterval() {
        return containerTokenExpiryInterval_;
      }
      /**
       * <code>optional int32 container_token_expiry_interval = 5;</code>
       */
      public Builder setContainerTokenExpiryInterval(int value) {
        bitField0_ |= 0x00000010;
        containerTokenExpiryInterval_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 container_token_expiry_interval = 5;</code>
       */
      public Builder clearContainerTokenExpiryInterval() {
        bitField0_ = (bitField0_ & ~0x00000010);
        containerTokenExpiryInterval_ = 0;
        onChanged();
        return this;
      }

      // optional int64 container_id_start = 6;
      private long containerIdStart_ ;
      /**
       * <code>optional int64 container_id_start = 6;</code>
       */
      public boolean hasContainerIdStart() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional int64 container_id_start = 6;</code>
       */
      public long getContainerIdStart() {
        return containerIdStart_;
      }
      /**
       * <code>optional int64 container_id_start = 6;</code>
       */
      public Builder setContainerIdStart(long value) {
        bitField0_ |= 0x00000020;
        containerIdStart_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 container_id_start = 6;</code>
       */
      public Builder clearContainerIdStart() {
        bitField0_ = (bitField0_ & ~0x00000020);
        containerIdStart_ = 0L;
        onChanged();
        return this;
      }

      // repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 7;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto> nodesForScheduling_ =
        java.util.Collections.emptyList();
      private void ensureNodesForSchedulingIsMutable() {
        if (!((bitField0_ & 0x00000040) == 0x00000040)) {
          nodesForScheduling_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto>(nodesForScheduling_);
          bitField0_ |= 0x00000040;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> nodesForSchedulingBuilder_;

      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 7;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto> getNodesForSchedulingList() {
        if (nodesForSchedulingBuilder_ == null) {
          return java.util.Collections.unmodifiableList(nodesForScheduling_);
        } else {
          return nodesForSchedulingBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 7;</code>
       */
      public int getNodesForSchedulingCount() {
        if (nodesForSchedulingBuilder_ == null) {
          return nodesForScheduling_.size();
        } else {
          return nodesForSchedulingBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodesForScheduling(int index) {
        if (nodesForSchedulingBuilder_ == null) {
          return nodesForScheduling_.get(index);
        } else {
          return nodesForSchedulingBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 7;</code>
       */
      public Builder setNodesForScheduling(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodesForSchedulingBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureNodesForSchedulingIsMutable();
          nodesForScheduling_.set(index, value);
          onChanged();
        } else {
          nodesForSchedulingBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 7;</code>
       */
      public Builder setNodesForScheduling(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder builderForValue) {
        if (nodesForSchedulingBuilder_ == null) {
          ensureNodesForSchedulingIsMutable();
          nodesForScheduling_.set(index, builderForValue.build());
          onChanged();
        } else {
          nodesForSchedulingBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 7;</code>
       */
      public Builder addNodesForScheduling(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodesForSchedulingBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureNodesForSchedulingIsMutable();
          nodesForScheduling_.add(value);
          onChanged();
        } else {
          nodesForSchedulingBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 7;</code>
       */
      public Builder addNodesForScheduling(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodesForSchedulingBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureNodesForSchedulingIsMutable();
          nodesForScheduling_.add(index, value);
          onChanged();
        } else {
          nodesForSchedulingBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 7;</code>
       */
      public Builder addNodesForScheduling(
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder builderForValue) {
        if (nodesForSchedulingBuilder_ == null) {
          ensureNodesForSchedulingIsMutable();
          nodesForScheduling_.add(builderForValue.build());
          onChanged();
        } else {
          nodesForSchedulingBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 7;</code>
       */
      public Builder addNodesForScheduling(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder builderForValue) {
        if (nodesForSchedulingBuilder_ == null) {
          ensureNodesForSchedulingIsMutable();
          nodesForScheduling_.add(index, builderForValue.build());
          onChanged();
        } else {
          nodesForSchedulingBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 7;</code>
       */
      public Builder addAllNodesForScheduling(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto> values) {
        if (nodesForSchedulingBuilder_ == null) {
          ensureNodesForSchedulingIsMutable();
          super.addAll(values, nodesForScheduling_);
          onChanged();
        } else {
          nodesForSchedulingBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 7;</code>
       */
      public Builder clearNodesForScheduling() {
        if (nodesForSchedulingBuilder_ == null) {
          nodesForScheduling_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000040);
          onChanged();
        } else {
          nodesForSchedulingBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 7;</code>
       */
      public Builder removeNodesForScheduling(int index) {
        if (nodesForSchedulingBuilder_ == null) {
          ensureNodesForSchedulingIsMutable();
          nodesForScheduling_.remove(index);
          onChanged();
        } else {
          nodesForSchedulingBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder getNodesForSchedulingBuilder(
          int index) {
        return getNodesForSchedulingFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodesForSchedulingOrBuilder(
          int index) {
        if (nodesForSchedulingBuilder_ == null) {
          return nodesForScheduling_.get(index);  } else {
          return nodesForSchedulingBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 7;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> 
           getNodesForSchedulingOrBuilderList() {
        if (nodesForSchedulingBuilder_ != null) {
          return nodesForSchedulingBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(nodesForScheduling_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder addNodesForSchedulingBuilder() {
        return getNodesForSchedulingFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder addNodesForSchedulingBuilder(
          int index) {
        return getNodesForSchedulingFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 7;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder> 
           getNodesForSchedulingBuilderList() {
        return getNodesForSchedulingFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> 
          getNodesForSchedulingFieldBuilder() {
        if (nodesForSchedulingBuilder_ == null) {
          nodesForSchedulingBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder>(
                  nodesForScheduling_,
                  ((bitField0_ & 0x00000040) == 0x00000040),
                  getParentForChildren(),
                  isClean());
          nodesForScheduling_ = null;
        }
        return nodesForSchedulingBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.DistSchedRegisterResponseProto)
    }

    static {
      defaultInstance = new DistSchedRegisterResponseProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.DistSchedRegisterResponseProto)
  }

  public interface DistSchedAllocateResponseProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.AllocateResponseProto allocate_response = 1;
    /**
     * <code>optional .hadoop.yarn.AllocateResponseProto allocate_response = 1;</code>
     */
    boolean hasAllocateResponse();
    /**
     * <code>optional .hadoop.yarn.AllocateResponseProto allocate_response = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto getAllocateResponse();
    /**
     * <code>optional .hadoop.yarn.AllocateResponseProto allocate_response = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProtoOrBuilder getAllocateResponseOrBuilder();

    // repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 2;
    /**
     * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 2;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto> 
        getNodesForSchedulingList();
    /**
     * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodesForScheduling(int index);
    /**
     * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 2;</code>
     */
    int getNodesForSchedulingCount();
    /**
     * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 2;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> 
        getNodesForSchedulingOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodesForSchedulingOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.DistSchedAllocateResponseProto}
   */
  public static final class DistSchedAllocateResponseProto extends
      com.google.protobuf.GeneratedMessage
      implements DistSchedAllocateResponseProtoOrBuilder {
    // Use DistSchedAllocateResponseProto.newBuilder() to construct.
    private DistSchedAllocateResponseProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private DistSchedAllocateResponseProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final DistSchedAllocateResponseProto defaultInstance;
    public static DistSchedAllocateResponseProto getDefaultInstance() {
      return defaultInstance;
    }

    public DistSchedAllocateResponseProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private DistSchedAllocateResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = allocateResponse_.toBuilder();
              }
              allocateResponse_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(allocateResponse_);
                allocateResponse_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                nodesForScheduling_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto>();
                mutable_bitField0_ |= 0x00000002;
              }
              nodesForScheduling_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
          nodesForScheduling_ = java.util.Collections.unmodifiableList(nodesForScheduling_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_DistSchedAllocateResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_DistSchedAllocateResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateResponseProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateResponseProto.Builder.class);
    }

    public static com.google.protobuf.Parser<DistSchedAllocateResponseProto> PARSER =
        new com.google.protobuf.AbstractParser<DistSchedAllocateResponseProto>() {
      public DistSchedAllocateResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new DistSchedAllocateResponseProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<DistSchedAllocateResponseProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.AllocateResponseProto allocate_response = 1;
    public static final int ALLOCATE_RESPONSE_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto allocateResponse_;
    /**
     * <code>optional .hadoop.yarn.AllocateResponseProto allocate_response = 1;</code>
     */
    public boolean hasAllocateResponse() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.AllocateResponseProto allocate_response = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto getAllocateResponse() {
      return allocateResponse_;
    }
    /**
     * <code>optional .hadoop.yarn.AllocateResponseProto allocate_response = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProtoOrBuilder getAllocateResponseOrBuilder() {
      return allocateResponse_;
    }

    // repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 2;
    public static final int NODES_FOR_SCHEDULING_FIELD_NUMBER = 2;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto> nodesForScheduling_;
    /**
     * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 2;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto> getNodesForSchedulingList() {
      return nodesForScheduling_;
    }
    /**
     * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 2;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> 
        getNodesForSchedulingOrBuilderList() {
      return nodesForScheduling_;
    }
    /**
     * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 2;</code>
     */
    public int getNodesForSchedulingCount() {
      return nodesForScheduling_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodesForScheduling(int index) {
      return nodesForScheduling_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodesForSchedulingOrBuilder(
        int index) {
      return nodesForScheduling_.get(index);
    }

    private void initFields() {
      allocateResponse_ = org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto.getDefaultInstance();
      nodesForScheduling_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (hasAllocateResponse()) {
        if (!getAllocateResponse().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, allocateResponse_);
      }
      for (int i = 0; i < nodesForScheduling_.size(); i++) {
        output.writeMessage(2, nodesForScheduling_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, allocateResponse_);
      }
      for (int i = 0; i < nodesForScheduling_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, nodesForScheduling_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateResponseProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateResponseProto other = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateResponseProto) obj;

      boolean result = true;
      result = result && (hasAllocateResponse() == other.hasAllocateResponse());
      if (hasAllocateResponse()) {
        result = result && getAllocateResponse()
            .equals(other.getAllocateResponse());
      }
      result = result && getNodesForSchedulingList()
          .equals(other.getNodesForSchedulingList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasAllocateResponse()) {
        hash = (37 * hash) + ALLOCATE_RESPONSE_FIELD_NUMBER;
        hash = (53 * hash) + getAllocateResponse().hashCode();
      }
      if (getNodesForSchedulingCount() > 0) {
        hash = (37 * hash) + NODES_FOR_SCHEDULING_FIELD_NUMBER;
        hash = (53 * hash) + getNodesForSchedulingList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateResponseProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.DistSchedAllocateResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_DistSchedAllocateResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_DistSchedAllocateResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateResponseProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateResponseProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getAllocateResponseFieldBuilder();
          getNodesForSchedulingFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (allocateResponseBuilder_ == null) {
          allocateResponse_ = org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto.getDefaultInstance();
        } else {
          allocateResponseBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (nodesForSchedulingBuilder_ == null) {
          nodesForScheduling_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
        } else {
          nodesForSchedulingBuilder_.clear();
        }
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_DistSchedAllocateResponseProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateResponseProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateResponseProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateResponseProto build() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateResponseProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateResponseProto result = new org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateResponseProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (allocateResponseBuilder_ == null) {
          result.allocateResponse_ = allocateResponse_;
        } else {
          result.allocateResponse_ = allocateResponseBuilder_.build();
        }
        if (nodesForSchedulingBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002)) {
            nodesForScheduling_ = java.util.Collections.unmodifiableList(nodesForScheduling_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.nodesForScheduling_ = nodesForScheduling_;
        } else {
          result.nodesForScheduling_ = nodesForSchedulingBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateResponseProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateResponseProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateResponseProto.getDefaultInstance()) return this;
        if (other.hasAllocateResponse()) {
          mergeAllocateResponse(other.getAllocateResponse());
        }
        if (nodesForSchedulingBuilder_ == null) {
          if (!other.nodesForScheduling_.isEmpty()) {
            if (nodesForScheduling_.isEmpty()) {
              nodesForScheduling_ = other.nodesForScheduling_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureNodesForSchedulingIsMutable();
              nodesForScheduling_.addAll(other.nodesForScheduling_);
            }
            onChanged();
          }
        } else {
          if (!other.nodesForScheduling_.isEmpty()) {
            if (nodesForSchedulingBuilder_.isEmpty()) {
              nodesForSchedulingBuilder_.dispose();
              nodesForSchedulingBuilder_ = null;
              nodesForScheduling_ = other.nodesForScheduling_;
              bitField0_ = (bitField0_ & ~0x00000002);
              nodesForSchedulingBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getNodesForSchedulingFieldBuilder() : null;
            } else {
              nodesForSchedulingBuilder_.addAllMessages(other.nodesForScheduling_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (hasAllocateResponse()) {
          if (!getAllocateResponse().isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateResponseProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.AllocateResponseProto allocate_response = 1;
      private org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto allocateResponse_ = org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto, org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto.Builder, org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProtoOrBuilder> allocateResponseBuilder_;
      /**
       * <code>optional .hadoop.yarn.AllocateResponseProto allocate_response = 1;</code>
       */
      public boolean hasAllocateResponse() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.AllocateResponseProto allocate_response = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto getAllocateResponse() {
        if (allocateResponseBuilder_ == null) {
          return allocateResponse_;
        } else {
          return allocateResponseBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.AllocateResponseProto allocate_response = 1;</code>
       */
      public Builder setAllocateResponse(org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto value) {
        if (allocateResponseBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          allocateResponse_ = value;
          onChanged();
        } else {
          allocateResponseBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.AllocateResponseProto allocate_response = 1;</code>
       */
      public Builder setAllocateResponse(
          org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto.Builder builderForValue) {
        if (allocateResponseBuilder_ == null) {
          allocateResponse_ = builderForValue.build();
          onChanged();
        } else {
          allocateResponseBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.AllocateResponseProto allocate_response = 1;</code>
       */
      public Builder mergeAllocateResponse(org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto value) {
        if (allocateResponseBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              allocateResponse_ != org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto.getDefaultInstance()) {
            allocateResponse_ =
              org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto.newBuilder(allocateResponse_).mergeFrom(value).buildPartial();
          } else {
            allocateResponse_ = value;
          }
          onChanged();
        } else {
          allocateResponseBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.AllocateResponseProto allocate_response = 1;</code>
       */
      public Builder clearAllocateResponse() {
        if (allocateResponseBuilder_ == null) {
          allocateResponse_ = org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto.getDefaultInstance();
          onChanged();
        } else {
          allocateResponseBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.AllocateResponseProto allocate_response = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto.Builder getAllocateResponseBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getAllocateResponseFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.AllocateResponseProto allocate_response = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProtoOrBuilder getAllocateResponseOrBuilder() {
        if (allocateResponseBuilder_ != null) {
          return allocateResponseBuilder_.getMessageOrBuilder();
        } else {
          return allocateResponse_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.AllocateResponseProto allocate_response = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto, org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto.Builder, org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProtoOrBuilder> 
          getAllocateResponseFieldBuilder() {
        if (allocateResponseBuilder_ == null) {
          allocateResponseBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto, org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto.Builder, org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProtoOrBuilder>(
                  allocateResponse_,
                  getParentForChildren(),
                  isClean());
          allocateResponse_ = null;
        }
        return allocateResponseBuilder_;
      }

      // repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 2;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto> nodesForScheduling_ =
        java.util.Collections.emptyList();
      private void ensureNodesForSchedulingIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          nodesForScheduling_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto>(nodesForScheduling_);
          bitField0_ |= 0x00000002;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> nodesForSchedulingBuilder_;

      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 2;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto> getNodesForSchedulingList() {
        if (nodesForSchedulingBuilder_ == null) {
          return java.util.Collections.unmodifiableList(nodesForScheduling_);
        } else {
          return nodesForSchedulingBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 2;</code>
       */
      public int getNodesForSchedulingCount() {
        if (nodesForSchedulingBuilder_ == null) {
          return nodesForScheduling_.size();
        } else {
          return nodesForSchedulingBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodesForScheduling(int index) {
        if (nodesForSchedulingBuilder_ == null) {
          return nodesForScheduling_.get(index);
        } else {
          return nodesForSchedulingBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 2;</code>
       */
      public Builder setNodesForScheduling(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodesForSchedulingBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureNodesForSchedulingIsMutable();
          nodesForScheduling_.set(index, value);
          onChanged();
        } else {
          nodesForSchedulingBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 2;</code>
       */
      public Builder setNodesForScheduling(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder builderForValue) {
        if (nodesForSchedulingBuilder_ == null) {
          ensureNodesForSchedulingIsMutable();
          nodesForScheduling_.set(index, builderForValue.build());
          onChanged();
        } else {
          nodesForSchedulingBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 2;</code>
       */
      public Builder addNodesForScheduling(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodesForSchedulingBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureNodesForSchedulingIsMutable();
          nodesForScheduling_.add(value);
          onChanged();
        } else {
          nodesForSchedulingBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 2;</code>
       */
      public Builder addNodesForScheduling(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodesForSchedulingBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureNodesForSchedulingIsMutable();
          nodesForScheduling_.add(index, value);
          onChanged();
        } else {
          nodesForSchedulingBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 2;</code>
       */
      public Builder addNodesForScheduling(
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder builderForValue) {
        if (nodesForSchedulingBuilder_ == null) {
          ensureNodesForSchedulingIsMutable();
          nodesForScheduling_.add(builderForValue.build());
          onChanged();
        } else {
          nodesForSchedulingBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 2;</code>
       */
      public Builder addNodesForScheduling(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder builderForValue) {
        if (nodesForSchedulingBuilder_ == null) {
          ensureNodesForSchedulingIsMutable();
          nodesForScheduling_.add(index, builderForValue.build());
          onChanged();
        } else {
          nodesForSchedulingBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 2;</code>
       */
      public Builder addAllNodesForScheduling(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto> values) {
        if (nodesForSchedulingBuilder_ == null) {
          ensureNodesForSchedulingIsMutable();
          super.addAll(values, nodesForScheduling_);
          onChanged();
        } else {
          nodesForSchedulingBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 2;</code>
       */
      public Builder clearNodesForScheduling() {
        if (nodesForSchedulingBuilder_ == null) {
          nodesForScheduling_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          nodesForSchedulingBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 2;</code>
       */
      public Builder removeNodesForScheduling(int index) {
        if (nodesForSchedulingBuilder_ == null) {
          ensureNodesForSchedulingIsMutable();
          nodesForScheduling_.remove(index);
          onChanged();
        } else {
          nodesForSchedulingBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder getNodesForSchedulingBuilder(
          int index) {
        return getNodesForSchedulingFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodesForSchedulingOrBuilder(
          int index) {
        if (nodesForSchedulingBuilder_ == null) {
          return nodesForScheduling_.get(index);  } else {
          return nodesForSchedulingBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 2;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> 
           getNodesForSchedulingOrBuilderList() {
        if (nodesForSchedulingBuilder_ != null) {
          return nodesForSchedulingBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(nodesForScheduling_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder addNodesForSchedulingBuilder() {
        return getNodesForSchedulingFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder addNodesForSchedulingBuilder(
          int index) {
        return getNodesForSchedulingFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.NodeIdProto nodes_for_scheduling = 2;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder> 
           getNodesForSchedulingBuilderList() {
        return getNodesForSchedulingFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> 
          getNodesForSchedulingFieldBuilder() {
        if (nodesForSchedulingBuilder_ == null) {
          nodesForSchedulingBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder>(
                  nodesForScheduling_,
                  ((bitField0_ & 0x00000002) == 0x00000002),
                  getParentForChildren(),
                  isClean());
          nodesForScheduling_ = null;
        }
        return nodesForSchedulingBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.DistSchedAllocateResponseProto)
    }

    static {
      defaultInstance = new DistSchedAllocateResponseProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.DistSchedAllocateResponseProto)
  }

  public interface DistSchedAllocateRequestProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.AllocateRequestProto allocate_request = 1;
    /**
     * <code>optional .hadoop.yarn.AllocateRequestProto allocate_request = 1;</code>
     */
    boolean hasAllocateRequest();
    /**
     * <code>optional .hadoop.yarn.AllocateRequestProto allocate_request = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto getAllocateRequest();
    /**
     * <code>optional .hadoop.yarn.AllocateRequestProto allocate_request = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProtoOrBuilder getAllocateRequestOrBuilder();

    // repeated .hadoop.yarn.ContainerProto allocated_containers = 2;
    /**
     * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 2;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto> 
        getAllocatedContainersList();
    /**
     * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto getAllocatedContainers(int index);
    /**
     * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 2;</code>
     */
    int getAllocatedContainersCount();
    /**
     * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 2;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder> 
        getAllocatedContainersOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder getAllocatedContainersOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.DistSchedAllocateRequestProto}
   */
  public static final class DistSchedAllocateRequestProto extends
      com.google.protobuf.GeneratedMessage
      implements DistSchedAllocateRequestProtoOrBuilder {
    // Use DistSchedAllocateRequestProto.newBuilder() to construct.
    private DistSchedAllocateRequestProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private DistSchedAllocateRequestProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final DistSchedAllocateRequestProto defaultInstance;
    public static DistSchedAllocateRequestProto getDefaultInstance() {
      return defaultInstance;
    }

    public DistSchedAllocateRequestProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private DistSchedAllocateRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = allocateRequest_.toBuilder();
              }
              allocateRequest_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(allocateRequest_);
                allocateRequest_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                allocatedContainers_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto>();
                mutable_bitField0_ |= 0x00000002;
              }
              allocatedContainers_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
          allocatedContainers_ = java.util.Collections.unmodifiableList(allocatedContainers_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_DistSchedAllocateRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_DistSchedAllocateRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateRequestProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateRequestProto.Builder.class);
    }

    public static com.google.protobuf.Parser<DistSchedAllocateRequestProto> PARSER =
        new com.google.protobuf.AbstractParser<DistSchedAllocateRequestProto>() {
      public DistSchedAllocateRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new DistSchedAllocateRequestProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<DistSchedAllocateRequestProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.AllocateRequestProto allocate_request = 1;
    public static final int ALLOCATE_REQUEST_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto allocateRequest_;
    /**
     * <code>optional .hadoop.yarn.AllocateRequestProto allocate_request = 1;</code>
     */
    public boolean hasAllocateRequest() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.AllocateRequestProto allocate_request = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto getAllocateRequest() {
      return allocateRequest_;
    }
    /**
     * <code>optional .hadoop.yarn.AllocateRequestProto allocate_request = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProtoOrBuilder getAllocateRequestOrBuilder() {
      return allocateRequest_;
    }

    // repeated .hadoop.yarn.ContainerProto allocated_containers = 2;
    public static final int ALLOCATED_CONTAINERS_FIELD_NUMBER = 2;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto> allocatedContainers_;
    /**
     * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 2;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto> getAllocatedContainersList() {
      return allocatedContainers_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 2;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder> 
        getAllocatedContainersOrBuilderList() {
      return allocatedContainers_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 2;</code>
     */
    public int getAllocatedContainersCount() {
      return allocatedContainers_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto getAllocatedContainers(int index) {
      return allocatedContainers_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder getAllocatedContainersOrBuilder(
        int index) {
      return allocatedContainers_.get(index);
    }

    private void initFields() {
      allocateRequest_ = org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto.getDefaultInstance();
      allocatedContainers_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      for (int i = 0; i < getAllocatedContainersCount(); i++) {
        if (!getAllocatedContainers(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, allocateRequest_);
      }
      for (int i = 0; i < allocatedContainers_.size(); i++) {
        output.writeMessage(2, allocatedContainers_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, allocateRequest_);
      }
      for (int i = 0; i < allocatedContainers_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, allocatedContainers_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateRequestProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateRequestProto other = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateRequestProto) obj;

      boolean result = true;
      result = result && (hasAllocateRequest() == other.hasAllocateRequest());
      if (hasAllocateRequest()) {
        result = result && getAllocateRequest()
            .equals(other.getAllocateRequest());
      }
      result = result && getAllocatedContainersList()
          .equals(other.getAllocatedContainersList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasAllocateRequest()) {
        hash = (37 * hash) + ALLOCATE_REQUEST_FIELD_NUMBER;
        hash = (53 * hash) + getAllocateRequest().hashCode();
      }
      if (getAllocatedContainersCount() > 0) {
        hash = (37 * hash) + ALLOCATED_CONTAINERS_FIELD_NUMBER;
        hash = (53 * hash) + getAllocatedContainersList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateRequestProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.DistSchedAllocateRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_DistSchedAllocateRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_DistSchedAllocateRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateRequestProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateRequestProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getAllocateRequestFieldBuilder();
          getAllocatedContainersFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (allocateRequestBuilder_ == null) {
          allocateRequest_ = org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto.getDefaultInstance();
        } else {
          allocateRequestBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (allocatedContainersBuilder_ == null) {
          allocatedContainers_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
        } else {
          allocatedContainersBuilder_.clear();
        }
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_DistSchedAllocateRequestProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateRequestProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateRequestProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateRequestProto build() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateRequestProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateRequestProto result = new org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (allocateRequestBuilder_ == null) {
          result.allocateRequest_ = allocateRequest_;
        } else {
          result.allocateRequest_ = allocateRequestBuilder_.build();
        }
        if (allocatedContainersBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002)) {
            allocatedContainers_ = java.util.Collections.unmodifiableList(allocatedContainers_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.allocatedContainers_ = allocatedContainers_;
        } else {
          result.allocatedContainers_ = allocatedContainersBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateRequestProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateRequestProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateRequestProto.getDefaultInstance()) return this;
        if (other.hasAllocateRequest()) {
          mergeAllocateRequest(other.getAllocateRequest());
        }
        if (allocatedContainersBuilder_ == null) {
          if (!other.allocatedContainers_.isEmpty()) {
            if (allocatedContainers_.isEmpty()) {
              allocatedContainers_ = other.allocatedContainers_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureAllocatedContainersIsMutable();
              allocatedContainers_.addAll(other.allocatedContainers_);
            }
            onChanged();
          }
        } else {
          if (!other.allocatedContainers_.isEmpty()) {
            if (allocatedContainersBuilder_.isEmpty()) {
              allocatedContainersBuilder_.dispose();
              allocatedContainersBuilder_ = null;
              allocatedContainers_ = other.allocatedContainers_;
              bitField0_ = (bitField0_ & ~0x00000002);
              allocatedContainersBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getAllocatedContainersFieldBuilder() : null;
            } else {
              allocatedContainersBuilder_.addAllMessages(other.allocatedContainers_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        for (int i = 0; i < getAllocatedContainersCount(); i++) {
          if (!getAllocatedContainers(i).isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.DistSchedAllocateRequestProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.AllocateRequestProto allocate_request = 1;
      private org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto allocateRequest_ = org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto, org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProtoOrBuilder> allocateRequestBuilder_;
      /**
       * <code>optional .hadoop.yarn.AllocateRequestProto allocate_request = 1;</code>
       */
      public boolean hasAllocateRequest() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.AllocateRequestProto allocate_request = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto getAllocateRequest() {
        if (allocateRequestBuilder_ == null) {
          return allocateRequest_;
        } else {
          return allocateRequestBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.AllocateRequestProto allocate_request = 1;</code>
       */
      public Builder setAllocateRequest(org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto value) {
        if (allocateRequestBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          allocateRequest_ = value;
          onChanged();
        } else {
          allocateRequestBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.AllocateRequestProto allocate_request = 1;</code>
       */
      public Builder setAllocateRequest(
          org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto.Builder builderForValue) {
        if (allocateRequestBuilder_ == null) {
          allocateRequest_ = builderForValue.build();
          onChanged();
        } else {
          allocateRequestBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.AllocateRequestProto allocate_request = 1;</code>
       */
      public Builder mergeAllocateRequest(org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto value) {
        if (allocateRequestBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              allocateRequest_ != org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto.getDefaultInstance()) {
            allocateRequest_ =
              org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto.newBuilder(allocateRequest_).mergeFrom(value).buildPartial();
          } else {
            allocateRequest_ = value;
          }
          onChanged();
        } else {
          allocateRequestBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.AllocateRequestProto allocate_request = 1;</code>
       */
      public Builder clearAllocateRequest() {
        if (allocateRequestBuilder_ == null) {
          allocateRequest_ = org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto.getDefaultInstance();
          onChanged();
        } else {
          allocateRequestBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.AllocateRequestProto allocate_request = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto.Builder getAllocateRequestBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getAllocateRequestFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.AllocateRequestProto allocate_request = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProtoOrBuilder getAllocateRequestOrBuilder() {
        if (allocateRequestBuilder_ != null) {
          return allocateRequestBuilder_.getMessageOrBuilder();
        } else {
          return allocateRequest_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.AllocateRequestProto allocate_request = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto, org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProtoOrBuilder> 
          getAllocateRequestFieldBuilder() {
        if (allocateRequestBuilder_ == null) {
          allocateRequestBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto, org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProtoOrBuilder>(
                  allocateRequest_,
                  getParentForChildren(),
                  isClean());
          allocateRequest_ = null;
        }
        return allocateRequestBuilder_;
      }

      // repeated .hadoop.yarn.ContainerProto allocated_containers = 2;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto> allocatedContainers_ =
        java.util.Collections.emptyList();
      private void ensureAllocatedContainersIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          allocatedContainers_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto>(allocatedContainers_);
          bitField0_ |= 0x00000002;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder> allocatedContainersBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 2;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto> getAllocatedContainersList() {
        if (allocatedContainersBuilder_ == null) {
          return java.util.Collections.unmodifiableList(allocatedContainers_);
        } else {
          return allocatedContainersBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 2;</code>
       */
      public int getAllocatedContainersCount() {
        if (allocatedContainersBuilder_ == null) {
          return allocatedContainers_.size();
        } else {
          return allocatedContainersBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto getAllocatedContainers(int index) {
        if (allocatedContainersBuilder_ == null) {
          return allocatedContainers_.get(index);
        } else {
          return allocatedContainersBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 2;</code>
       */
      public Builder setAllocatedContainers(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto value) {
        if (allocatedContainersBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAllocatedContainersIsMutable();
          allocatedContainers_.set(index, value);
          onChanged();
        } else {
          allocatedContainersBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 2;</code>
       */
      public Builder setAllocatedContainers(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder builderForValue) {
        if (allocatedContainersBuilder_ == null) {
          ensureAllocatedContainersIsMutable();
          allocatedContainers_.set(index, builderForValue.build());
          onChanged();
        } else {
          allocatedContainersBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 2;</code>
       */
      public Builder addAllocatedContainers(org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto value) {
        if (allocatedContainersBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAllocatedContainersIsMutable();
          allocatedContainers_.add(value);
          onChanged();
        } else {
          allocatedContainersBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 2;</code>
       */
      public Builder addAllocatedContainers(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto value) {
        if (allocatedContainersBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAllocatedContainersIsMutable();
          allocatedContainers_.add(index, value);
          onChanged();
        } else {
          allocatedContainersBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 2;</code>
       */
      public Builder addAllocatedContainers(
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder builderForValue) {
        if (allocatedContainersBuilder_ == null) {
          ensureAllocatedContainersIsMutable();
          allocatedContainers_.add(builderForValue.build());
          onChanged();
        } else {
          allocatedContainersBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 2;</code>
       */
      public Builder addAllocatedContainers(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder builderForValue) {
        if (allocatedContainersBuilder_ == null) {
          ensureAllocatedContainersIsMutable();
          allocatedContainers_.add(index, builderForValue.build());
          onChanged();
        } else {
          allocatedContainersBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 2;</code>
       */
      public Builder addAllAllocatedContainers(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto> values) {
        if (allocatedContainersBuilder_ == null) {
          ensureAllocatedContainersIsMutable();
          super.addAll(values, allocatedContainers_);
          onChanged();
        } else {
          allocatedContainersBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 2;</code>
       */
      public Builder clearAllocatedContainers() {
        if (allocatedContainersBuilder_ == null) {
          allocatedContainers_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          allocatedContainersBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 2;</code>
       */
      public Builder removeAllocatedContainers(int index) {
        if (allocatedContainersBuilder_ == null) {
          ensureAllocatedContainersIsMutable();
          allocatedContainers_.remove(index);
          onChanged();
        } else {
          allocatedContainersBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder getAllocatedContainersBuilder(
          int index) {
        return getAllocatedContainersFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder getAllocatedContainersOrBuilder(
          int index) {
        if (allocatedContainersBuilder_ == null) {
          return allocatedContainers_.get(index);  } else {
          return allocatedContainersBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 2;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder> 
           getAllocatedContainersOrBuilderList() {
        if (allocatedContainersBuilder_ != null) {
          return allocatedContainersBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(allocatedContainers_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder addAllocatedContainersBuilder() {
        return getAllocatedContainersFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder addAllocatedContainersBuilder(
          int index) {
        return getAllocatedContainersFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto allocated_containers = 2;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder> 
           getAllocatedContainersBuilderList() {
        return getAllocatedContainersFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder> 
          getAllocatedContainersFieldBuilder() {
        if (allocatedContainersBuilder_ == null) {
          allocatedContainersBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder>(
                  allocatedContainers_,
                  ((bitField0_ & 0x00000002) == 0x00000002),
                  getParentForChildren(),
                  isClean());
          allocatedContainers_ = null;
        }
        return allocatedContainersBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.DistSchedAllocateRequestProto)
    }

    static {
      defaultInstance = new DistSchedAllocateRequestProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.DistSchedAllocateRequestProto)
  }

  public interface NodeLabelsProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;
    /**
     * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto> 
        getNodeLabelsList();
    /**
     * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto getNodeLabels(int index);
    /**
     * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
     */
    int getNodeLabelsCount();
    /**
     * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProtoOrBuilder> 
        getNodeLabelsOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProtoOrBuilder getNodeLabelsOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.NodeLabelsProto}
   */
  public static final class NodeLabelsProto extends
      com.google.protobuf.GeneratedMessage
      implements NodeLabelsProtoOrBuilder {
    // Use NodeLabelsProto.newBuilder() to construct.
    private NodeLabelsProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private NodeLabelsProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final NodeLabelsProto defaultInstance;
    public static NodeLabelsProto getDefaultInstance() {
      return defaultInstance;
    }

    public NodeLabelsProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private NodeLabelsProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                nodeLabels_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto>();
                mutable_bitField0_ |= 0x00000001;
              }
              nodeLabels_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          nodeLabels_ = java.util.Collections.unmodifiableList(nodeLabels_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_NodeLabelsProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_NodeLabelsProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto.Builder.class);
    }

    public static com.google.protobuf.Parser<NodeLabelsProto> PARSER =
        new com.google.protobuf.AbstractParser<NodeLabelsProto>() {
      public NodeLabelsProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new NodeLabelsProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<NodeLabelsProto> getParserForType() {
      return PARSER;
    }

    // repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;
    public static final int NODELABELS_FIELD_NUMBER = 1;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto> nodeLabels_;
    /**
     * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto> getNodeLabelsList() {
      return nodeLabels_;
    }
    /**
     * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProtoOrBuilder> 
        getNodeLabelsOrBuilderList() {
      return nodeLabels_;
    }
    /**
     * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
     */
    public int getNodeLabelsCount() {
      return nodeLabels_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto getNodeLabels(int index) {
      return nodeLabels_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProtoOrBuilder getNodeLabelsOrBuilder(
        int index) {
      return nodeLabels_.get(index);
    }

    private void initFields() {
      nodeLabels_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      for (int i = 0; i < nodeLabels_.size(); i++) {
        output.writeMessage(1, nodeLabels_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < nodeLabels_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, nodeLabels_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto other = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto) obj;

      boolean result = true;
      result = result && getNodeLabelsList()
          .equals(other.getNodeLabelsList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getNodeLabelsCount() > 0) {
        hash = (37 * hash) + NODELABELS_FIELD_NUMBER;
        hash = (53 * hash) + getNodeLabelsList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.NodeLabelsProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_NodeLabelsProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_NodeLabelsProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getNodeLabelsFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (nodeLabelsBuilder_ == null) {
          nodeLabels_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          nodeLabelsBuilder_.clear();
        }
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_NodeLabelsProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto build() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto result = new org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto(this);
        int from_bitField0_ = bitField0_;
        if (nodeLabelsBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            nodeLabels_ = java.util.Collections.unmodifiableList(nodeLabels_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.nodeLabels_ = nodeLabels_;
        } else {
          result.nodeLabels_ = nodeLabelsBuilder_.build();
        }
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto.getDefaultInstance()) return this;
        if (nodeLabelsBuilder_ == null) {
          if (!other.nodeLabels_.isEmpty()) {
            if (nodeLabels_.isEmpty()) {
              nodeLabels_ = other.nodeLabels_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureNodeLabelsIsMutable();
              nodeLabels_.addAll(other.nodeLabels_);
            }
            onChanged();
          }
        } else {
          if (!other.nodeLabels_.isEmpty()) {
            if (nodeLabelsBuilder_.isEmpty()) {
              nodeLabelsBuilder_.dispose();
              nodeLabelsBuilder_ = null;
              nodeLabels_ = other.nodeLabels_;
              bitField0_ = (bitField0_ & ~0x00000001);
              nodeLabelsBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getNodeLabelsFieldBuilder() : null;
            } else {
              nodeLabelsBuilder_.addAllMessages(other.nodeLabels_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto> nodeLabels_ =
        java.util.Collections.emptyList();
      private void ensureNodeLabelsIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          nodeLabels_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto>(nodeLabels_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProtoOrBuilder> nodeLabelsBuilder_;

      /**
       * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto> getNodeLabelsList() {
        if (nodeLabelsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(nodeLabels_);
        } else {
          return nodeLabelsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
       */
      public int getNodeLabelsCount() {
        if (nodeLabelsBuilder_ == null) {
          return nodeLabels_.size();
        } else {
          return nodeLabelsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto getNodeLabels(int index) {
        if (nodeLabelsBuilder_ == null) {
          return nodeLabels_.get(index);
        } else {
          return nodeLabelsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
       */
      public Builder setNodeLabels(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto value) {
        if (nodeLabelsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureNodeLabelsIsMutable();
          nodeLabels_.set(index, value);
          onChanged();
        } else {
          nodeLabelsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
       */
      public Builder setNodeLabels(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto.Builder builderForValue) {
        if (nodeLabelsBuilder_ == null) {
          ensureNodeLabelsIsMutable();
          nodeLabels_.set(index, builderForValue.build());
          onChanged();
        } else {
          nodeLabelsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
       */
      public Builder addNodeLabels(org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto value) {
        if (nodeLabelsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureNodeLabelsIsMutable();
          nodeLabels_.add(value);
          onChanged();
        } else {
          nodeLabelsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
       */
      public Builder addNodeLabels(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto value) {
        if (nodeLabelsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureNodeLabelsIsMutable();
          nodeLabels_.add(index, value);
          onChanged();
        } else {
          nodeLabelsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
       */
      public Builder addNodeLabels(
          org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto.Builder builderForValue) {
        if (nodeLabelsBuilder_ == null) {
          ensureNodeLabelsIsMutable();
          nodeLabels_.add(builderForValue.build());
          onChanged();
        } else {
          nodeLabelsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
       */
      public Builder addNodeLabels(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto.Builder builderForValue) {
        if (nodeLabelsBuilder_ == null) {
          ensureNodeLabelsIsMutable();
          nodeLabels_.add(index, builderForValue.build());
          onChanged();
        } else {
          nodeLabelsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
       */
      public Builder addAllNodeLabels(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto> values) {
        if (nodeLabelsBuilder_ == null) {
          ensureNodeLabelsIsMutable();
          super.addAll(values, nodeLabels_);
          onChanged();
        } else {
          nodeLabelsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
       */
      public Builder clearNodeLabels() {
        if (nodeLabelsBuilder_ == null) {
          nodeLabels_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          nodeLabelsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
       */
      public Builder removeNodeLabels(int index) {
        if (nodeLabelsBuilder_ == null) {
          ensureNodeLabelsIsMutable();
          nodeLabels_.remove(index);
          onChanged();
        } else {
          nodeLabelsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto.Builder getNodeLabelsBuilder(
          int index) {
        return getNodeLabelsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProtoOrBuilder getNodeLabelsOrBuilder(
          int index) {
        if (nodeLabelsBuilder_ == null) {
          return nodeLabels_.get(index);  } else {
          return nodeLabelsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProtoOrBuilder> 
           getNodeLabelsOrBuilderList() {
        if (nodeLabelsBuilder_ != null) {
          return nodeLabelsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(nodeLabels_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto.Builder addNodeLabelsBuilder() {
        return getNodeLabelsFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto.Builder addNodeLabelsBuilder(
          int index) {
        return getNodeLabelsFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.NodeLabelProto nodeLabels = 1;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto.Builder> 
           getNodeLabelsBuilderList() {
        return getNodeLabelsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProtoOrBuilder> 
          getNodeLabelsFieldBuilder() {
        if (nodeLabelsBuilder_ == null) {
          nodeLabelsBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeLabelProtoOrBuilder>(
                  nodeLabels_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          nodeLabels_ = null;
        }
        return nodeLabelsBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.NodeLabelsProto)
    }

    static {
      defaultInstance = new NodeLabelsProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.NodeLabelsProto)
  }

  public interface RegisterNodeManagerRequestProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.NodeIdProto node_id = 1;
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
     */
    boolean hasNodeId();
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId();
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder();

    // optional int32 http_port = 3;
    /**
     * <code>optional int32 http_port = 3;</code>
     */
    boolean hasHttpPort();
    /**
     * <code>optional int32 http_port = 3;</code>
     */
    int getHttpPort();

    // optional .hadoop.yarn.ResourceProto resource = 4;
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
     */
    boolean hasResource();
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource();
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder();

    // optional string nm_version = 5;
    /**
     * <code>optional string nm_version = 5;</code>
     */
    boolean hasNmVersion();
    /**
     * <code>optional string nm_version = 5;</code>
     */
    java.lang.String getNmVersion();
    /**
     * <code>optional string nm_version = 5;</code>
     */
    com.google.protobuf.ByteString
        getNmVersionBytes();

    // repeated .hadoop.yarn.NMContainerStatusProto container_statuses = 6;
    /**
     * <code>repeated .hadoop.yarn.NMContainerStatusProto container_statuses = 6;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto> 
        getContainerStatusesList();
    /**
     * <code>repeated .hadoop.yarn.NMContainerStatusProto container_statuses = 6;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto getContainerStatuses(int index);
    /**
     * <code>repeated .hadoop.yarn.NMContainerStatusProto container_statuses = 6;</code>
     */
    int getContainerStatusesCount();
    /**
     * <code>repeated .hadoop.yarn.NMContainerStatusProto container_statuses = 6;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProtoOrBuilder> 
        getContainerStatusesOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.NMContainerStatusProto container_statuses = 6;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProtoOrBuilder getContainerStatusesOrBuilder(
        int index);

    // repeated .hadoop.yarn.ApplicationIdProto runningApplications = 7;
    /**
     * <code>repeated .hadoop.yarn.ApplicationIdProto runningApplications = 7;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto> 
        getRunningApplicationsList();
    /**
     * <code>repeated .hadoop.yarn.ApplicationIdProto runningApplications = 7;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getRunningApplications(int index);
    /**
     * <code>repeated .hadoop.yarn.ApplicationIdProto runningApplications = 7;</code>
     */
    int getRunningApplicationsCount();
    /**
     * <code>repeated .hadoop.yarn.ApplicationIdProto runningApplications = 7;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> 
        getRunningApplicationsOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ApplicationIdProto runningApplications = 7;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getRunningApplicationsOrBuilder(
        int index);

    // optional .hadoop.yarn.NodeLabelsProto nodeLabels = 8;
    /**
     * <code>optional .hadoop.yarn.NodeLabelsProto nodeLabels = 8;</code>
     */
    boolean hasNodeLabels();
    /**
     * <code>optional .hadoop.yarn.NodeLabelsProto nodeLabels = 8;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto getNodeLabels();
    /**
     * <code>optional .hadoop.yarn.NodeLabelsProto nodeLabels = 8;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProtoOrBuilder getNodeLabelsOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.RegisterNodeManagerRequestProto}
   */
  public static final class RegisterNodeManagerRequestProto extends
      com.google.protobuf.GeneratedMessage
      implements RegisterNodeManagerRequestProtoOrBuilder {
    // Use RegisterNodeManagerRequestProto.newBuilder() to construct.
    private RegisterNodeManagerRequestProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private RegisterNodeManagerRequestProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final RegisterNodeManagerRequestProto defaultInstance;
    public static RegisterNodeManagerRequestProto getDefaultInstance() {
      return defaultInstance;
    }

    public RegisterNodeManagerRequestProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private RegisterNodeManagerRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = nodeId_.toBuilder();
              }
              nodeId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(nodeId_);
                nodeId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 24: {
              bitField0_ |= 0x00000002;
              httpPort_ = input.readInt32();
              break;
            }
            case 34: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = resource_.toBuilder();
              }
              resource_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(resource_);
                resource_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
            case 42: {
              bitField0_ |= 0x00000008;
              nmVersion_ = input.readBytes();
              break;
            }
            case 50: {
              if (!((mutable_bitField0_ & 0x00000010) == 0x00000010)) {
                containerStatuses_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto>();
                mutable_bitField0_ |= 0x00000010;
              }
              containerStatuses_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto.PARSER, extensionRegistry));
              break;
            }
            case 58: {
              if (!((mutable_bitField0_ & 0x00000020) == 0x00000020)) {
                runningApplications_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto>();
                mutable_bitField0_ |= 0x00000020;
              }
              runningApplications_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.PARSER, extensionRegistry));
              break;
            }
            case 66: {
              org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000010) == 0x00000010)) {
                subBuilder = nodeLabels_.toBuilder();
              }
              nodeLabels_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(nodeLabels_);
                nodeLabels_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000010;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000010) == 0x00000010)) {
          containerStatuses_ = java.util.Collections.unmodifiableList(containerStatuses_);
        }
        if (((mutable_bitField0_ & 0x00000020) == 0x00000020)) {
          runningApplications_ = java.util.Collections.unmodifiableList(runningApplications_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_RegisterNodeManagerRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_RegisterNodeManagerRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto.Builder.class);
    }

    public static com.google.protobuf.Parser<RegisterNodeManagerRequestProto> PARSER =
        new com.google.protobuf.AbstractParser<RegisterNodeManagerRequestProto>() {
      public RegisterNodeManagerRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new RegisterNodeManagerRequestProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<RegisterNodeManagerRequestProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.NodeIdProto node_id = 1;
    public static final int NODE_ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto nodeId_;
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
     */
    public boolean hasNodeId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId() {
      return nodeId_;
    }
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder() {
      return nodeId_;
    }

    // optional int32 http_port = 3;
    public static final int HTTP_PORT_FIELD_NUMBER = 3;
    private int httpPort_;
    /**
     * <code>optional int32 http_port = 3;</code>
     */
    public boolean hasHttpPort() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int32 http_port = 3;</code>
     */
    public int getHttpPort() {
      return httpPort_;
    }

    // optional .hadoop.yarn.ResourceProto resource = 4;
    public static final int RESOURCE_FIELD_NUMBER = 4;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto resource_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
     */
    public boolean hasResource() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource() {
      return resource_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder() {
      return resource_;
    }

    // optional string nm_version = 5;
    public static final int NM_VERSION_FIELD_NUMBER = 5;
    private java.lang.Object nmVersion_;
    /**
     * <code>optional string nm_version = 5;</code>
     */
    public boolean hasNmVersion() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional string nm_version = 5;</code>
     */
    public java.lang.String getNmVersion() {
      java.lang.Object ref = nmVersion_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          nmVersion_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string nm_version = 5;</code>
     */
    public com.google.protobuf.ByteString
        getNmVersionBytes() {
      java.lang.Object ref = nmVersion_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        nmVersion_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // repeated .hadoop.yarn.NMContainerStatusProto container_statuses = 6;
    public static final int CONTAINER_STATUSES_FIELD_NUMBER = 6;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto> containerStatuses_;
    /**
     * <code>repeated .hadoop.yarn.NMContainerStatusProto container_statuses = 6;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto> getContainerStatusesList() {
      return containerStatuses_;
    }
    /**
     * <code>repeated .hadoop.yarn.NMContainerStatusProto container_statuses = 6;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProtoOrBuilder> 
        getContainerStatusesOrBuilderList() {
      return containerStatuses_;
    }
    /**
     * <code>repeated .hadoop.yarn.NMContainerStatusProto container_statuses = 6;</code>
     */
    public int getContainerStatusesCount() {
      return containerStatuses_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.NMContainerStatusProto container_statuses = 6;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto getContainerStatuses(int index) {
      return containerStatuses_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.NMContainerStatusProto container_statuses = 6;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProtoOrBuilder getContainerStatusesOrBuilder(
        int index) {
      return containerStatuses_.get(index);
    }

    // repeated .hadoop.yarn.ApplicationIdProto runningApplications = 7;
    public static final int RUNNINGAPPLICATIONS_FIELD_NUMBER = 7;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto> runningApplications_;
    /**
     * <code>repeated .hadoop.yarn.ApplicationIdProto runningApplications = 7;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto> getRunningApplicationsList() {
      return runningApplications_;
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationIdProto runningApplications = 7;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> 
        getRunningApplicationsOrBuilderList() {
      return runningApplications_;
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationIdProto runningApplications = 7;</code>
     */
    public int getRunningApplicationsCount() {
      return runningApplications_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationIdProto runningApplications = 7;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getRunningApplications(int index) {
      return runningApplications_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationIdProto runningApplications = 7;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getRunningApplicationsOrBuilder(
        int index) {
      return runningApplications_.get(index);
    }

    // optional .hadoop.yarn.NodeLabelsProto nodeLabels = 8;
    public static final int NODELABELS_FIELD_NUMBER = 8;
    private org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto nodeLabels_;
    /**
     * <code>optional .hadoop.yarn.NodeLabelsProto nodeLabels = 8;</code>
     */
    public boolean hasNodeLabels() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional .hadoop.yarn.NodeLabelsProto nodeLabels = 8;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto getNodeLabels() {
      return nodeLabels_;
    }
    /**
     * <code>optional .hadoop.yarn.NodeLabelsProto nodeLabels = 8;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProtoOrBuilder getNodeLabelsOrBuilder() {
      return nodeLabels_;
    }

    private void initFields() {
      nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
      httpPort_ = 0;
      resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      nmVersion_ = "";
      containerStatuses_ = java.util.Collections.emptyList();
      runningApplications_ = java.util.Collections.emptyList();
      nodeLabels_ = org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, nodeId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt32(3, httpPort_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(4, resource_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeBytes(5, getNmVersionBytes());
      }
      for (int i = 0; i < containerStatuses_.size(); i++) {
        output.writeMessage(6, containerStatuses_.get(i));
      }
      for (int i = 0; i < runningApplications_.size(); i++) {
        output.writeMessage(7, runningApplications_.get(i));
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeMessage(8, nodeLabels_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, nodeId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(3, httpPort_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, resource_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(5, getNmVersionBytes());
      }
      for (int i = 0; i < containerStatuses_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, containerStatuses_.get(i));
      }
      for (int i = 0; i < runningApplications_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(7, runningApplications_.get(i));
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(8, nodeLabels_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto other = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto) obj;

      boolean result = true;
      result = result && (hasNodeId() == other.hasNodeId());
      if (hasNodeId()) {
        result = result && getNodeId()
            .equals(other.getNodeId());
      }
      result = result && (hasHttpPort() == other.hasHttpPort());
      if (hasHttpPort()) {
        result = result && (getHttpPort()
            == other.getHttpPort());
      }
      result = result && (hasResource() == other.hasResource());
      if (hasResource()) {
        result = result && getResource()
            .equals(other.getResource());
      }
      result = result && (hasNmVersion() == other.hasNmVersion());
      if (hasNmVersion()) {
        result = result && getNmVersion()
            .equals(other.getNmVersion());
      }
      result = result && getContainerStatusesList()
          .equals(other.getContainerStatusesList());
      result = result && getRunningApplicationsList()
          .equals(other.getRunningApplicationsList());
      result = result && (hasNodeLabels() == other.hasNodeLabels());
      if (hasNodeLabels()) {
        result = result && getNodeLabels()
            .equals(other.getNodeLabels());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasNodeId()) {
        hash = (37 * hash) + NODE_ID_FIELD_NUMBER;
        hash = (53 * hash) + getNodeId().hashCode();
      }
      if (hasHttpPort()) {
        hash = (37 * hash) + HTTP_PORT_FIELD_NUMBER;
        hash = (53 * hash) + getHttpPort();
      }
      if (hasResource()) {
        hash = (37 * hash) + RESOURCE_FIELD_NUMBER;
        hash = (53 * hash) + getResource().hashCode();
      }
      if (hasNmVersion()) {
        hash = (37 * hash) + NM_VERSION_FIELD_NUMBER;
        hash = (53 * hash) + getNmVersion().hashCode();
      }
      if (getContainerStatusesCount() > 0) {
        hash = (37 * hash) + CONTAINER_STATUSES_FIELD_NUMBER;
        hash = (53 * hash) + getContainerStatusesList().hashCode();
      }
      if (getRunningApplicationsCount() > 0) {
        hash = (37 * hash) + RUNNINGAPPLICATIONS_FIELD_NUMBER;
        hash = (53 * hash) + getRunningApplicationsList().hashCode();
      }
      if (hasNodeLabels()) {
        hash = (37 * hash) + NODELABELS_FIELD_NUMBER;
        hash = (53 * hash) + getNodeLabels().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.RegisterNodeManagerRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_RegisterNodeManagerRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_RegisterNodeManagerRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getNodeIdFieldBuilder();
          getResourceFieldBuilder();
          getContainerStatusesFieldBuilder();
          getRunningApplicationsFieldBuilder();
          getNodeLabelsFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (nodeIdBuilder_ == null) {
          nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
        } else {
          nodeIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        httpPort_ = 0;
        bitField0_ = (bitField0_ & ~0x00000002);
        if (resourceBuilder_ == null) {
          resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        nmVersion_ = "";
        bitField0_ = (bitField0_ & ~0x00000008);
        if (containerStatusesBuilder_ == null) {
          containerStatuses_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000010);
        } else {
          containerStatusesBuilder_.clear();
        }
        if (runningApplicationsBuilder_ == null) {
          runningApplications_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000020);
        } else {
          runningApplicationsBuilder_.clear();
        }
        if (nodeLabelsBuilder_ == null) {
          nodeLabels_ = org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto.getDefaultInstance();
        } else {
          nodeLabelsBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000040);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_RegisterNodeManagerRequestProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto build() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto result = new org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (nodeIdBuilder_ == null) {
          result.nodeId_ = nodeId_;
        } else {
          result.nodeId_ = nodeIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.httpPort_ = httpPort_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (resourceBuilder_ == null) {
          result.resource_ = resource_;
        } else {
          result.resource_ = resourceBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.nmVersion_ = nmVersion_;
        if (containerStatusesBuilder_ == null) {
          if (((bitField0_ & 0x00000010) == 0x00000010)) {
            containerStatuses_ = java.util.Collections.unmodifiableList(containerStatuses_);
            bitField0_ = (bitField0_ & ~0x00000010);
          }
          result.containerStatuses_ = containerStatuses_;
        } else {
          result.containerStatuses_ = containerStatusesBuilder_.build();
        }
        if (runningApplicationsBuilder_ == null) {
          if (((bitField0_ & 0x00000020) == 0x00000020)) {
            runningApplications_ = java.util.Collections.unmodifiableList(runningApplications_);
            bitField0_ = (bitField0_ & ~0x00000020);
          }
          result.runningApplications_ = runningApplications_;
        } else {
          result.runningApplications_ = runningApplicationsBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
          to_bitField0_ |= 0x00000010;
        }
        if (nodeLabelsBuilder_ == null) {
          result.nodeLabels_ = nodeLabels_;
        } else {
          result.nodeLabels_ = nodeLabelsBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto.getDefaultInstance()) return this;
        if (other.hasNodeId()) {
          mergeNodeId(other.getNodeId());
        }
        if (other.hasHttpPort()) {
          setHttpPort(other.getHttpPort());
        }
        if (other.hasResource()) {
          mergeResource(other.getResource());
        }
        if (other.hasNmVersion()) {
          bitField0_ |= 0x00000008;
          nmVersion_ = other.nmVersion_;
          onChanged();
        }
        if (containerStatusesBuilder_ == null) {
          if (!other.containerStatuses_.isEmpty()) {
            if (containerStatuses_.isEmpty()) {
              containerStatuses_ = other.containerStatuses_;
              bitField0_ = (bitField0_ & ~0x00000010);
            } else {
              ensureContainerStatusesIsMutable();
              containerStatuses_.addAll(other.containerStatuses_);
            }
            onChanged();
          }
        } else {
          if (!other.containerStatuses_.isEmpty()) {
            if (containerStatusesBuilder_.isEmpty()) {
              containerStatusesBuilder_.dispose();
              containerStatusesBuilder_ = null;
              containerStatuses_ = other.containerStatuses_;
              bitField0_ = (bitField0_ & ~0x00000010);
              containerStatusesBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getContainerStatusesFieldBuilder() : null;
            } else {
              containerStatusesBuilder_.addAllMessages(other.containerStatuses_);
            }
          }
        }
        if (runningApplicationsBuilder_ == null) {
          if (!other.runningApplications_.isEmpty()) {
            if (runningApplications_.isEmpty()) {
              runningApplications_ = other.runningApplications_;
              bitField0_ = (bitField0_ & ~0x00000020);
            } else {
              ensureRunningApplicationsIsMutable();
              runningApplications_.addAll(other.runningApplications_);
            }
            onChanged();
          }
        } else {
          if (!other.runningApplications_.isEmpty()) {
            if (runningApplicationsBuilder_.isEmpty()) {
              runningApplicationsBuilder_.dispose();
              runningApplicationsBuilder_ = null;
              runningApplications_ = other.runningApplications_;
              bitField0_ = (bitField0_ & ~0x00000020);
              runningApplicationsBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getRunningApplicationsFieldBuilder() : null;
            } else {
              runningApplicationsBuilder_.addAllMessages(other.runningApplications_);
            }
          }
        }
        if (other.hasNodeLabels()) {
          mergeNodeLabels(other.getNodeLabels());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerRequestProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.NodeIdProto node_id = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> nodeIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public boolean hasNodeId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId() {
        if (nodeIdBuilder_ == null) {
          return nodeId_;
        } else {
          return nodeIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public Builder setNodeId(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodeIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          nodeId_ = value;
          onChanged();
        } else {
          nodeIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public Builder setNodeId(
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder builderForValue) {
        if (nodeIdBuilder_ == null) {
          nodeId_ = builderForValue.build();
          onChanged();
        } else {
          nodeIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public Builder mergeNodeId(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodeIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              nodeId_ != org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance()) {
            nodeId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.newBuilder(nodeId_).mergeFrom(value).buildPartial();
          } else {
            nodeId_ = value;
          }
          onChanged();
        } else {
          nodeIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public Builder clearNodeId() {
        if (nodeIdBuilder_ == null) {
          nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
          onChanged();
        } else {
          nodeIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder getNodeIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getNodeIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder() {
        if (nodeIdBuilder_ != null) {
          return nodeIdBuilder_.getMessageOrBuilder();
        } else {
          return nodeId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> 
          getNodeIdFieldBuilder() {
        if (nodeIdBuilder_ == null) {
          nodeIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder>(
                  nodeId_,
                  getParentForChildren(),
                  isClean());
          nodeId_ = null;
        }
        return nodeIdBuilder_;
      }

      // optional int32 http_port = 3;
      private int httpPort_ ;
      /**
       * <code>optional int32 http_port = 3;</code>
       */
      public boolean hasHttpPort() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional int32 http_port = 3;</code>
       */
      public int getHttpPort() {
        return httpPort_;
      }
      /**
       * <code>optional int32 http_port = 3;</code>
       */
      public Builder setHttpPort(int value) {
        bitField0_ |= 0x00000002;
        httpPort_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 http_port = 3;</code>
       */
      public Builder clearHttpPort() {
        bitField0_ = (bitField0_ & ~0x00000002);
        httpPort_ = 0;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.ResourceProto resource = 4;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> resourceBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
       */
      public boolean hasResource() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource() {
        if (resourceBuilder_ == null) {
          return resource_;
        } else {
          return resourceBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
       */
      public Builder setResource(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (resourceBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          resource_ = value;
          onChanged();
        } else {
          resourceBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
       */
      public Builder setResource(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (resourceBuilder_ == null) {
          resource_ = builderForValue.build();
          onChanged();
        } else {
          resourceBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
       */
      public Builder mergeResource(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (resourceBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              resource_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            resource_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(resource_).mergeFrom(value).buildPartial();
          } else {
            resource_ = value;
          }
          onChanged();
        } else {
          resourceBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
       */
      public Builder clearResource() {
        if (resourceBuilder_ == null) {
          resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
          onChanged();
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getResourceBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getResourceFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder() {
        if (resourceBuilder_ != null) {
          return resourceBuilder_.getMessageOrBuilder();
        } else {
          return resource_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getResourceFieldBuilder() {
        if (resourceBuilder_ == null) {
          resourceBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  resource_,
                  getParentForChildren(),
                  isClean());
          resource_ = null;
        }
        return resourceBuilder_;
      }

      // optional string nm_version = 5;
      private java.lang.Object nmVersion_ = "";
      /**
       * <code>optional string nm_version = 5;</code>
       */
      public boolean hasNmVersion() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional string nm_version = 5;</code>
       */
      public java.lang.String getNmVersion() {
        java.lang.Object ref = nmVersion_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          nmVersion_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string nm_version = 5;</code>
       */
      public com.google.protobuf.ByteString
          getNmVersionBytes() {
        java.lang.Object ref = nmVersion_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          nmVersion_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string nm_version = 5;</code>
       */
      public Builder setNmVersion(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000008;
        nmVersion_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string nm_version = 5;</code>
       */
      public Builder clearNmVersion() {
        bitField0_ = (bitField0_ & ~0x00000008);
        nmVersion_ = getDefaultInstance().getNmVersion();
        onChanged();
        return this;
      }
      /**
       * <code>optional string nm_version = 5;</code>
       */
      public Builder setNmVersionBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000008;
        nmVersion_ = value;
        onChanged();
        return this;
      }

      // repeated .hadoop.yarn.NMContainerStatusProto container_statuses = 6;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto> containerStatuses_ =
        java.util.Collections.emptyList();
      private void ensureContainerStatusesIsMutable() {
        if (!((bitField0_ & 0x00000010) == 0x00000010)) {
          containerStatuses_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto>(containerStatuses_);
          bitField0_ |= 0x00000010;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProtoOrBuilder> containerStatusesBuilder_;

      /**
       * <code>repeated .hadoop.yarn.NMContainerStatusProto container_statuses = 6;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto> getContainerStatusesList() {
        if (containerStatusesBuilder_ == null) {
          return java.util.Collections.unmodifiableList(containerStatuses_);
        } else {
          return containerStatusesBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NMContainerStatusProto container_statuses = 6;</code>
       */
      public int getContainerStatusesCount() {
        if (containerStatusesBuilder_ == null) {
          return containerStatuses_.size();
        } else {
          return containerStatusesBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NMContainerStatusProto container_statuses = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto getContainerStatuses(int index) {
        if (containerStatusesBuilder_ == null) {
          return containerStatuses_.get(index);
        } else {
          return containerStatusesBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NMContainerStatusProto container_statuses = 6;</code>
       */
      public Builder setContainerStatuses(
          int index, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto value) {
        if (containerStatusesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainerStatusesIsMutable();
          containerStatuses_.set(index, value);
          onChanged();
        } else {
          containerStatusesBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NMContainerStatusProto container_statuses = 6;</code>
       */
      public Builder setContainerStatuses(
          int index, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto.Builder builderForValue) {
        if (containerStatusesBuilder_ == null) {
          ensureContainerStatusesIsMutable();
          containerStatuses_.set(index, builderForValue.build());
          onChanged();
        } else {
          containerStatusesBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NMContainerStatusProto container_statuses = 6;</code>
       */
      public Builder addContainerStatuses(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto value) {
        if (containerStatusesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainerStatusesIsMutable();
          containerStatuses_.add(value);
          onChanged();
        } else {
          containerStatusesBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NMContainerStatusProto container_statuses = 6;</code>
       */
      public Builder addContainerStatuses(
          int index, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto value) {
        if (containerStatusesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainerStatusesIsMutable();
          containerStatuses_.add(index, value);
          onChanged();
        } else {
          containerStatusesBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NMContainerStatusProto container_statuses = 6;</code>
       */
      public Builder addContainerStatuses(
          org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto.Builder builderForValue) {
        if (containerStatusesBuilder_ == null) {
          ensureContainerStatusesIsMutable();
          containerStatuses_.add(builderForValue.build());
          onChanged();
        } else {
          containerStatusesBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NMContainerStatusProto container_statuses = 6;</code>
       */
      public Builder addContainerStatuses(
          int index, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto.Builder builderForValue) {
        if (containerStatusesBuilder_ == null) {
          ensureContainerStatusesIsMutable();
          containerStatuses_.add(index, builderForValue.build());
          onChanged();
        } else {
          containerStatusesBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NMContainerStatusProto container_statuses = 6;</code>
       */
      public Builder addAllContainerStatuses(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto> values) {
        if (containerStatusesBuilder_ == null) {
          ensureContainerStatusesIsMutable();
          super.addAll(values, containerStatuses_);
          onChanged();
        } else {
          containerStatusesBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NMContainerStatusProto container_statuses = 6;</code>
       */
      public Builder clearContainerStatuses() {
        if (containerStatusesBuilder_ == null) {
          containerStatuses_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000010);
          onChanged();
        } else {
          containerStatusesBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NMContainerStatusProto container_statuses = 6;</code>
       */
      public Builder removeContainerStatuses(int index) {
        if (containerStatusesBuilder_ == null) {
          ensureContainerStatusesIsMutable();
          containerStatuses_.remove(index);
          onChanged();
        } else {
          containerStatusesBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.NMContainerStatusProto container_statuses = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto.Builder getContainerStatusesBuilder(
          int index) {
        return getContainerStatusesFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.NMContainerStatusProto container_statuses = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProtoOrBuilder getContainerStatusesOrBuilder(
          int index) {
        if (containerStatusesBuilder_ == null) {
          return containerStatuses_.get(index);  } else {
          return containerStatusesBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NMContainerStatusProto container_statuses = 6;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProtoOrBuilder> 
           getContainerStatusesOrBuilderList() {
        if (containerStatusesBuilder_ != null) {
          return containerStatusesBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(containerStatuses_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.NMContainerStatusProto container_statuses = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto.Builder addContainerStatusesBuilder() {
        return getContainerStatusesFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.NMContainerStatusProto container_statuses = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto.Builder addContainerStatusesBuilder(
          int index) {
        return getContainerStatusesFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.NMContainerStatusProto container_statuses = 6;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto.Builder> 
           getContainerStatusesBuilderList() {
        return getContainerStatusesFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProtoOrBuilder> 
          getContainerStatusesFieldBuilder() {
        if (containerStatusesBuilder_ == null) {
          containerStatusesBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProtoOrBuilder>(
                  containerStatuses_,
                  ((bitField0_ & 0x00000010) == 0x00000010),
                  getParentForChildren(),
                  isClean());
          containerStatuses_ = null;
        }
        return containerStatusesBuilder_;
      }

      // repeated .hadoop.yarn.ApplicationIdProto runningApplications = 7;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto> runningApplications_ =
        java.util.Collections.emptyList();
      private void ensureRunningApplicationsIsMutable() {
        if (!((bitField0_ & 0x00000020) == 0x00000020)) {
          runningApplications_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto>(runningApplications_);
          bitField0_ |= 0x00000020;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> runningApplicationsBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto runningApplications = 7;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto> getRunningApplicationsList() {
        if (runningApplicationsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(runningApplications_);
        } else {
          return runningApplicationsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto runningApplications = 7;</code>
       */
      public int getRunningApplicationsCount() {
        if (runningApplicationsBuilder_ == null) {
          return runningApplications_.size();
        } else {
          return runningApplicationsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto runningApplications = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getRunningApplications(int index) {
        if (runningApplicationsBuilder_ == null) {
          return runningApplications_.get(index);
        } else {
          return runningApplicationsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto runningApplications = 7;</code>
       */
      public Builder setRunningApplications(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (runningApplicationsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRunningApplicationsIsMutable();
          runningApplications_.set(index, value);
          onChanged();
        } else {
          runningApplicationsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto runningApplications = 7;</code>
       */
      public Builder setRunningApplications(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder builderForValue) {
        if (runningApplicationsBuilder_ == null) {
          ensureRunningApplicationsIsMutable();
          runningApplications_.set(index, builderForValue.build());
          onChanged();
        } else {
          runningApplicationsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto runningApplications = 7;</code>
       */
      public Builder addRunningApplications(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (runningApplicationsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRunningApplicationsIsMutable();
          runningApplications_.add(value);
          onChanged();
        } else {
          runningApplicationsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto runningApplications = 7;</code>
       */
      public Builder addRunningApplications(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (runningApplicationsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRunningApplicationsIsMutable();
          runningApplications_.add(index, value);
          onChanged();
        } else {
          runningApplicationsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto runningApplications = 7;</code>
       */
      public Builder addRunningApplications(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder builderForValue) {
        if (runningApplicationsBuilder_ == null) {
          ensureRunningApplicationsIsMutable();
          runningApplications_.add(builderForValue.build());
          onChanged();
        } else {
          runningApplicationsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto runningApplications = 7;</code>
       */
      public Builder addRunningApplications(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder builderForValue) {
        if (runningApplicationsBuilder_ == null) {
          ensureRunningApplicationsIsMutable();
          runningApplications_.add(index, builderForValue.build());
          onChanged();
        } else {
          runningApplicationsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto runningApplications = 7;</code>
       */
      public Builder addAllRunningApplications(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto> values) {
        if (runningApplicationsBuilder_ == null) {
          ensureRunningApplicationsIsMutable();
          super.addAll(values, runningApplications_);
          onChanged();
        } else {
          runningApplicationsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto runningApplications = 7;</code>
       */
      public Builder clearRunningApplications() {
        if (runningApplicationsBuilder_ == null) {
          runningApplications_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000020);
          onChanged();
        } else {
          runningApplicationsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto runningApplications = 7;</code>
       */
      public Builder removeRunningApplications(int index) {
        if (runningApplicationsBuilder_ == null) {
          ensureRunningApplicationsIsMutable();
          runningApplications_.remove(index);
          onChanged();
        } else {
          runningApplicationsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto runningApplications = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder getRunningApplicationsBuilder(
          int index) {
        return getRunningApplicationsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto runningApplications = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getRunningApplicationsOrBuilder(
          int index) {
        if (runningApplicationsBuilder_ == null) {
          return runningApplications_.get(index);  } else {
          return runningApplicationsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto runningApplications = 7;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> 
           getRunningApplicationsOrBuilderList() {
        if (runningApplicationsBuilder_ != null) {
          return runningApplicationsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(runningApplications_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto runningApplications = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder addRunningApplicationsBuilder() {
        return getRunningApplicationsFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto runningApplications = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder addRunningApplicationsBuilder(
          int index) {
        return getRunningApplicationsFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto runningApplications = 7;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder> 
           getRunningApplicationsBuilderList() {
        return getRunningApplicationsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> 
          getRunningApplicationsFieldBuilder() {
        if (runningApplicationsBuilder_ == null) {
          runningApplicationsBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder>(
                  runningApplications_,
                  ((bitField0_ & 0x00000020) == 0x00000020),
                  getParentForChildren(),
                  isClean());
          runningApplications_ = null;
        }
        return runningApplicationsBuilder_;
      }

      // optional .hadoop.yarn.NodeLabelsProto nodeLabels = 8;
      private org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto nodeLabels_ = org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProtoOrBuilder> nodeLabelsBuilder_;
      /**
       * <code>optional .hadoop.yarn.NodeLabelsProto nodeLabels = 8;</code>
       */
      public boolean hasNodeLabels() {
        return ((bitField0_ & 0x00000040) == 0x00000040);
      }
      /**
       * <code>optional .hadoop.yarn.NodeLabelsProto nodeLabels = 8;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto getNodeLabels() {
        if (nodeLabelsBuilder_ == null) {
          return nodeLabels_;
        } else {
          return nodeLabelsBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeLabelsProto nodeLabels = 8;</code>
       */
      public Builder setNodeLabels(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto value) {
        if (nodeLabelsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          nodeLabels_ = value;
          onChanged();
        } else {
          nodeLabelsBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000040;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeLabelsProto nodeLabels = 8;</code>
       */
      public Builder setNodeLabels(
          org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto.Builder builderForValue) {
        if (nodeLabelsBuilder_ == null) {
          nodeLabels_ = builderForValue.build();
          onChanged();
        } else {
          nodeLabelsBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000040;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeLabelsProto nodeLabels = 8;</code>
       */
      public Builder mergeNodeLabels(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto value) {
        if (nodeLabelsBuilder_ == null) {
          if (((bitField0_ & 0x00000040) == 0x00000040) &&
              nodeLabels_ != org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto.getDefaultInstance()) {
            nodeLabels_ =
              org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto.newBuilder(nodeLabels_).mergeFrom(value).buildPartial();
          } else {
            nodeLabels_ = value;
          }
          onChanged();
        } else {
          nodeLabelsBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000040;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeLabelsProto nodeLabels = 8;</code>
       */
      public Builder clearNodeLabels() {
        if (nodeLabelsBuilder_ == null) {
          nodeLabels_ = org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto.getDefaultInstance();
          onChanged();
        } else {
          nodeLabelsBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000040);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeLabelsProto nodeLabels = 8;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto.Builder getNodeLabelsBuilder() {
        bitField0_ |= 0x00000040;
        onChanged();
        return getNodeLabelsFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.NodeLabelsProto nodeLabels = 8;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProtoOrBuilder getNodeLabelsOrBuilder() {
        if (nodeLabelsBuilder_ != null) {
          return nodeLabelsBuilder_.getMessageOrBuilder();
        } else {
          return nodeLabels_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeLabelsProto nodeLabels = 8;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProtoOrBuilder> 
          getNodeLabelsFieldBuilder() {
        if (nodeLabelsBuilder_ == null) {
          nodeLabelsBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProtoOrBuilder>(
                  nodeLabels_,
                  getParentForChildren(),
                  isClean());
          nodeLabels_ = null;
        }
        return nodeLabelsBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.RegisterNodeManagerRequestProto)
    }

    static {
      defaultInstance = new RegisterNodeManagerRequestProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.RegisterNodeManagerRequestProto)
  }

  public interface RegisterNodeManagerResponseProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.MasterKeyProto container_token_master_key = 1;
    /**
     * <code>optional .hadoop.yarn.MasterKeyProto container_token_master_key = 1;</code>
     */
    boolean hasContainerTokenMasterKey();
    /**
     * <code>optional .hadoop.yarn.MasterKeyProto container_token_master_key = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto getContainerTokenMasterKey();
    /**
     * <code>optional .hadoop.yarn.MasterKeyProto container_token_master_key = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProtoOrBuilder getContainerTokenMasterKeyOrBuilder();

    // optional .hadoop.yarn.MasterKeyProto nm_token_master_key = 2;
    /**
     * <code>optional .hadoop.yarn.MasterKeyProto nm_token_master_key = 2;</code>
     */
    boolean hasNmTokenMasterKey();
    /**
     * <code>optional .hadoop.yarn.MasterKeyProto nm_token_master_key = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto getNmTokenMasterKey();
    /**
     * <code>optional .hadoop.yarn.MasterKeyProto nm_token_master_key = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProtoOrBuilder getNmTokenMasterKeyOrBuilder();

    // optional .hadoop.yarn.NodeActionProto nodeAction = 3;
    /**
     * <code>optional .hadoop.yarn.NodeActionProto nodeAction = 3;</code>
     */
    boolean hasNodeAction();
    /**
     * <code>optional .hadoop.yarn.NodeActionProto nodeAction = 3;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeActionProto getNodeAction();

    // optional int64 rm_identifier = 4;
    /**
     * <code>optional int64 rm_identifier = 4;</code>
     */
    boolean hasRmIdentifier();
    /**
     * <code>optional int64 rm_identifier = 4;</code>
     */
    long getRmIdentifier();

    // optional string diagnostics_message = 5;
    /**
     * <code>optional string diagnostics_message = 5;</code>
     */
    boolean hasDiagnosticsMessage();
    /**
     * <code>optional string diagnostics_message = 5;</code>
     */
    java.lang.String getDiagnosticsMessage();
    /**
     * <code>optional string diagnostics_message = 5;</code>
     */
    com.google.protobuf.ByteString
        getDiagnosticsMessageBytes();

    // optional string rm_version = 6;
    /**
     * <code>optional string rm_version = 6;</code>
     */
    boolean hasRmVersion();
    /**
     * <code>optional string rm_version = 6;</code>
     */
    java.lang.String getRmVersion();
    /**
     * <code>optional string rm_version = 6;</code>
     */
    com.google.protobuf.ByteString
        getRmVersionBytes();

    // optional bool areNodeLabelsAcceptedByRM = 7 [default = false];
    /**
     * <code>optional bool areNodeLabelsAcceptedByRM = 7 [default = false];</code>
     */
    boolean hasAreNodeLabelsAcceptedByRM();
    /**
     * <code>optional bool areNodeLabelsAcceptedByRM = 7 [default = false];</code>
     */
    boolean getAreNodeLabelsAcceptedByRM();

    // optional .hadoop.yarn.ResourceProto resource = 8;
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 8;</code>
     */
    boolean hasResource();
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 8;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource();
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 8;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.RegisterNodeManagerResponseProto}
   */
  public static final class RegisterNodeManagerResponseProto extends
      com.google.protobuf.GeneratedMessage
      implements RegisterNodeManagerResponseProtoOrBuilder {
    // Use RegisterNodeManagerResponseProto.newBuilder() to construct.
    private RegisterNodeManagerResponseProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private RegisterNodeManagerResponseProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final RegisterNodeManagerResponseProto defaultInstance;
    public static RegisterNodeManagerResponseProto getDefaultInstance() {
      return defaultInstance;
    }

    public RegisterNodeManagerResponseProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private RegisterNodeManagerResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = containerTokenMasterKey_.toBuilder();
              }
              containerTokenMasterKey_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(containerTokenMasterKey_);
                containerTokenMasterKey_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = nmTokenMasterKey_.toBuilder();
              }
              nmTokenMasterKey_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(nmTokenMasterKey_);
                nmTokenMasterKey_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 24: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeActionProto value = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeActionProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(3, rawValue);
              } else {
                bitField0_ |= 0x00000004;
                nodeAction_ = value;
              }
              break;
            }
            case 32: {
              bitField0_ |= 0x00000008;
              rmIdentifier_ = input.readInt64();
              break;
            }
            case 42: {
              bitField0_ |= 0x00000010;
              diagnosticsMessage_ = input.readBytes();
              break;
            }
            case 50: {
              bitField0_ |= 0x00000020;
              rmVersion_ = input.readBytes();
              break;
            }
            case 56: {
              bitField0_ |= 0x00000040;
              areNodeLabelsAcceptedByRM_ = input.readBool();
              break;
            }
            case 66: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000080) == 0x00000080)) {
                subBuilder = resource_.toBuilder();
              }
              resource_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(resource_);
                resource_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000080;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_RegisterNodeManagerResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_RegisterNodeManagerResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto.Builder.class);
    }

    public static com.google.protobuf.Parser<RegisterNodeManagerResponseProto> PARSER =
        new com.google.protobuf.AbstractParser<RegisterNodeManagerResponseProto>() {
      public RegisterNodeManagerResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new RegisterNodeManagerResponseProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<RegisterNodeManagerResponseProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.MasterKeyProto container_token_master_key = 1;
    public static final int CONTAINER_TOKEN_MASTER_KEY_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto containerTokenMasterKey_;
    /**
     * <code>optional .hadoop.yarn.MasterKeyProto container_token_master_key = 1;</code>
     */
    public boolean hasContainerTokenMasterKey() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.MasterKeyProto container_token_master_key = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto getContainerTokenMasterKey() {
      return containerTokenMasterKey_;
    }
    /**
     * <code>optional .hadoop.yarn.MasterKeyProto container_token_master_key = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProtoOrBuilder getContainerTokenMasterKeyOrBuilder() {
      return containerTokenMasterKey_;
    }

    // optional .hadoop.yarn.MasterKeyProto nm_token_master_key = 2;
    public static final int NM_TOKEN_MASTER_KEY_FIELD_NUMBER = 2;
    private org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto nmTokenMasterKey_;
    /**
     * <code>optional .hadoop.yarn.MasterKeyProto nm_token_master_key = 2;</code>
     */
    public boolean hasNmTokenMasterKey() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.MasterKeyProto nm_token_master_key = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto getNmTokenMasterKey() {
      return nmTokenMasterKey_;
    }
    /**
     * <code>optional .hadoop.yarn.MasterKeyProto nm_token_master_key = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProtoOrBuilder getNmTokenMasterKeyOrBuilder() {
      return nmTokenMasterKey_;
    }

    // optional .hadoop.yarn.NodeActionProto nodeAction = 3;
    public static final int NODEACTION_FIELD_NUMBER = 3;
    private org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeActionProto nodeAction_;
    /**
     * <code>optional .hadoop.yarn.NodeActionProto nodeAction = 3;</code>
     */
    public boolean hasNodeAction() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional .hadoop.yarn.NodeActionProto nodeAction = 3;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeActionProto getNodeAction() {
      return nodeAction_;
    }

    // optional int64 rm_identifier = 4;
    public static final int RM_IDENTIFIER_FIELD_NUMBER = 4;
    private long rmIdentifier_;
    /**
     * <code>optional int64 rm_identifier = 4;</code>
     */
    public boolean hasRmIdentifier() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional int64 rm_identifier = 4;</code>
     */
    public long getRmIdentifier() {
      return rmIdentifier_;
    }

    // optional string diagnostics_message = 5;
    public static final int DIAGNOSTICS_MESSAGE_FIELD_NUMBER = 5;
    private java.lang.Object diagnosticsMessage_;
    /**
     * <code>optional string diagnostics_message = 5;</code>
     */
    public boolean hasDiagnosticsMessage() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional string diagnostics_message = 5;</code>
     */
    public java.lang.String getDiagnosticsMessage() {
      java.lang.Object ref = diagnosticsMessage_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          diagnosticsMessage_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string diagnostics_message = 5;</code>
     */
    public com.google.protobuf.ByteString
        getDiagnosticsMessageBytes() {
      java.lang.Object ref = diagnosticsMessage_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        diagnosticsMessage_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional string rm_version = 6;
    public static final int RM_VERSION_FIELD_NUMBER = 6;
    private java.lang.Object rmVersion_;
    /**
     * <code>optional string rm_version = 6;</code>
     */
    public boolean hasRmVersion() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional string rm_version = 6;</code>
     */
    public java.lang.String getRmVersion() {
      java.lang.Object ref = rmVersion_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          rmVersion_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string rm_version = 6;</code>
     */
    public com.google.protobuf.ByteString
        getRmVersionBytes() {
      java.lang.Object ref = rmVersion_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        rmVersion_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional bool areNodeLabelsAcceptedByRM = 7 [default = false];
    public static final int ARENODELABELSACCEPTEDBYRM_FIELD_NUMBER = 7;
    private boolean areNodeLabelsAcceptedByRM_;
    /**
     * <code>optional bool areNodeLabelsAcceptedByRM = 7 [default = false];</code>
     */
    public boolean hasAreNodeLabelsAcceptedByRM() {
      return ((bitField0_ & 0x00000040) == 0x00000040);
    }
    /**
     * <code>optional bool areNodeLabelsAcceptedByRM = 7 [default = false];</code>
     */
    public boolean getAreNodeLabelsAcceptedByRM() {
      return areNodeLabelsAcceptedByRM_;
    }

    // optional .hadoop.yarn.ResourceProto resource = 8;
    public static final int RESOURCE_FIELD_NUMBER = 8;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto resource_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 8;</code>
     */
    public boolean hasResource() {
      return ((bitField0_ & 0x00000080) == 0x00000080);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 8;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource() {
      return resource_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 8;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder() {
      return resource_;
    }

    private void initFields() {
      containerTokenMasterKey_ = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.getDefaultInstance();
      nmTokenMasterKey_ = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.getDefaultInstance();
      nodeAction_ = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeActionProto.NORMAL;
      rmIdentifier_ = 0L;
      diagnosticsMessage_ = "";
      rmVersion_ = "";
      areNodeLabelsAcceptedByRM_ = false;
      resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, containerTokenMasterKey_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, nmTokenMasterKey_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeEnum(3, nodeAction_.getNumber());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeInt64(4, rmIdentifier_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeBytes(5, getDiagnosticsMessageBytes());
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeBytes(6, getRmVersionBytes());
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        output.writeBool(7, areNodeLabelsAcceptedByRM_);
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        output.writeMessage(8, resource_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, containerTokenMasterKey_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, nmTokenMasterKey_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(3, nodeAction_.getNumber());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(4, rmIdentifier_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(5, getDiagnosticsMessageBytes());
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(6, getRmVersionBytes());
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(7, areNodeLabelsAcceptedByRM_);
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(8, resource_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto other = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto) obj;

      boolean result = true;
      result = result && (hasContainerTokenMasterKey() == other.hasContainerTokenMasterKey());
      if (hasContainerTokenMasterKey()) {
        result = result && getContainerTokenMasterKey()
            .equals(other.getContainerTokenMasterKey());
      }
      result = result && (hasNmTokenMasterKey() == other.hasNmTokenMasterKey());
      if (hasNmTokenMasterKey()) {
        result = result && getNmTokenMasterKey()
            .equals(other.getNmTokenMasterKey());
      }
      result = result && (hasNodeAction() == other.hasNodeAction());
      if (hasNodeAction()) {
        result = result &&
            (getNodeAction() == other.getNodeAction());
      }
      result = result && (hasRmIdentifier() == other.hasRmIdentifier());
      if (hasRmIdentifier()) {
        result = result && (getRmIdentifier()
            == other.getRmIdentifier());
      }
      result = result && (hasDiagnosticsMessage() == other.hasDiagnosticsMessage());
      if (hasDiagnosticsMessage()) {
        result = result && getDiagnosticsMessage()
            .equals(other.getDiagnosticsMessage());
      }
      result = result && (hasRmVersion() == other.hasRmVersion());
      if (hasRmVersion()) {
        result = result && getRmVersion()
            .equals(other.getRmVersion());
      }
      result = result && (hasAreNodeLabelsAcceptedByRM() == other.hasAreNodeLabelsAcceptedByRM());
      if (hasAreNodeLabelsAcceptedByRM()) {
        result = result && (getAreNodeLabelsAcceptedByRM()
            == other.getAreNodeLabelsAcceptedByRM());
      }
      result = result && (hasResource() == other.hasResource());
      if (hasResource()) {
        result = result && getResource()
            .equals(other.getResource());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasContainerTokenMasterKey()) {
        hash = (37 * hash) + CONTAINER_TOKEN_MASTER_KEY_FIELD_NUMBER;
        hash = (53 * hash) + getContainerTokenMasterKey().hashCode();
      }
      if (hasNmTokenMasterKey()) {
        hash = (37 * hash) + NM_TOKEN_MASTER_KEY_FIELD_NUMBER;
        hash = (53 * hash) + getNmTokenMasterKey().hashCode();
      }
      if (hasNodeAction()) {
        hash = (37 * hash) + NODEACTION_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getNodeAction());
      }
      if (hasRmIdentifier()) {
        hash = (37 * hash) + RM_IDENTIFIER_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getRmIdentifier());
      }
      if (hasDiagnosticsMessage()) {
        hash = (37 * hash) + DIAGNOSTICS_MESSAGE_FIELD_NUMBER;
        hash = (53 * hash) + getDiagnosticsMessage().hashCode();
      }
      if (hasRmVersion()) {
        hash = (37 * hash) + RM_VERSION_FIELD_NUMBER;
        hash = (53 * hash) + getRmVersion().hashCode();
      }
      if (hasAreNodeLabelsAcceptedByRM()) {
        hash = (37 * hash) + ARENODELABELSACCEPTEDBYRM_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getAreNodeLabelsAcceptedByRM());
      }
      if (hasResource()) {
        hash = (37 * hash) + RESOURCE_FIELD_NUMBER;
        hash = (53 * hash) + getResource().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.RegisterNodeManagerResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_RegisterNodeManagerResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_RegisterNodeManagerResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getContainerTokenMasterKeyFieldBuilder();
          getNmTokenMasterKeyFieldBuilder();
          getResourceFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (containerTokenMasterKeyBuilder_ == null) {
          containerTokenMasterKey_ = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.getDefaultInstance();
        } else {
          containerTokenMasterKeyBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (nmTokenMasterKeyBuilder_ == null) {
          nmTokenMasterKey_ = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.getDefaultInstance();
        } else {
          nmTokenMasterKeyBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        nodeAction_ = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeActionProto.NORMAL;
        bitField0_ = (bitField0_ & ~0x00000004);
        rmIdentifier_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000008);
        diagnosticsMessage_ = "";
        bitField0_ = (bitField0_ & ~0x00000010);
        rmVersion_ = "";
        bitField0_ = (bitField0_ & ~0x00000020);
        areNodeLabelsAcceptedByRM_ = false;
        bitField0_ = (bitField0_ & ~0x00000040);
        if (resourceBuilder_ == null) {
          resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000080);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_RegisterNodeManagerResponseProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto build() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto result = new org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (containerTokenMasterKeyBuilder_ == null) {
          result.containerTokenMasterKey_ = containerTokenMasterKey_;
        } else {
          result.containerTokenMasterKey_ = containerTokenMasterKeyBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (nmTokenMasterKeyBuilder_ == null) {
          result.nmTokenMasterKey_ = nmTokenMasterKey_;
        } else {
          result.nmTokenMasterKey_ = nmTokenMasterKeyBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.nodeAction_ = nodeAction_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.rmIdentifier_ = rmIdentifier_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.diagnosticsMessage_ = diagnosticsMessage_;
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000020;
        }
        result.rmVersion_ = rmVersion_;
        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
          to_bitField0_ |= 0x00000040;
        }
        result.areNodeLabelsAcceptedByRM_ = areNodeLabelsAcceptedByRM_;
        if (((from_bitField0_ & 0x00000080) == 0x00000080)) {
          to_bitField0_ |= 0x00000080;
        }
        if (resourceBuilder_ == null) {
          result.resource_ = resource_;
        } else {
          result.resource_ = resourceBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto.getDefaultInstance()) return this;
        if (other.hasContainerTokenMasterKey()) {
          mergeContainerTokenMasterKey(other.getContainerTokenMasterKey());
        }
        if (other.hasNmTokenMasterKey()) {
          mergeNmTokenMasterKey(other.getNmTokenMasterKey());
        }
        if (other.hasNodeAction()) {
          setNodeAction(other.getNodeAction());
        }
        if (other.hasRmIdentifier()) {
          setRmIdentifier(other.getRmIdentifier());
        }
        if (other.hasDiagnosticsMessage()) {
          bitField0_ |= 0x00000010;
          diagnosticsMessage_ = other.diagnosticsMessage_;
          onChanged();
        }
        if (other.hasRmVersion()) {
          bitField0_ |= 0x00000020;
          rmVersion_ = other.rmVersion_;
          onChanged();
        }
        if (other.hasAreNodeLabelsAcceptedByRM()) {
          setAreNodeLabelsAcceptedByRM(other.getAreNodeLabelsAcceptedByRM());
        }
        if (other.hasResource()) {
          mergeResource(other.getResource());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.RegisterNodeManagerResponseProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.MasterKeyProto container_token_master_key = 1;
      private org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto containerTokenMasterKey_ = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProtoOrBuilder> containerTokenMasterKeyBuilder_;
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto container_token_master_key = 1;</code>
       */
      public boolean hasContainerTokenMasterKey() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto container_token_master_key = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto getContainerTokenMasterKey() {
        if (containerTokenMasterKeyBuilder_ == null) {
          return containerTokenMasterKey_;
        } else {
          return containerTokenMasterKeyBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto container_token_master_key = 1;</code>
       */
      public Builder setContainerTokenMasterKey(org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto value) {
        if (containerTokenMasterKeyBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          containerTokenMasterKey_ = value;
          onChanged();
        } else {
          containerTokenMasterKeyBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto container_token_master_key = 1;</code>
       */
      public Builder setContainerTokenMasterKey(
          org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.Builder builderForValue) {
        if (containerTokenMasterKeyBuilder_ == null) {
          containerTokenMasterKey_ = builderForValue.build();
          onChanged();
        } else {
          containerTokenMasterKeyBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto container_token_master_key = 1;</code>
       */
      public Builder mergeContainerTokenMasterKey(org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto value) {
        if (containerTokenMasterKeyBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              containerTokenMasterKey_ != org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.getDefaultInstance()) {
            containerTokenMasterKey_ =
              org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.newBuilder(containerTokenMasterKey_).mergeFrom(value).buildPartial();
          } else {
            containerTokenMasterKey_ = value;
          }
          onChanged();
        } else {
          containerTokenMasterKeyBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto container_token_master_key = 1;</code>
       */
      public Builder clearContainerTokenMasterKey() {
        if (containerTokenMasterKeyBuilder_ == null) {
          containerTokenMasterKey_ = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.getDefaultInstance();
          onChanged();
        } else {
          containerTokenMasterKeyBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto container_token_master_key = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.Builder getContainerTokenMasterKeyBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getContainerTokenMasterKeyFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto container_token_master_key = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProtoOrBuilder getContainerTokenMasterKeyOrBuilder() {
        if (containerTokenMasterKeyBuilder_ != null) {
          return containerTokenMasterKeyBuilder_.getMessageOrBuilder();
        } else {
          return containerTokenMasterKey_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto container_token_master_key = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProtoOrBuilder> 
          getContainerTokenMasterKeyFieldBuilder() {
        if (containerTokenMasterKeyBuilder_ == null) {
          containerTokenMasterKeyBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProtoOrBuilder>(
                  containerTokenMasterKey_,
                  getParentForChildren(),
                  isClean());
          containerTokenMasterKey_ = null;
        }
        return containerTokenMasterKeyBuilder_;
      }

      // optional .hadoop.yarn.MasterKeyProto nm_token_master_key = 2;
      private org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto nmTokenMasterKey_ = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProtoOrBuilder> nmTokenMasterKeyBuilder_;
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto nm_token_master_key = 2;</code>
       */
      public boolean hasNmTokenMasterKey() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto nm_token_master_key = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto getNmTokenMasterKey() {
        if (nmTokenMasterKeyBuilder_ == null) {
          return nmTokenMasterKey_;
        } else {
          return nmTokenMasterKeyBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto nm_token_master_key = 2;</code>
       */
      public Builder setNmTokenMasterKey(org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto value) {
        if (nmTokenMasterKeyBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          nmTokenMasterKey_ = value;
          onChanged();
        } else {
          nmTokenMasterKeyBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto nm_token_master_key = 2;</code>
       */
      public Builder setNmTokenMasterKey(
          org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.Builder builderForValue) {
        if (nmTokenMasterKeyBuilder_ == null) {
          nmTokenMasterKey_ = builderForValue.build();
          onChanged();
        } else {
          nmTokenMasterKeyBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto nm_token_master_key = 2;</code>
       */
      public Builder mergeNmTokenMasterKey(org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto value) {
        if (nmTokenMasterKeyBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              nmTokenMasterKey_ != org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.getDefaultInstance()) {
            nmTokenMasterKey_ =
              org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.newBuilder(nmTokenMasterKey_).mergeFrom(value).buildPartial();
          } else {
            nmTokenMasterKey_ = value;
          }
          onChanged();
        } else {
          nmTokenMasterKeyBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto nm_token_master_key = 2;</code>
       */
      public Builder clearNmTokenMasterKey() {
        if (nmTokenMasterKeyBuilder_ == null) {
          nmTokenMasterKey_ = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.getDefaultInstance();
          onChanged();
        } else {
          nmTokenMasterKeyBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto nm_token_master_key = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.Builder getNmTokenMasterKeyBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getNmTokenMasterKeyFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto nm_token_master_key = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProtoOrBuilder getNmTokenMasterKeyOrBuilder() {
        if (nmTokenMasterKeyBuilder_ != null) {
          return nmTokenMasterKeyBuilder_.getMessageOrBuilder();
        } else {
          return nmTokenMasterKey_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto nm_token_master_key = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProtoOrBuilder> 
          getNmTokenMasterKeyFieldBuilder() {
        if (nmTokenMasterKeyBuilder_ == null) {
          nmTokenMasterKeyBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProtoOrBuilder>(
                  nmTokenMasterKey_,
                  getParentForChildren(),
                  isClean());
          nmTokenMasterKey_ = null;
        }
        return nmTokenMasterKeyBuilder_;
      }

      // optional .hadoop.yarn.NodeActionProto nodeAction = 3;
      private org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeActionProto nodeAction_ = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeActionProto.NORMAL;
      /**
       * <code>optional .hadoop.yarn.NodeActionProto nodeAction = 3;</code>
       */
      public boolean hasNodeAction() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional .hadoop.yarn.NodeActionProto nodeAction = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeActionProto getNodeAction() {
        return nodeAction_;
      }
      /**
       * <code>optional .hadoop.yarn.NodeActionProto nodeAction = 3;</code>
       */
      public Builder setNodeAction(org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeActionProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000004;
        nodeAction_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeActionProto nodeAction = 3;</code>
       */
      public Builder clearNodeAction() {
        bitField0_ = (bitField0_ & ~0x00000004);
        nodeAction_ = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeActionProto.NORMAL;
        onChanged();
        return this;
      }

      // optional int64 rm_identifier = 4;
      private long rmIdentifier_ ;
      /**
       * <code>optional int64 rm_identifier = 4;</code>
       */
      public boolean hasRmIdentifier() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional int64 rm_identifier = 4;</code>
       */
      public long getRmIdentifier() {
        return rmIdentifier_;
      }
      /**
       * <code>optional int64 rm_identifier = 4;</code>
       */
      public Builder setRmIdentifier(long value) {
        bitField0_ |= 0x00000008;
        rmIdentifier_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 rm_identifier = 4;</code>
       */
      public Builder clearRmIdentifier() {
        bitField0_ = (bitField0_ & ~0x00000008);
        rmIdentifier_ = 0L;
        onChanged();
        return this;
      }

      // optional string diagnostics_message = 5;
      private java.lang.Object diagnosticsMessage_ = "";
      /**
       * <code>optional string diagnostics_message = 5;</code>
       */
      public boolean hasDiagnosticsMessage() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional string diagnostics_message = 5;</code>
       */
      public java.lang.String getDiagnosticsMessage() {
        java.lang.Object ref = diagnosticsMessage_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          diagnosticsMessage_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string diagnostics_message = 5;</code>
       */
      public com.google.protobuf.ByteString
          getDiagnosticsMessageBytes() {
        java.lang.Object ref = diagnosticsMessage_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          diagnosticsMessage_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string diagnostics_message = 5;</code>
       */
      public Builder setDiagnosticsMessage(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000010;
        diagnosticsMessage_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string diagnostics_message = 5;</code>
       */
      public Builder clearDiagnosticsMessage() {
        bitField0_ = (bitField0_ & ~0x00000010);
        diagnosticsMessage_ = getDefaultInstance().getDiagnosticsMessage();
        onChanged();
        return this;
      }
      /**
       * <code>optional string diagnostics_message = 5;</code>
       */
      public Builder setDiagnosticsMessageBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000010;
        diagnosticsMessage_ = value;
        onChanged();
        return this;
      }

      // optional string rm_version = 6;
      private java.lang.Object rmVersion_ = "";
      /**
       * <code>optional string rm_version = 6;</code>
       */
      public boolean hasRmVersion() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional string rm_version = 6;</code>
       */
      public java.lang.String getRmVersion() {
        java.lang.Object ref = rmVersion_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          rmVersion_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string rm_version = 6;</code>
       */
      public com.google.protobuf.ByteString
          getRmVersionBytes() {
        java.lang.Object ref = rmVersion_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          rmVersion_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string rm_version = 6;</code>
       */
      public Builder setRmVersion(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000020;
        rmVersion_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string rm_version = 6;</code>
       */
      public Builder clearRmVersion() {
        bitField0_ = (bitField0_ & ~0x00000020);
        rmVersion_ = getDefaultInstance().getRmVersion();
        onChanged();
        return this;
      }
      /**
       * <code>optional string rm_version = 6;</code>
       */
      public Builder setRmVersionBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000020;
        rmVersion_ = value;
        onChanged();
        return this;
      }

      // optional bool areNodeLabelsAcceptedByRM = 7 [default = false];
      private boolean areNodeLabelsAcceptedByRM_ ;
      /**
       * <code>optional bool areNodeLabelsAcceptedByRM = 7 [default = false];</code>
       */
      public boolean hasAreNodeLabelsAcceptedByRM() {
        return ((bitField0_ & 0x00000040) == 0x00000040);
      }
      /**
       * <code>optional bool areNodeLabelsAcceptedByRM = 7 [default = false];</code>
       */
      public boolean getAreNodeLabelsAcceptedByRM() {
        return areNodeLabelsAcceptedByRM_;
      }
      /**
       * <code>optional bool areNodeLabelsAcceptedByRM = 7 [default = false];</code>
       */
      public Builder setAreNodeLabelsAcceptedByRM(boolean value) {
        bitField0_ |= 0x00000040;
        areNodeLabelsAcceptedByRM_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool areNodeLabelsAcceptedByRM = 7 [default = false];</code>
       */
      public Builder clearAreNodeLabelsAcceptedByRM() {
        bitField0_ = (bitField0_ & ~0x00000040);
        areNodeLabelsAcceptedByRM_ = false;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.ResourceProto resource = 8;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> resourceBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 8;</code>
       */
      public boolean hasResource() {
        return ((bitField0_ & 0x00000080) == 0x00000080);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 8;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource() {
        if (resourceBuilder_ == null) {
          return resource_;
        } else {
          return resourceBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 8;</code>
       */
      public Builder setResource(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (resourceBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          resource_ = value;
          onChanged();
        } else {
          resourceBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000080;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 8;</code>
       */
      public Builder setResource(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (resourceBuilder_ == null) {
          resource_ = builderForValue.build();
          onChanged();
        } else {
          resourceBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000080;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 8;</code>
       */
      public Builder mergeResource(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (resourceBuilder_ == null) {
          if (((bitField0_ & 0x00000080) == 0x00000080) &&
              resource_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            resource_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(resource_).mergeFrom(value).buildPartial();
          } else {
            resource_ = value;
          }
          onChanged();
        } else {
          resourceBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000080;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 8;</code>
       */
      public Builder clearResource() {
        if (resourceBuilder_ == null) {
          resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
          onChanged();
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000080);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 8;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getResourceBuilder() {
        bitField0_ |= 0x00000080;
        onChanged();
        return getResourceFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 8;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder() {
        if (resourceBuilder_ != null) {
          return resourceBuilder_.getMessageOrBuilder();
        } else {
          return resource_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 8;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getResourceFieldBuilder() {
        if (resourceBuilder_ == null) {
          resourceBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  resource_,
                  getParentForChildren(),
                  isClean());
          resource_ = null;
        }
        return resourceBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.RegisterNodeManagerResponseProto)
    }

    static {
      defaultInstance = new RegisterNodeManagerResponseProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.RegisterNodeManagerResponseProto)
  }

  public interface UnRegisterNodeManagerRequestProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.NodeIdProto node_id = 1;
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
     */
    boolean hasNodeId();
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId();
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.UnRegisterNodeManagerRequestProto}
   */
  public static final class UnRegisterNodeManagerRequestProto extends
      com.google.protobuf.GeneratedMessage
      implements UnRegisterNodeManagerRequestProtoOrBuilder {
    // Use UnRegisterNodeManagerRequestProto.newBuilder() to construct.
    private UnRegisterNodeManagerRequestProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private UnRegisterNodeManagerRequestProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final UnRegisterNodeManagerRequestProto defaultInstance;
    public static UnRegisterNodeManagerRequestProto getDefaultInstance() {
      return defaultInstance;
    }

    public UnRegisterNodeManagerRequestProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private UnRegisterNodeManagerRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = nodeId_.toBuilder();
              }
              nodeId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(nodeId_);
                nodeId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_UnRegisterNodeManagerRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_UnRegisterNodeManagerRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerRequestProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerRequestProto.Builder.class);
    }

    public static com.google.protobuf.Parser<UnRegisterNodeManagerRequestProto> PARSER =
        new com.google.protobuf.AbstractParser<UnRegisterNodeManagerRequestProto>() {
      public UnRegisterNodeManagerRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new UnRegisterNodeManagerRequestProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<UnRegisterNodeManagerRequestProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.NodeIdProto node_id = 1;
    public static final int NODE_ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto nodeId_;
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
     */
    public boolean hasNodeId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId() {
      return nodeId_;
    }
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder() {
      return nodeId_;
    }

    private void initFields() {
      nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, nodeId_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, nodeId_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerRequestProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerRequestProto other = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerRequestProto) obj;

      boolean result = true;
      result = result && (hasNodeId() == other.hasNodeId());
      if (hasNodeId()) {
        result = result && getNodeId()
            .equals(other.getNodeId());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasNodeId()) {
        hash = (37 * hash) + NODE_ID_FIELD_NUMBER;
        hash = (53 * hash) + getNodeId().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerRequestProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.UnRegisterNodeManagerRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_UnRegisterNodeManagerRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_UnRegisterNodeManagerRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerRequestProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerRequestProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getNodeIdFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (nodeIdBuilder_ == null) {
          nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
        } else {
          nodeIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_UnRegisterNodeManagerRequestProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerRequestProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerRequestProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerRequestProto build() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerRequestProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerRequestProto result = new org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (nodeIdBuilder_ == null) {
          result.nodeId_ = nodeId_;
        } else {
          result.nodeId_ = nodeIdBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerRequestProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerRequestProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerRequestProto.getDefaultInstance()) return this;
        if (other.hasNodeId()) {
          mergeNodeId(other.getNodeId());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerRequestProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.NodeIdProto node_id = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> nodeIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public boolean hasNodeId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId() {
        if (nodeIdBuilder_ == null) {
          return nodeId_;
        } else {
          return nodeIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public Builder setNodeId(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodeIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          nodeId_ = value;
          onChanged();
        } else {
          nodeIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public Builder setNodeId(
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder builderForValue) {
        if (nodeIdBuilder_ == null) {
          nodeId_ = builderForValue.build();
          onChanged();
        } else {
          nodeIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public Builder mergeNodeId(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodeIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              nodeId_ != org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance()) {
            nodeId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.newBuilder(nodeId_).mergeFrom(value).buildPartial();
          } else {
            nodeId_ = value;
          }
          onChanged();
        } else {
          nodeIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public Builder clearNodeId() {
        if (nodeIdBuilder_ == null) {
          nodeId_ = org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
          onChanged();
        } else {
          nodeIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder getNodeIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getNodeIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder() {
        if (nodeIdBuilder_ != null) {
          return nodeIdBuilder_.getMessageOrBuilder();
        } else {
          return nodeId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> 
          getNodeIdFieldBuilder() {
        if (nodeIdBuilder_ == null) {
          nodeIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder>(
                  nodeId_,
                  getParentForChildren(),
                  isClean());
          nodeId_ = null;
        }
        return nodeIdBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.UnRegisterNodeManagerRequestProto)
    }

    static {
      defaultInstance = new UnRegisterNodeManagerRequestProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.UnRegisterNodeManagerRequestProto)
  }

  public interface UnRegisterNodeManagerResponseProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hadoop.yarn.UnRegisterNodeManagerResponseProto}
   */
  public static final class UnRegisterNodeManagerResponseProto extends
      com.google.protobuf.GeneratedMessage
      implements UnRegisterNodeManagerResponseProtoOrBuilder {
    // Use UnRegisterNodeManagerResponseProto.newBuilder() to construct.
    private UnRegisterNodeManagerResponseProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private UnRegisterNodeManagerResponseProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final UnRegisterNodeManagerResponseProto defaultInstance;
    public static UnRegisterNodeManagerResponseProto getDefaultInstance() {
      return defaultInstance;
    }

    public UnRegisterNodeManagerResponseProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private UnRegisterNodeManagerResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_UnRegisterNodeManagerResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_UnRegisterNodeManagerResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerResponseProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerResponseProto.Builder.class);
    }

    public static com.google.protobuf.Parser<UnRegisterNodeManagerResponseProto> PARSER =
        new com.google.protobuf.AbstractParser<UnRegisterNodeManagerResponseProto>() {
      public UnRegisterNodeManagerResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new UnRegisterNodeManagerResponseProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<UnRegisterNodeManagerResponseProto> getParserForType() {
      return PARSER;
    }

    private void initFields() {
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerResponseProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerResponseProto other = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerResponseProto) obj;

      boolean result = true;
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerResponseProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.UnRegisterNodeManagerResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_UnRegisterNodeManagerResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_UnRegisterNodeManagerResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerResponseProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerResponseProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_UnRegisterNodeManagerResponseProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerResponseProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerResponseProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerResponseProto build() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerResponseProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerResponseProto result = new org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerResponseProto(this);
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerResponseProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerResponseProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerResponseProto.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.UnRegisterNodeManagerResponseProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.UnRegisterNodeManagerResponseProto)
    }

    static {
      defaultInstance = new UnRegisterNodeManagerResponseProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.UnRegisterNodeManagerResponseProto)
  }

  public interface NodeHeartbeatRequestProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.NodeStatusProto node_status = 1;
    /**
     * <code>optional .hadoop.yarn.NodeStatusProto node_status = 1;</code>
     */
    boolean hasNodeStatus();
    /**
     * <code>optional .hadoop.yarn.NodeStatusProto node_status = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto getNodeStatus();
    /**
     * <code>optional .hadoop.yarn.NodeStatusProto node_status = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProtoOrBuilder getNodeStatusOrBuilder();

    // optional .hadoop.yarn.MasterKeyProto last_known_container_token_master_key = 2;
    /**
     * <code>optional .hadoop.yarn.MasterKeyProto last_known_container_token_master_key = 2;</code>
     */
    boolean hasLastKnownContainerTokenMasterKey();
    /**
     * <code>optional .hadoop.yarn.MasterKeyProto last_known_container_token_master_key = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto getLastKnownContainerTokenMasterKey();
    /**
     * <code>optional .hadoop.yarn.MasterKeyProto last_known_container_token_master_key = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProtoOrBuilder getLastKnownContainerTokenMasterKeyOrBuilder();

    // optional .hadoop.yarn.MasterKeyProto last_known_nm_token_master_key = 3;
    /**
     * <code>optional .hadoop.yarn.MasterKeyProto last_known_nm_token_master_key = 3;</code>
     */
    boolean hasLastKnownNmTokenMasterKey();
    /**
     * <code>optional .hadoop.yarn.MasterKeyProto last_known_nm_token_master_key = 3;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto getLastKnownNmTokenMasterKey();
    /**
     * <code>optional .hadoop.yarn.MasterKeyProto last_known_nm_token_master_key = 3;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProtoOrBuilder getLastKnownNmTokenMasterKeyOrBuilder();

    // optional .hadoop.yarn.NodeLabelsProto nodeLabels = 4;
    /**
     * <code>optional .hadoop.yarn.NodeLabelsProto nodeLabels = 4;</code>
     */
    boolean hasNodeLabels();
    /**
     * <code>optional .hadoop.yarn.NodeLabelsProto nodeLabels = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto getNodeLabels();
    /**
     * <code>optional .hadoop.yarn.NodeLabelsProto nodeLabels = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProtoOrBuilder getNodeLabelsOrBuilder();

    // repeated .hadoop.yarn.LogAggregationReportProto log_aggregation_reports_for_apps = 5;
    /**
     * <code>repeated .hadoop.yarn.LogAggregationReportProto log_aggregation_reports_for_apps = 5;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto> 
        getLogAggregationReportsForAppsList();
    /**
     * <code>repeated .hadoop.yarn.LogAggregationReportProto log_aggregation_reports_for_apps = 5;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto getLogAggregationReportsForApps(int index);
    /**
     * <code>repeated .hadoop.yarn.LogAggregationReportProto log_aggregation_reports_for_apps = 5;</code>
     */
    int getLogAggregationReportsForAppsCount();
    /**
     * <code>repeated .hadoop.yarn.LogAggregationReportProto log_aggregation_reports_for_apps = 5;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProtoOrBuilder> 
        getLogAggregationReportsForAppsOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.LogAggregationReportProto log_aggregation_reports_for_apps = 5;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProtoOrBuilder getLogAggregationReportsForAppsOrBuilder(
        int index);

    // repeated .hadoop.yarn.AppCollectorsMapProto registered_collectors = 6;
    /**
     * <code>repeated .hadoop.yarn.AppCollectorsMapProto registered_collectors = 6;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto> 
        getRegisteredCollectorsList();
    /**
     * <code>repeated .hadoop.yarn.AppCollectorsMapProto registered_collectors = 6;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto getRegisteredCollectors(int index);
    /**
     * <code>repeated .hadoop.yarn.AppCollectorsMapProto registered_collectors = 6;</code>
     */
    int getRegisteredCollectorsCount();
    /**
     * <code>repeated .hadoop.yarn.AppCollectorsMapProto registered_collectors = 6;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProtoOrBuilder> 
        getRegisteredCollectorsOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.AppCollectorsMapProto registered_collectors = 6;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProtoOrBuilder getRegisteredCollectorsOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.NodeHeartbeatRequestProto}
   */
  public static final class NodeHeartbeatRequestProto extends
      com.google.protobuf.GeneratedMessage
      implements NodeHeartbeatRequestProtoOrBuilder {
    // Use NodeHeartbeatRequestProto.newBuilder() to construct.
    private NodeHeartbeatRequestProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private NodeHeartbeatRequestProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final NodeHeartbeatRequestProto defaultInstance;
    public static NodeHeartbeatRequestProto getDefaultInstance() {
      return defaultInstance;
    }

    public NodeHeartbeatRequestProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private NodeHeartbeatRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = nodeStatus_.toBuilder();
              }
              nodeStatus_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(nodeStatus_);
                nodeStatus_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = lastKnownContainerTokenMasterKey_.toBuilder();
              }
              lastKnownContainerTokenMasterKey_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(lastKnownContainerTokenMasterKey_);
                lastKnownContainerTokenMasterKey_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = lastKnownNmTokenMasterKey_.toBuilder();
              }
              lastKnownNmTokenMasterKey_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(lastKnownNmTokenMasterKey_);
                lastKnownNmTokenMasterKey_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
            case 34: {
              org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000008) == 0x00000008)) {
                subBuilder = nodeLabels_.toBuilder();
              }
              nodeLabels_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(nodeLabels_);
                nodeLabels_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000008;
              break;
            }
            case 42: {
              if (!((mutable_bitField0_ & 0x00000010) == 0x00000010)) {
                logAggregationReportsForApps_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto>();
                mutable_bitField0_ |= 0x00000010;
              }
              logAggregationReportsForApps_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto.PARSER, extensionRegistry));
              break;
            }
            case 50: {
              if (!((mutable_bitField0_ & 0x00000020) == 0x00000020)) {
                registeredCollectors_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto>();
                mutable_bitField0_ |= 0x00000020;
              }
              registeredCollectors_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000010) == 0x00000010)) {
          logAggregationReportsForApps_ = java.util.Collections.unmodifiableList(logAggregationReportsForApps_);
        }
        if (((mutable_bitField0_ & 0x00000020) == 0x00000020)) {
          registeredCollectors_ = java.util.Collections.unmodifiableList(registeredCollectors_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_NodeHeartbeatRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_NodeHeartbeatRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto.Builder.class);
    }

    public static com.google.protobuf.Parser<NodeHeartbeatRequestProto> PARSER =
        new com.google.protobuf.AbstractParser<NodeHeartbeatRequestProto>() {
      public NodeHeartbeatRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new NodeHeartbeatRequestProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<NodeHeartbeatRequestProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.NodeStatusProto node_status = 1;
    public static final int NODE_STATUS_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto nodeStatus_;
    /**
     * <code>optional .hadoop.yarn.NodeStatusProto node_status = 1;</code>
     */
    public boolean hasNodeStatus() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.NodeStatusProto node_status = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto getNodeStatus() {
      return nodeStatus_;
    }
    /**
     * <code>optional .hadoop.yarn.NodeStatusProto node_status = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProtoOrBuilder getNodeStatusOrBuilder() {
      return nodeStatus_;
    }

    // optional .hadoop.yarn.MasterKeyProto last_known_container_token_master_key = 2;
    public static final int LAST_KNOWN_CONTAINER_TOKEN_MASTER_KEY_FIELD_NUMBER = 2;
    private org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto lastKnownContainerTokenMasterKey_;
    /**
     * <code>optional .hadoop.yarn.MasterKeyProto last_known_container_token_master_key = 2;</code>
     */
    public boolean hasLastKnownContainerTokenMasterKey() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.MasterKeyProto last_known_container_token_master_key = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto getLastKnownContainerTokenMasterKey() {
      return lastKnownContainerTokenMasterKey_;
    }
    /**
     * <code>optional .hadoop.yarn.MasterKeyProto last_known_container_token_master_key = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProtoOrBuilder getLastKnownContainerTokenMasterKeyOrBuilder() {
      return lastKnownContainerTokenMasterKey_;
    }

    // optional .hadoop.yarn.MasterKeyProto last_known_nm_token_master_key = 3;
    public static final int LAST_KNOWN_NM_TOKEN_MASTER_KEY_FIELD_NUMBER = 3;
    private org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto lastKnownNmTokenMasterKey_;
    /**
     * <code>optional .hadoop.yarn.MasterKeyProto last_known_nm_token_master_key = 3;</code>
     */
    public boolean hasLastKnownNmTokenMasterKey() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional .hadoop.yarn.MasterKeyProto last_known_nm_token_master_key = 3;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto getLastKnownNmTokenMasterKey() {
      return lastKnownNmTokenMasterKey_;
    }
    /**
     * <code>optional .hadoop.yarn.MasterKeyProto last_known_nm_token_master_key = 3;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProtoOrBuilder getLastKnownNmTokenMasterKeyOrBuilder() {
      return lastKnownNmTokenMasterKey_;
    }

    // optional .hadoop.yarn.NodeLabelsProto nodeLabels = 4;
    public static final int NODELABELS_FIELD_NUMBER = 4;
    private org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto nodeLabels_;
    /**
     * <code>optional .hadoop.yarn.NodeLabelsProto nodeLabels = 4;</code>
     */
    public boolean hasNodeLabels() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional .hadoop.yarn.NodeLabelsProto nodeLabels = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto getNodeLabels() {
      return nodeLabels_;
    }
    /**
     * <code>optional .hadoop.yarn.NodeLabelsProto nodeLabels = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProtoOrBuilder getNodeLabelsOrBuilder() {
      return nodeLabels_;
    }

    // repeated .hadoop.yarn.LogAggregationReportProto log_aggregation_reports_for_apps = 5;
    public static final int LOG_AGGREGATION_REPORTS_FOR_APPS_FIELD_NUMBER = 5;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto> logAggregationReportsForApps_;
    /**
     * <code>repeated .hadoop.yarn.LogAggregationReportProto log_aggregation_reports_for_apps = 5;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto> getLogAggregationReportsForAppsList() {
      return logAggregationReportsForApps_;
    }
    /**
     * <code>repeated .hadoop.yarn.LogAggregationReportProto log_aggregation_reports_for_apps = 5;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProtoOrBuilder> 
        getLogAggregationReportsForAppsOrBuilderList() {
      return logAggregationReportsForApps_;
    }
    /**
     * <code>repeated .hadoop.yarn.LogAggregationReportProto log_aggregation_reports_for_apps = 5;</code>
     */
    public int getLogAggregationReportsForAppsCount() {
      return logAggregationReportsForApps_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.LogAggregationReportProto log_aggregation_reports_for_apps = 5;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto getLogAggregationReportsForApps(int index) {
      return logAggregationReportsForApps_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.LogAggregationReportProto log_aggregation_reports_for_apps = 5;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProtoOrBuilder getLogAggregationReportsForAppsOrBuilder(
        int index) {
      return logAggregationReportsForApps_.get(index);
    }

    // repeated .hadoop.yarn.AppCollectorsMapProto registered_collectors = 6;
    public static final int REGISTERED_COLLECTORS_FIELD_NUMBER = 6;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto> registeredCollectors_;
    /**
     * <code>repeated .hadoop.yarn.AppCollectorsMapProto registered_collectors = 6;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto> getRegisteredCollectorsList() {
      return registeredCollectors_;
    }
    /**
     * <code>repeated .hadoop.yarn.AppCollectorsMapProto registered_collectors = 6;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProtoOrBuilder> 
        getRegisteredCollectorsOrBuilderList() {
      return registeredCollectors_;
    }
    /**
     * <code>repeated .hadoop.yarn.AppCollectorsMapProto registered_collectors = 6;</code>
     */
    public int getRegisteredCollectorsCount() {
      return registeredCollectors_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.AppCollectorsMapProto registered_collectors = 6;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto getRegisteredCollectors(int index) {
      return registeredCollectors_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.AppCollectorsMapProto registered_collectors = 6;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProtoOrBuilder getRegisteredCollectorsOrBuilder(
        int index) {
      return registeredCollectors_.get(index);
    }

    private void initFields() {
      nodeStatus_ = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto.getDefaultInstance();
      lastKnownContainerTokenMasterKey_ = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.getDefaultInstance();
      lastKnownNmTokenMasterKey_ = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.getDefaultInstance();
      nodeLabels_ = org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto.getDefaultInstance();
      logAggregationReportsForApps_ = java.util.Collections.emptyList();
      registeredCollectors_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (hasNodeStatus()) {
        if (!getNodeStatus().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, nodeStatus_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, lastKnownContainerTokenMasterKey_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(3, lastKnownNmTokenMasterKey_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeMessage(4, nodeLabels_);
      }
      for (int i = 0; i < logAggregationReportsForApps_.size(); i++) {
        output.writeMessage(5, logAggregationReportsForApps_.get(i));
      }
      for (int i = 0; i < registeredCollectors_.size(); i++) {
        output.writeMessage(6, registeredCollectors_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, nodeStatus_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, lastKnownContainerTokenMasterKey_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, lastKnownNmTokenMasterKey_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, nodeLabels_);
      }
      for (int i = 0; i < logAggregationReportsForApps_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, logAggregationReportsForApps_.get(i));
      }
      for (int i = 0; i < registeredCollectors_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, registeredCollectors_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto other = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto) obj;

      boolean result = true;
      result = result && (hasNodeStatus() == other.hasNodeStatus());
      if (hasNodeStatus()) {
        result = result && getNodeStatus()
            .equals(other.getNodeStatus());
      }
      result = result && (hasLastKnownContainerTokenMasterKey() == other.hasLastKnownContainerTokenMasterKey());
      if (hasLastKnownContainerTokenMasterKey()) {
        result = result && getLastKnownContainerTokenMasterKey()
            .equals(other.getLastKnownContainerTokenMasterKey());
      }
      result = result && (hasLastKnownNmTokenMasterKey() == other.hasLastKnownNmTokenMasterKey());
      if (hasLastKnownNmTokenMasterKey()) {
        result = result && getLastKnownNmTokenMasterKey()
            .equals(other.getLastKnownNmTokenMasterKey());
      }
      result = result && (hasNodeLabels() == other.hasNodeLabels());
      if (hasNodeLabels()) {
        result = result && getNodeLabels()
            .equals(other.getNodeLabels());
      }
      result = result && getLogAggregationReportsForAppsList()
          .equals(other.getLogAggregationReportsForAppsList());
      result = result && getRegisteredCollectorsList()
          .equals(other.getRegisteredCollectorsList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasNodeStatus()) {
        hash = (37 * hash) + NODE_STATUS_FIELD_NUMBER;
        hash = (53 * hash) + getNodeStatus().hashCode();
      }
      if (hasLastKnownContainerTokenMasterKey()) {
        hash = (37 * hash) + LAST_KNOWN_CONTAINER_TOKEN_MASTER_KEY_FIELD_NUMBER;
        hash = (53 * hash) + getLastKnownContainerTokenMasterKey().hashCode();
      }
      if (hasLastKnownNmTokenMasterKey()) {
        hash = (37 * hash) + LAST_KNOWN_NM_TOKEN_MASTER_KEY_FIELD_NUMBER;
        hash = (53 * hash) + getLastKnownNmTokenMasterKey().hashCode();
      }
      if (hasNodeLabels()) {
        hash = (37 * hash) + NODELABELS_FIELD_NUMBER;
        hash = (53 * hash) + getNodeLabels().hashCode();
      }
      if (getLogAggregationReportsForAppsCount() > 0) {
        hash = (37 * hash) + LOG_AGGREGATION_REPORTS_FOR_APPS_FIELD_NUMBER;
        hash = (53 * hash) + getLogAggregationReportsForAppsList().hashCode();
      }
      if (getRegisteredCollectorsCount() > 0) {
        hash = (37 * hash) + REGISTERED_COLLECTORS_FIELD_NUMBER;
        hash = (53 * hash) + getRegisteredCollectorsList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.NodeHeartbeatRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_NodeHeartbeatRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_NodeHeartbeatRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getNodeStatusFieldBuilder();
          getLastKnownContainerTokenMasterKeyFieldBuilder();
          getLastKnownNmTokenMasterKeyFieldBuilder();
          getNodeLabelsFieldBuilder();
          getLogAggregationReportsForAppsFieldBuilder();
          getRegisteredCollectorsFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (nodeStatusBuilder_ == null) {
          nodeStatus_ = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto.getDefaultInstance();
        } else {
          nodeStatusBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (lastKnownContainerTokenMasterKeyBuilder_ == null) {
          lastKnownContainerTokenMasterKey_ = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.getDefaultInstance();
        } else {
          lastKnownContainerTokenMasterKeyBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (lastKnownNmTokenMasterKeyBuilder_ == null) {
          lastKnownNmTokenMasterKey_ = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.getDefaultInstance();
        } else {
          lastKnownNmTokenMasterKeyBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        if (nodeLabelsBuilder_ == null) {
          nodeLabels_ = org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto.getDefaultInstance();
        } else {
          nodeLabelsBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        if (logAggregationReportsForAppsBuilder_ == null) {
          logAggregationReportsForApps_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000010);
        } else {
          logAggregationReportsForAppsBuilder_.clear();
        }
        if (registeredCollectorsBuilder_ == null) {
          registeredCollectors_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000020);
        } else {
          registeredCollectorsBuilder_.clear();
        }
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_NodeHeartbeatRequestProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto build() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto result = new org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (nodeStatusBuilder_ == null) {
          result.nodeStatus_ = nodeStatus_;
        } else {
          result.nodeStatus_ = nodeStatusBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (lastKnownContainerTokenMasterKeyBuilder_ == null) {
          result.lastKnownContainerTokenMasterKey_ = lastKnownContainerTokenMasterKey_;
        } else {
          result.lastKnownContainerTokenMasterKey_ = lastKnownContainerTokenMasterKeyBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (lastKnownNmTokenMasterKeyBuilder_ == null) {
          result.lastKnownNmTokenMasterKey_ = lastKnownNmTokenMasterKey_;
        } else {
          result.lastKnownNmTokenMasterKey_ = lastKnownNmTokenMasterKeyBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        if (nodeLabelsBuilder_ == null) {
          result.nodeLabels_ = nodeLabels_;
        } else {
          result.nodeLabels_ = nodeLabelsBuilder_.build();
        }
        if (logAggregationReportsForAppsBuilder_ == null) {
          if (((bitField0_ & 0x00000010) == 0x00000010)) {
            logAggregationReportsForApps_ = java.util.Collections.unmodifiableList(logAggregationReportsForApps_);
            bitField0_ = (bitField0_ & ~0x00000010);
          }
          result.logAggregationReportsForApps_ = logAggregationReportsForApps_;
        } else {
          result.logAggregationReportsForApps_ = logAggregationReportsForAppsBuilder_.build();
        }
        if (registeredCollectorsBuilder_ == null) {
          if (((bitField0_ & 0x00000020) == 0x00000020)) {
            registeredCollectors_ = java.util.Collections.unmodifiableList(registeredCollectors_);
            bitField0_ = (bitField0_ & ~0x00000020);
          }
          result.registeredCollectors_ = registeredCollectors_;
        } else {
          result.registeredCollectors_ = registeredCollectorsBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto.getDefaultInstance()) return this;
        if (other.hasNodeStatus()) {
          mergeNodeStatus(other.getNodeStatus());
        }
        if (other.hasLastKnownContainerTokenMasterKey()) {
          mergeLastKnownContainerTokenMasterKey(other.getLastKnownContainerTokenMasterKey());
        }
        if (other.hasLastKnownNmTokenMasterKey()) {
          mergeLastKnownNmTokenMasterKey(other.getLastKnownNmTokenMasterKey());
        }
        if (other.hasNodeLabels()) {
          mergeNodeLabels(other.getNodeLabels());
        }
        if (logAggregationReportsForAppsBuilder_ == null) {
          if (!other.logAggregationReportsForApps_.isEmpty()) {
            if (logAggregationReportsForApps_.isEmpty()) {
              logAggregationReportsForApps_ = other.logAggregationReportsForApps_;
              bitField0_ = (bitField0_ & ~0x00000010);
            } else {
              ensureLogAggregationReportsForAppsIsMutable();
              logAggregationReportsForApps_.addAll(other.logAggregationReportsForApps_);
            }
            onChanged();
          }
        } else {
          if (!other.logAggregationReportsForApps_.isEmpty()) {
            if (logAggregationReportsForAppsBuilder_.isEmpty()) {
              logAggregationReportsForAppsBuilder_.dispose();
              logAggregationReportsForAppsBuilder_ = null;
              logAggregationReportsForApps_ = other.logAggregationReportsForApps_;
              bitField0_ = (bitField0_ & ~0x00000010);
              logAggregationReportsForAppsBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getLogAggregationReportsForAppsFieldBuilder() : null;
            } else {
              logAggregationReportsForAppsBuilder_.addAllMessages(other.logAggregationReportsForApps_);
            }
          }
        }
        if (registeredCollectorsBuilder_ == null) {
          if (!other.registeredCollectors_.isEmpty()) {
            if (registeredCollectors_.isEmpty()) {
              registeredCollectors_ = other.registeredCollectors_;
              bitField0_ = (bitField0_ & ~0x00000020);
            } else {
              ensureRegisteredCollectorsIsMutable();
              registeredCollectors_.addAll(other.registeredCollectors_);
            }
            onChanged();
          }
        } else {
          if (!other.registeredCollectors_.isEmpty()) {
            if (registeredCollectorsBuilder_.isEmpty()) {
              registeredCollectorsBuilder_.dispose();
              registeredCollectorsBuilder_ = null;
              registeredCollectors_ = other.registeredCollectors_;
              bitField0_ = (bitField0_ & ~0x00000020);
              registeredCollectorsBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getRegisteredCollectorsFieldBuilder() : null;
            } else {
              registeredCollectorsBuilder_.addAllMessages(other.registeredCollectors_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (hasNodeStatus()) {
          if (!getNodeStatus().isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatRequestProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.NodeStatusProto node_status = 1;
      private org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto nodeStatus_ = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProtoOrBuilder> nodeStatusBuilder_;
      /**
       * <code>optional .hadoop.yarn.NodeStatusProto node_status = 1;</code>
       */
      public boolean hasNodeStatus() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.NodeStatusProto node_status = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto getNodeStatus() {
        if (nodeStatusBuilder_ == null) {
          return nodeStatus_;
        } else {
          return nodeStatusBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeStatusProto node_status = 1;</code>
       */
      public Builder setNodeStatus(org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto value) {
        if (nodeStatusBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          nodeStatus_ = value;
          onChanged();
        } else {
          nodeStatusBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeStatusProto node_status = 1;</code>
       */
      public Builder setNodeStatus(
          org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto.Builder builderForValue) {
        if (nodeStatusBuilder_ == null) {
          nodeStatus_ = builderForValue.build();
          onChanged();
        } else {
          nodeStatusBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeStatusProto node_status = 1;</code>
       */
      public Builder mergeNodeStatus(org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto value) {
        if (nodeStatusBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              nodeStatus_ != org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto.getDefaultInstance()) {
            nodeStatus_ =
              org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto.newBuilder(nodeStatus_).mergeFrom(value).buildPartial();
          } else {
            nodeStatus_ = value;
          }
          onChanged();
        } else {
          nodeStatusBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeStatusProto node_status = 1;</code>
       */
      public Builder clearNodeStatus() {
        if (nodeStatusBuilder_ == null) {
          nodeStatus_ = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto.getDefaultInstance();
          onChanged();
        } else {
          nodeStatusBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeStatusProto node_status = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto.Builder getNodeStatusBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getNodeStatusFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.NodeStatusProto node_status = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProtoOrBuilder getNodeStatusOrBuilder() {
        if (nodeStatusBuilder_ != null) {
          return nodeStatusBuilder_.getMessageOrBuilder();
        } else {
          return nodeStatus_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeStatusProto node_status = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProtoOrBuilder> 
          getNodeStatusFieldBuilder() {
        if (nodeStatusBuilder_ == null) {
          nodeStatusBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeStatusProtoOrBuilder>(
                  nodeStatus_,
                  getParentForChildren(),
                  isClean());
          nodeStatus_ = null;
        }
        return nodeStatusBuilder_;
      }

      // optional .hadoop.yarn.MasterKeyProto last_known_container_token_master_key = 2;
      private org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto lastKnownContainerTokenMasterKey_ = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProtoOrBuilder> lastKnownContainerTokenMasterKeyBuilder_;
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto last_known_container_token_master_key = 2;</code>
       */
      public boolean hasLastKnownContainerTokenMasterKey() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto last_known_container_token_master_key = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto getLastKnownContainerTokenMasterKey() {
        if (lastKnownContainerTokenMasterKeyBuilder_ == null) {
          return lastKnownContainerTokenMasterKey_;
        } else {
          return lastKnownContainerTokenMasterKeyBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto last_known_container_token_master_key = 2;</code>
       */
      public Builder setLastKnownContainerTokenMasterKey(org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto value) {
        if (lastKnownContainerTokenMasterKeyBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          lastKnownContainerTokenMasterKey_ = value;
          onChanged();
        } else {
          lastKnownContainerTokenMasterKeyBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto last_known_container_token_master_key = 2;</code>
       */
      public Builder setLastKnownContainerTokenMasterKey(
          org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.Builder builderForValue) {
        if (lastKnownContainerTokenMasterKeyBuilder_ == null) {
          lastKnownContainerTokenMasterKey_ = builderForValue.build();
          onChanged();
        } else {
          lastKnownContainerTokenMasterKeyBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto last_known_container_token_master_key = 2;</code>
       */
      public Builder mergeLastKnownContainerTokenMasterKey(org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto value) {
        if (lastKnownContainerTokenMasterKeyBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              lastKnownContainerTokenMasterKey_ != org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.getDefaultInstance()) {
            lastKnownContainerTokenMasterKey_ =
              org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.newBuilder(lastKnownContainerTokenMasterKey_).mergeFrom(value).buildPartial();
          } else {
            lastKnownContainerTokenMasterKey_ = value;
          }
          onChanged();
        } else {
          lastKnownContainerTokenMasterKeyBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto last_known_container_token_master_key = 2;</code>
       */
      public Builder clearLastKnownContainerTokenMasterKey() {
        if (lastKnownContainerTokenMasterKeyBuilder_ == null) {
          lastKnownContainerTokenMasterKey_ = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.getDefaultInstance();
          onChanged();
        } else {
          lastKnownContainerTokenMasterKeyBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto last_known_container_token_master_key = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.Builder getLastKnownContainerTokenMasterKeyBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getLastKnownContainerTokenMasterKeyFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto last_known_container_token_master_key = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProtoOrBuilder getLastKnownContainerTokenMasterKeyOrBuilder() {
        if (lastKnownContainerTokenMasterKeyBuilder_ != null) {
          return lastKnownContainerTokenMasterKeyBuilder_.getMessageOrBuilder();
        } else {
          return lastKnownContainerTokenMasterKey_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto last_known_container_token_master_key = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProtoOrBuilder> 
          getLastKnownContainerTokenMasterKeyFieldBuilder() {
        if (lastKnownContainerTokenMasterKeyBuilder_ == null) {
          lastKnownContainerTokenMasterKeyBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProtoOrBuilder>(
                  lastKnownContainerTokenMasterKey_,
                  getParentForChildren(),
                  isClean());
          lastKnownContainerTokenMasterKey_ = null;
        }
        return lastKnownContainerTokenMasterKeyBuilder_;
      }

      // optional .hadoop.yarn.MasterKeyProto last_known_nm_token_master_key = 3;
      private org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto lastKnownNmTokenMasterKey_ = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProtoOrBuilder> lastKnownNmTokenMasterKeyBuilder_;
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto last_known_nm_token_master_key = 3;</code>
       */
      public boolean hasLastKnownNmTokenMasterKey() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto last_known_nm_token_master_key = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto getLastKnownNmTokenMasterKey() {
        if (lastKnownNmTokenMasterKeyBuilder_ == null) {
          return lastKnownNmTokenMasterKey_;
        } else {
          return lastKnownNmTokenMasterKeyBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto last_known_nm_token_master_key = 3;</code>
       */
      public Builder setLastKnownNmTokenMasterKey(org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto value) {
        if (lastKnownNmTokenMasterKeyBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          lastKnownNmTokenMasterKey_ = value;
          onChanged();
        } else {
          lastKnownNmTokenMasterKeyBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto last_known_nm_token_master_key = 3;</code>
       */
      public Builder setLastKnownNmTokenMasterKey(
          org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.Builder builderForValue) {
        if (lastKnownNmTokenMasterKeyBuilder_ == null) {
          lastKnownNmTokenMasterKey_ = builderForValue.build();
          onChanged();
        } else {
          lastKnownNmTokenMasterKeyBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto last_known_nm_token_master_key = 3;</code>
       */
      public Builder mergeLastKnownNmTokenMasterKey(org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto value) {
        if (lastKnownNmTokenMasterKeyBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              lastKnownNmTokenMasterKey_ != org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.getDefaultInstance()) {
            lastKnownNmTokenMasterKey_ =
              org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.newBuilder(lastKnownNmTokenMasterKey_).mergeFrom(value).buildPartial();
          } else {
            lastKnownNmTokenMasterKey_ = value;
          }
          onChanged();
        } else {
          lastKnownNmTokenMasterKeyBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto last_known_nm_token_master_key = 3;</code>
       */
      public Builder clearLastKnownNmTokenMasterKey() {
        if (lastKnownNmTokenMasterKeyBuilder_ == null) {
          lastKnownNmTokenMasterKey_ = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.getDefaultInstance();
          onChanged();
        } else {
          lastKnownNmTokenMasterKeyBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto last_known_nm_token_master_key = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.Builder getLastKnownNmTokenMasterKeyBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getLastKnownNmTokenMasterKeyFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto last_known_nm_token_master_key = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProtoOrBuilder getLastKnownNmTokenMasterKeyOrBuilder() {
        if (lastKnownNmTokenMasterKeyBuilder_ != null) {
          return lastKnownNmTokenMasterKeyBuilder_.getMessageOrBuilder();
        } else {
          return lastKnownNmTokenMasterKey_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto last_known_nm_token_master_key = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProtoOrBuilder> 
          getLastKnownNmTokenMasterKeyFieldBuilder() {
        if (lastKnownNmTokenMasterKeyBuilder_ == null) {
          lastKnownNmTokenMasterKeyBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProtoOrBuilder>(
                  lastKnownNmTokenMasterKey_,
                  getParentForChildren(),
                  isClean());
          lastKnownNmTokenMasterKey_ = null;
        }
        return lastKnownNmTokenMasterKeyBuilder_;
      }

      // optional .hadoop.yarn.NodeLabelsProto nodeLabels = 4;
      private org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto nodeLabels_ = org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProtoOrBuilder> nodeLabelsBuilder_;
      /**
       * <code>optional .hadoop.yarn.NodeLabelsProto nodeLabels = 4;</code>
       */
      public boolean hasNodeLabels() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional .hadoop.yarn.NodeLabelsProto nodeLabels = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto getNodeLabels() {
        if (nodeLabelsBuilder_ == null) {
          return nodeLabels_;
        } else {
          return nodeLabelsBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeLabelsProto nodeLabels = 4;</code>
       */
      public Builder setNodeLabels(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto value) {
        if (nodeLabelsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          nodeLabels_ = value;
          onChanged();
        } else {
          nodeLabelsBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeLabelsProto nodeLabels = 4;</code>
       */
      public Builder setNodeLabels(
          org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto.Builder builderForValue) {
        if (nodeLabelsBuilder_ == null) {
          nodeLabels_ = builderForValue.build();
          onChanged();
        } else {
          nodeLabelsBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeLabelsProto nodeLabels = 4;</code>
       */
      public Builder mergeNodeLabels(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto value) {
        if (nodeLabelsBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008) &&
              nodeLabels_ != org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto.getDefaultInstance()) {
            nodeLabels_ =
              org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto.newBuilder(nodeLabels_).mergeFrom(value).buildPartial();
          } else {
            nodeLabels_ = value;
          }
          onChanged();
        } else {
          nodeLabelsBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeLabelsProto nodeLabels = 4;</code>
       */
      public Builder clearNodeLabels() {
        if (nodeLabelsBuilder_ == null) {
          nodeLabels_ = org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto.getDefaultInstance();
          onChanged();
        } else {
          nodeLabelsBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeLabelsProto nodeLabels = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto.Builder getNodeLabelsBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getNodeLabelsFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.NodeLabelsProto nodeLabels = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProtoOrBuilder getNodeLabelsOrBuilder() {
        if (nodeLabelsBuilder_ != null) {
          return nodeLabelsBuilder_.getMessageOrBuilder();
        } else {
          return nodeLabels_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeLabelsProto nodeLabels = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProtoOrBuilder> 
          getNodeLabelsFieldBuilder() {
        if (nodeLabelsBuilder_ == null) {
          nodeLabelsBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeLabelsProtoOrBuilder>(
                  nodeLabels_,
                  getParentForChildren(),
                  isClean());
          nodeLabels_ = null;
        }
        return nodeLabelsBuilder_;
      }

      // repeated .hadoop.yarn.LogAggregationReportProto log_aggregation_reports_for_apps = 5;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto> logAggregationReportsForApps_ =
        java.util.Collections.emptyList();
      private void ensureLogAggregationReportsForAppsIsMutable() {
        if (!((bitField0_ & 0x00000010) == 0x00000010)) {
          logAggregationReportsForApps_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto>(logAggregationReportsForApps_);
          bitField0_ |= 0x00000010;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProtoOrBuilder> logAggregationReportsForAppsBuilder_;

      /**
       * <code>repeated .hadoop.yarn.LogAggregationReportProto log_aggregation_reports_for_apps = 5;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto> getLogAggregationReportsForAppsList() {
        if (logAggregationReportsForAppsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(logAggregationReportsForApps_);
        } else {
          return logAggregationReportsForAppsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.LogAggregationReportProto log_aggregation_reports_for_apps = 5;</code>
       */
      public int getLogAggregationReportsForAppsCount() {
        if (logAggregationReportsForAppsBuilder_ == null) {
          return logAggregationReportsForApps_.size();
        } else {
          return logAggregationReportsForAppsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.LogAggregationReportProto log_aggregation_reports_for_apps = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto getLogAggregationReportsForApps(int index) {
        if (logAggregationReportsForAppsBuilder_ == null) {
          return logAggregationReportsForApps_.get(index);
        } else {
          return logAggregationReportsForAppsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.LogAggregationReportProto log_aggregation_reports_for_apps = 5;</code>
       */
      public Builder setLogAggregationReportsForApps(
          int index, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto value) {
        if (logAggregationReportsForAppsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureLogAggregationReportsForAppsIsMutable();
          logAggregationReportsForApps_.set(index, value);
          onChanged();
        } else {
          logAggregationReportsForAppsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.LogAggregationReportProto log_aggregation_reports_for_apps = 5;</code>
       */
      public Builder setLogAggregationReportsForApps(
          int index, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto.Builder builderForValue) {
        if (logAggregationReportsForAppsBuilder_ == null) {
          ensureLogAggregationReportsForAppsIsMutable();
          logAggregationReportsForApps_.set(index, builderForValue.build());
          onChanged();
        } else {
          logAggregationReportsForAppsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.LogAggregationReportProto log_aggregation_reports_for_apps = 5;</code>
       */
      public Builder addLogAggregationReportsForApps(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto value) {
        if (logAggregationReportsForAppsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureLogAggregationReportsForAppsIsMutable();
          logAggregationReportsForApps_.add(value);
          onChanged();
        } else {
          logAggregationReportsForAppsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.LogAggregationReportProto log_aggregation_reports_for_apps = 5;</code>
       */
      public Builder addLogAggregationReportsForApps(
          int index, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto value) {
        if (logAggregationReportsForAppsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureLogAggregationReportsForAppsIsMutable();
          logAggregationReportsForApps_.add(index, value);
          onChanged();
        } else {
          logAggregationReportsForAppsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.LogAggregationReportProto log_aggregation_reports_for_apps = 5;</code>
       */
      public Builder addLogAggregationReportsForApps(
          org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto.Builder builderForValue) {
        if (logAggregationReportsForAppsBuilder_ == null) {
          ensureLogAggregationReportsForAppsIsMutable();
          logAggregationReportsForApps_.add(builderForValue.build());
          onChanged();
        } else {
          logAggregationReportsForAppsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.LogAggregationReportProto log_aggregation_reports_for_apps = 5;</code>
       */
      public Builder addLogAggregationReportsForApps(
          int index, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto.Builder builderForValue) {
        if (logAggregationReportsForAppsBuilder_ == null) {
          ensureLogAggregationReportsForAppsIsMutable();
          logAggregationReportsForApps_.add(index, builderForValue.build());
          onChanged();
        } else {
          logAggregationReportsForAppsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.LogAggregationReportProto log_aggregation_reports_for_apps = 5;</code>
       */
      public Builder addAllLogAggregationReportsForApps(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto> values) {
        if (logAggregationReportsForAppsBuilder_ == null) {
          ensureLogAggregationReportsForAppsIsMutable();
          super.addAll(values, logAggregationReportsForApps_);
          onChanged();
        } else {
          logAggregationReportsForAppsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.LogAggregationReportProto log_aggregation_reports_for_apps = 5;</code>
       */
      public Builder clearLogAggregationReportsForApps() {
        if (logAggregationReportsForAppsBuilder_ == null) {
          logAggregationReportsForApps_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000010);
          onChanged();
        } else {
          logAggregationReportsForAppsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.LogAggregationReportProto log_aggregation_reports_for_apps = 5;</code>
       */
      public Builder removeLogAggregationReportsForApps(int index) {
        if (logAggregationReportsForAppsBuilder_ == null) {
          ensureLogAggregationReportsForAppsIsMutable();
          logAggregationReportsForApps_.remove(index);
          onChanged();
        } else {
          logAggregationReportsForAppsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.LogAggregationReportProto log_aggregation_reports_for_apps = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto.Builder getLogAggregationReportsForAppsBuilder(
          int index) {
        return getLogAggregationReportsForAppsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.LogAggregationReportProto log_aggregation_reports_for_apps = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProtoOrBuilder getLogAggregationReportsForAppsOrBuilder(
          int index) {
        if (logAggregationReportsForAppsBuilder_ == null) {
          return logAggregationReportsForApps_.get(index);  } else {
          return logAggregationReportsForAppsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.LogAggregationReportProto log_aggregation_reports_for_apps = 5;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProtoOrBuilder> 
           getLogAggregationReportsForAppsOrBuilderList() {
        if (logAggregationReportsForAppsBuilder_ != null) {
          return logAggregationReportsForAppsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(logAggregationReportsForApps_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.LogAggregationReportProto log_aggregation_reports_for_apps = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto.Builder addLogAggregationReportsForAppsBuilder() {
        return getLogAggregationReportsForAppsFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.LogAggregationReportProto log_aggregation_reports_for_apps = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto.Builder addLogAggregationReportsForAppsBuilder(
          int index) {
        return getLogAggregationReportsForAppsFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.LogAggregationReportProto log_aggregation_reports_for_apps = 5;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto.Builder> 
           getLogAggregationReportsForAppsBuilderList() {
        return getLogAggregationReportsForAppsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProtoOrBuilder> 
          getLogAggregationReportsForAppsFieldBuilder() {
        if (logAggregationReportsForAppsBuilder_ == null) {
          logAggregationReportsForAppsBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProtoOrBuilder>(
                  logAggregationReportsForApps_,
                  ((bitField0_ & 0x00000010) == 0x00000010),
                  getParentForChildren(),
                  isClean());
          logAggregationReportsForApps_ = null;
        }
        return logAggregationReportsForAppsBuilder_;
      }

      // repeated .hadoop.yarn.AppCollectorsMapProto registered_collectors = 6;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto> registeredCollectors_ =
        java.util.Collections.emptyList();
      private void ensureRegisteredCollectorsIsMutable() {
        if (!((bitField0_ & 0x00000020) == 0x00000020)) {
          registeredCollectors_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto>(registeredCollectors_);
          bitField0_ |= 0x00000020;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProtoOrBuilder> registeredCollectorsBuilder_;

      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto registered_collectors = 6;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto> getRegisteredCollectorsList() {
        if (registeredCollectorsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(registeredCollectors_);
        } else {
          return registeredCollectorsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto registered_collectors = 6;</code>
       */
      public int getRegisteredCollectorsCount() {
        if (registeredCollectorsBuilder_ == null) {
          return registeredCollectors_.size();
        } else {
          return registeredCollectorsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto registered_collectors = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto getRegisteredCollectors(int index) {
        if (registeredCollectorsBuilder_ == null) {
          return registeredCollectors_.get(index);
        } else {
          return registeredCollectorsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto registered_collectors = 6;</code>
       */
      public Builder setRegisteredCollectors(
          int index, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto value) {
        if (registeredCollectorsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegisteredCollectorsIsMutable();
          registeredCollectors_.set(index, value);
          onChanged();
        } else {
          registeredCollectorsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto registered_collectors = 6;</code>
       */
      public Builder setRegisteredCollectors(
          int index, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.Builder builderForValue) {
        if (registeredCollectorsBuilder_ == null) {
          ensureRegisteredCollectorsIsMutable();
          registeredCollectors_.set(index, builderForValue.build());
          onChanged();
        } else {
          registeredCollectorsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto registered_collectors = 6;</code>
       */
      public Builder addRegisteredCollectors(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto value) {
        if (registeredCollectorsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegisteredCollectorsIsMutable();
          registeredCollectors_.add(value);
          onChanged();
        } else {
          registeredCollectorsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto registered_collectors = 6;</code>
       */
      public Builder addRegisteredCollectors(
          int index, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto value) {
        if (registeredCollectorsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegisteredCollectorsIsMutable();
          registeredCollectors_.add(index, value);
          onChanged();
        } else {
          registeredCollectorsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto registered_collectors = 6;</code>
       */
      public Builder addRegisteredCollectors(
          org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.Builder builderForValue) {
        if (registeredCollectorsBuilder_ == null) {
          ensureRegisteredCollectorsIsMutable();
          registeredCollectors_.add(builderForValue.build());
          onChanged();
        } else {
          registeredCollectorsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto registered_collectors = 6;</code>
       */
      public Builder addRegisteredCollectors(
          int index, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.Builder builderForValue) {
        if (registeredCollectorsBuilder_ == null) {
          ensureRegisteredCollectorsIsMutable();
          registeredCollectors_.add(index, builderForValue.build());
          onChanged();
        } else {
          registeredCollectorsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto registered_collectors = 6;</code>
       */
      public Builder addAllRegisteredCollectors(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto> values) {
        if (registeredCollectorsBuilder_ == null) {
          ensureRegisteredCollectorsIsMutable();
          super.addAll(values, registeredCollectors_);
          onChanged();
        } else {
          registeredCollectorsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto registered_collectors = 6;</code>
       */
      public Builder clearRegisteredCollectors() {
        if (registeredCollectorsBuilder_ == null) {
          registeredCollectors_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000020);
          onChanged();
        } else {
          registeredCollectorsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto registered_collectors = 6;</code>
       */
      public Builder removeRegisteredCollectors(int index) {
        if (registeredCollectorsBuilder_ == null) {
          ensureRegisteredCollectorsIsMutable();
          registeredCollectors_.remove(index);
          onChanged();
        } else {
          registeredCollectorsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto registered_collectors = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.Builder getRegisteredCollectorsBuilder(
          int index) {
        return getRegisteredCollectorsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto registered_collectors = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProtoOrBuilder getRegisteredCollectorsOrBuilder(
          int index) {
        if (registeredCollectorsBuilder_ == null) {
          return registeredCollectors_.get(index);  } else {
          return registeredCollectorsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto registered_collectors = 6;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProtoOrBuilder> 
           getRegisteredCollectorsOrBuilderList() {
        if (registeredCollectorsBuilder_ != null) {
          return registeredCollectorsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(registeredCollectors_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto registered_collectors = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.Builder addRegisteredCollectorsBuilder() {
        return getRegisteredCollectorsFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto registered_collectors = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.Builder addRegisteredCollectorsBuilder(
          int index) {
        return getRegisteredCollectorsFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto registered_collectors = 6;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.Builder> 
           getRegisteredCollectorsBuilderList() {
        return getRegisteredCollectorsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProtoOrBuilder> 
          getRegisteredCollectorsFieldBuilder() {
        if (registeredCollectorsBuilder_ == null) {
          registeredCollectorsBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProtoOrBuilder>(
                  registeredCollectors_,
                  ((bitField0_ & 0x00000020) == 0x00000020),
                  getParentForChildren(),
                  isClean());
          registeredCollectors_ = null;
        }
        return registeredCollectorsBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.NodeHeartbeatRequestProto)
    }

    static {
      defaultInstance = new NodeHeartbeatRequestProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.NodeHeartbeatRequestProto)
  }

  public interface LogAggregationReportProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.ApplicationIdProto application_id = 1;
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    boolean hasApplicationId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder();

    // optional .hadoop.yarn.LogAggregationStatusProto log_aggregation_status = 2;
    /**
     * <code>optional .hadoop.yarn.LogAggregationStatusProto log_aggregation_status = 2;</code>
     */
    boolean hasLogAggregationStatus();
    /**
     * <code>optional .hadoop.yarn.LogAggregationStatusProto log_aggregation_status = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationStatusProto getLogAggregationStatus();

    // optional string diagnostics = 3 [default = "N/A"];
    /**
     * <code>optional string diagnostics = 3 [default = "N/A"];</code>
     */
    boolean hasDiagnostics();
    /**
     * <code>optional string diagnostics = 3 [default = "N/A"];</code>
     */
    java.lang.String getDiagnostics();
    /**
     * <code>optional string diagnostics = 3 [default = "N/A"];</code>
     */
    com.google.protobuf.ByteString
        getDiagnosticsBytes();
  }
  /**
   * Protobuf type {@code hadoop.yarn.LogAggregationReportProto}
   */
  public static final class LogAggregationReportProto extends
      com.google.protobuf.GeneratedMessage
      implements LogAggregationReportProtoOrBuilder {
    // Use LogAggregationReportProto.newBuilder() to construct.
    private LogAggregationReportProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private LogAggregationReportProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final LogAggregationReportProto defaultInstance;
    public static LogAggregationReportProto getDefaultInstance() {
      return defaultInstance;
    }

    public LogAggregationReportProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private LogAggregationReportProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = applicationId_.toBuilder();
              }
              applicationId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(applicationId_);
                applicationId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 16: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationStatusProto value = org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationStatusProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(2, rawValue);
              } else {
                bitField0_ |= 0x00000002;
                logAggregationStatus_ = value;
              }
              break;
            }
            case 26: {
              bitField0_ |= 0x00000004;
              diagnostics_ = input.readBytes();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_LogAggregationReportProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_LogAggregationReportProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto.Builder.class);
    }

    public static com.google.protobuf.Parser<LogAggregationReportProto> PARSER =
        new com.google.protobuf.AbstractParser<LogAggregationReportProto>() {
      public LogAggregationReportProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new LogAggregationReportProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<LogAggregationReportProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.ApplicationIdProto application_id = 1;
    public static final int APPLICATION_ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_;
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    public boolean hasApplicationId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
      return applicationId_;
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
      return applicationId_;
    }

    // optional .hadoop.yarn.LogAggregationStatusProto log_aggregation_status = 2;
    public static final int LOG_AGGREGATION_STATUS_FIELD_NUMBER = 2;
    private org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationStatusProto logAggregationStatus_;
    /**
     * <code>optional .hadoop.yarn.LogAggregationStatusProto log_aggregation_status = 2;</code>
     */
    public boolean hasLogAggregationStatus() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.LogAggregationStatusProto log_aggregation_status = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationStatusProto getLogAggregationStatus() {
      return logAggregationStatus_;
    }

    // optional string diagnostics = 3 [default = "N/A"];
    public static final int DIAGNOSTICS_FIELD_NUMBER = 3;
    private java.lang.Object diagnostics_;
    /**
     * <code>optional string diagnostics = 3 [default = "N/A"];</code>
     */
    public boolean hasDiagnostics() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional string diagnostics = 3 [default = "N/A"];</code>
     */
    public java.lang.String getDiagnostics() {
      java.lang.Object ref = diagnostics_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          diagnostics_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string diagnostics = 3 [default = "N/A"];</code>
     */
    public com.google.protobuf.ByteString
        getDiagnosticsBytes() {
      java.lang.Object ref = diagnostics_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        diagnostics_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private void initFields() {
      applicationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
      logAggregationStatus_ = org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationStatusProto.LOG_DISABLED;
      diagnostics_ = "N/A";
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, applicationId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeEnum(2, logAggregationStatus_.getNumber());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBytes(3, getDiagnosticsBytes());
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, applicationId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(2, logAggregationStatus_.getNumber());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(3, getDiagnosticsBytes());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto other = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto) obj;

      boolean result = true;
      result = result && (hasApplicationId() == other.hasApplicationId());
      if (hasApplicationId()) {
        result = result && getApplicationId()
            .equals(other.getApplicationId());
      }
      result = result && (hasLogAggregationStatus() == other.hasLogAggregationStatus());
      if (hasLogAggregationStatus()) {
        result = result &&
            (getLogAggregationStatus() == other.getLogAggregationStatus());
      }
      result = result && (hasDiagnostics() == other.hasDiagnostics());
      if (hasDiagnostics()) {
        result = result && getDiagnostics()
            .equals(other.getDiagnostics());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasApplicationId()) {
        hash = (37 * hash) + APPLICATION_ID_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationId().hashCode();
      }
      if (hasLogAggregationStatus()) {
        hash = (37 * hash) + LOG_AGGREGATION_STATUS_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getLogAggregationStatus());
      }
      if (hasDiagnostics()) {
        hash = (37 * hash) + DIAGNOSTICS_FIELD_NUMBER;
        hash = (53 * hash) + getDiagnostics().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.LogAggregationReportProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_LogAggregationReportProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_LogAggregationReportProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getApplicationIdFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (applicationIdBuilder_ == null) {
          applicationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        logAggregationStatus_ = org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationStatusProto.LOG_DISABLED;
        bitField0_ = (bitField0_ & ~0x00000002);
        diagnostics_ = "N/A";
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_LogAggregationReportProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto build() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto result = new org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (applicationIdBuilder_ == null) {
          result.applicationId_ = applicationId_;
        } else {
          result.applicationId_ = applicationIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.logAggregationStatus_ = logAggregationStatus_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.diagnostics_ = diagnostics_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto.getDefaultInstance()) return this;
        if (other.hasApplicationId()) {
          mergeApplicationId(other.getApplicationId());
        }
        if (other.hasLogAggregationStatus()) {
          setLogAggregationStatus(other.getLogAggregationStatus());
        }
        if (other.hasDiagnostics()) {
          bitField0_ |= 0x00000004;
          diagnostics_ = other.diagnostics_;
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.LogAggregationReportProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.ApplicationIdProto application_id = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> applicationIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public boolean hasApplicationId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
        if (applicationIdBuilder_ == null) {
          return applicationId_;
        } else {
          return applicationIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder setApplicationId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          applicationId_ = value;
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder setApplicationId(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder builderForValue) {
        if (applicationIdBuilder_ == null) {
          applicationId_ = builderForValue.build();
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder mergeApplicationId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              applicationId_ != org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance()) {
            applicationId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.newBuilder(applicationId_).mergeFrom(value).buildPartial();
          } else {
            applicationId_ = value;
          }
          onChanged();
        } else {
          applicationIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder clearApplicationId() {
        if (applicationIdBuilder_ == null) {
          applicationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
          onChanged();
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder getApplicationIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getApplicationIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
        if (applicationIdBuilder_ != null) {
          return applicationIdBuilder_.getMessageOrBuilder();
        } else {
          return applicationId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> 
          getApplicationIdFieldBuilder() {
        if (applicationIdBuilder_ == null) {
          applicationIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder>(
                  applicationId_,
                  getParentForChildren(),
                  isClean());
          applicationId_ = null;
        }
        return applicationIdBuilder_;
      }

      // optional .hadoop.yarn.LogAggregationStatusProto log_aggregation_status = 2;
      private org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationStatusProto logAggregationStatus_ = org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationStatusProto.LOG_DISABLED;
      /**
       * <code>optional .hadoop.yarn.LogAggregationStatusProto log_aggregation_status = 2;</code>
       */
      public boolean hasLogAggregationStatus() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.LogAggregationStatusProto log_aggregation_status = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationStatusProto getLogAggregationStatus() {
        return logAggregationStatus_;
      }
      /**
       * <code>optional .hadoop.yarn.LogAggregationStatusProto log_aggregation_status = 2;</code>
       */
      public Builder setLogAggregationStatus(org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationStatusProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000002;
        logAggregationStatus_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.LogAggregationStatusProto log_aggregation_status = 2;</code>
       */
      public Builder clearLogAggregationStatus() {
        bitField0_ = (bitField0_ & ~0x00000002);
        logAggregationStatus_ = org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationStatusProto.LOG_DISABLED;
        onChanged();
        return this;
      }

      // optional string diagnostics = 3 [default = "N/A"];
      private java.lang.Object diagnostics_ = "N/A";
      /**
       * <code>optional string diagnostics = 3 [default = "N/A"];</code>
       */
      public boolean hasDiagnostics() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional string diagnostics = 3 [default = "N/A"];</code>
       */
      public java.lang.String getDiagnostics() {
        java.lang.Object ref = diagnostics_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          diagnostics_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string diagnostics = 3 [default = "N/A"];</code>
       */
      public com.google.protobuf.ByteString
          getDiagnosticsBytes() {
        java.lang.Object ref = diagnostics_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          diagnostics_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string diagnostics = 3 [default = "N/A"];</code>
       */
      public Builder setDiagnostics(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        diagnostics_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string diagnostics = 3 [default = "N/A"];</code>
       */
      public Builder clearDiagnostics() {
        bitField0_ = (bitField0_ & ~0x00000004);
        diagnostics_ = getDefaultInstance().getDiagnostics();
        onChanged();
        return this;
      }
      /**
       * <code>optional string diagnostics = 3 [default = "N/A"];</code>
       */
      public Builder setDiagnosticsBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        diagnostics_ = value;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.LogAggregationReportProto)
    }

    static {
      defaultInstance = new LogAggregationReportProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.LogAggregationReportProto)
  }

  public interface NodeHeartbeatResponseProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional int32 response_id = 1;
    /**
     * <code>optional int32 response_id = 1;</code>
     */
    boolean hasResponseId();
    /**
     * <code>optional int32 response_id = 1;</code>
     */
    int getResponseId();

    // optional .hadoop.yarn.MasterKeyProto container_token_master_key = 2;
    /**
     * <code>optional .hadoop.yarn.MasterKeyProto container_token_master_key = 2;</code>
     */
    boolean hasContainerTokenMasterKey();
    /**
     * <code>optional .hadoop.yarn.MasterKeyProto container_token_master_key = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto getContainerTokenMasterKey();
    /**
     * <code>optional .hadoop.yarn.MasterKeyProto container_token_master_key = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProtoOrBuilder getContainerTokenMasterKeyOrBuilder();

    // optional .hadoop.yarn.MasterKeyProto nm_token_master_key = 3;
    /**
     * <code>optional .hadoop.yarn.MasterKeyProto nm_token_master_key = 3;</code>
     */
    boolean hasNmTokenMasterKey();
    /**
     * <code>optional .hadoop.yarn.MasterKeyProto nm_token_master_key = 3;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto getNmTokenMasterKey();
    /**
     * <code>optional .hadoop.yarn.MasterKeyProto nm_token_master_key = 3;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProtoOrBuilder getNmTokenMasterKeyOrBuilder();

    // optional .hadoop.yarn.NodeActionProto nodeAction = 4;
    /**
     * <code>optional .hadoop.yarn.NodeActionProto nodeAction = 4;</code>
     */
    boolean hasNodeAction();
    /**
     * <code>optional .hadoop.yarn.NodeActionProto nodeAction = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeActionProto getNodeAction();

    // repeated .hadoop.yarn.ContainerIdProto containers_to_cleanup = 5;
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_cleanup = 5;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto> 
        getContainersToCleanupList();
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_cleanup = 5;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainersToCleanup(int index);
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_cleanup = 5;</code>
     */
    int getContainersToCleanupCount();
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_cleanup = 5;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
        getContainersToCleanupOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_cleanup = 5;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainersToCleanupOrBuilder(
        int index);

    // repeated .hadoop.yarn.ApplicationIdProto applications_to_cleanup = 6;
    /**
     * <code>repeated .hadoop.yarn.ApplicationIdProto applications_to_cleanup = 6;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto> 
        getApplicationsToCleanupList();
    /**
     * <code>repeated .hadoop.yarn.ApplicationIdProto applications_to_cleanup = 6;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationsToCleanup(int index);
    /**
     * <code>repeated .hadoop.yarn.ApplicationIdProto applications_to_cleanup = 6;</code>
     */
    int getApplicationsToCleanupCount();
    /**
     * <code>repeated .hadoop.yarn.ApplicationIdProto applications_to_cleanup = 6;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> 
        getApplicationsToCleanupOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ApplicationIdProto applications_to_cleanup = 6;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationsToCleanupOrBuilder(
        int index);

    // optional int64 nextHeartBeatInterval = 7;
    /**
     * <code>optional int64 nextHeartBeatInterval = 7;</code>
     */
    boolean hasNextHeartBeatInterval();
    /**
     * <code>optional int64 nextHeartBeatInterval = 7;</code>
     */
    long getNextHeartBeatInterval();

    // optional string diagnostics_message = 8;
    /**
     * <code>optional string diagnostics_message = 8;</code>
     */
    boolean hasDiagnosticsMessage();
    /**
     * <code>optional string diagnostics_message = 8;</code>
     */
    java.lang.String getDiagnosticsMessage();
    /**
     * <code>optional string diagnostics_message = 8;</code>
     */
    com.google.protobuf.ByteString
        getDiagnosticsMessageBytes();

    // repeated .hadoop.yarn.ContainerIdProto containers_to_be_removed_from_nm = 9;
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_be_removed_from_nm = 9;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto> 
        getContainersToBeRemovedFromNmList();
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_be_removed_from_nm = 9;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainersToBeRemovedFromNm(int index);
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_be_removed_from_nm = 9;</code>
     */
    int getContainersToBeRemovedFromNmCount();
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_be_removed_from_nm = 9;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
        getContainersToBeRemovedFromNmOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_be_removed_from_nm = 9;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainersToBeRemovedFromNmOrBuilder(
        int index);

    // repeated .hadoop.yarn.SystemCredentialsForAppsProto system_credentials_for_apps = 10;
    /**
     * <code>repeated .hadoop.yarn.SystemCredentialsForAppsProto system_credentials_for_apps = 10;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto> 
        getSystemCredentialsForAppsList();
    /**
     * <code>repeated .hadoop.yarn.SystemCredentialsForAppsProto system_credentials_for_apps = 10;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto getSystemCredentialsForApps(int index);
    /**
     * <code>repeated .hadoop.yarn.SystemCredentialsForAppsProto system_credentials_for_apps = 10;</code>
     */
    int getSystemCredentialsForAppsCount();
    /**
     * <code>repeated .hadoop.yarn.SystemCredentialsForAppsProto system_credentials_for_apps = 10;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProtoOrBuilder> 
        getSystemCredentialsForAppsOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.SystemCredentialsForAppsProto system_credentials_for_apps = 10;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProtoOrBuilder getSystemCredentialsForAppsOrBuilder(
        int index);

    // optional bool areNodeLabelsAcceptedByRM = 11 [default = false];
    /**
     * <code>optional bool areNodeLabelsAcceptedByRM = 11 [default = false];</code>
     */
    boolean hasAreNodeLabelsAcceptedByRM();
    /**
     * <code>optional bool areNodeLabelsAcceptedByRM = 11 [default = false];</code>
     */
    boolean getAreNodeLabelsAcceptedByRM();

    // repeated .hadoop.yarn.ContainerProto containers_to_decrease = 12;
    /**
     * <code>repeated .hadoop.yarn.ContainerProto containers_to_decrease = 12;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto> 
        getContainersToDecreaseList();
    /**
     * <code>repeated .hadoop.yarn.ContainerProto containers_to_decrease = 12;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto getContainersToDecrease(int index);
    /**
     * <code>repeated .hadoop.yarn.ContainerProto containers_to_decrease = 12;</code>
     */
    int getContainersToDecreaseCount();
    /**
     * <code>repeated .hadoop.yarn.ContainerProto containers_to_decrease = 12;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder> 
        getContainersToDecreaseOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ContainerProto containers_to_decrease = 12;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder getContainersToDecreaseOrBuilder(
        int index);

    // repeated .hadoop.yarn.SignalContainerRequestProto containers_to_signal = 13;
    /**
     * <code>repeated .hadoop.yarn.SignalContainerRequestProto containers_to_signal = 13;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto> 
        getContainersToSignalList();
    /**
     * <code>repeated .hadoop.yarn.SignalContainerRequestProto containers_to_signal = 13;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto getContainersToSignal(int index);
    /**
     * <code>repeated .hadoop.yarn.SignalContainerRequestProto containers_to_signal = 13;</code>
     */
    int getContainersToSignalCount();
    /**
     * <code>repeated .hadoop.yarn.SignalContainerRequestProto containers_to_signal = 13;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProtoOrBuilder> 
        getContainersToSignalOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.SignalContainerRequestProto containers_to_signal = 13;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProtoOrBuilder getContainersToSignalOrBuilder(
        int index);

    // optional .hadoop.yarn.ResourceProto resource = 14;
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 14;</code>
     */
    boolean hasResource();
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 14;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource();
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 14;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder();

    // optional .hadoop.yarn.ContainerQueuingLimitProto container_queuing_limit = 15;
    /**
     * <code>optional .hadoop.yarn.ContainerQueuingLimitProto container_queuing_limit = 15;</code>
     */
    boolean hasContainerQueuingLimit();
    /**
     * <code>optional .hadoop.yarn.ContainerQueuingLimitProto container_queuing_limit = 15;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto getContainerQueuingLimit();
    /**
     * <code>optional .hadoop.yarn.ContainerQueuingLimitProto container_queuing_limit = 15;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProtoOrBuilder getContainerQueuingLimitOrBuilder();

    // repeated .hadoop.yarn.AppCollectorsMapProto app_collectors_map = 16;
    /**
     * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors_map = 16;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto> 
        getAppCollectorsMapList();
    /**
     * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors_map = 16;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto getAppCollectorsMap(int index);
    /**
     * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors_map = 16;</code>
     */
    int getAppCollectorsMapCount();
    /**
     * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors_map = 16;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProtoOrBuilder> 
        getAppCollectorsMapOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors_map = 16;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProtoOrBuilder getAppCollectorsMapOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.NodeHeartbeatResponseProto}
   */
  public static final class NodeHeartbeatResponseProto extends
      com.google.protobuf.GeneratedMessage
      implements NodeHeartbeatResponseProtoOrBuilder {
    // Use NodeHeartbeatResponseProto.newBuilder() to construct.
    private NodeHeartbeatResponseProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private NodeHeartbeatResponseProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final NodeHeartbeatResponseProto defaultInstance;
    public static NodeHeartbeatResponseProto getDefaultInstance() {
      return defaultInstance;
    }

    public NodeHeartbeatResponseProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private NodeHeartbeatResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              responseId_ = input.readInt32();
              break;
            }
            case 18: {
              org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = containerTokenMasterKey_.toBuilder();
              }
              containerTokenMasterKey_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(containerTokenMasterKey_);
                containerTokenMasterKey_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = nmTokenMasterKey_.toBuilder();
              }
              nmTokenMasterKey_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(nmTokenMasterKey_);
                nmTokenMasterKey_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
            case 32: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeActionProto value = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeActionProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(4, rawValue);
              } else {
                bitField0_ |= 0x00000008;
                nodeAction_ = value;
              }
              break;
            }
            case 42: {
              if (!((mutable_bitField0_ & 0x00000010) == 0x00000010)) {
                containersToCleanup_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto>();
                mutable_bitField0_ |= 0x00000010;
              }
              containersToCleanup_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.PARSER, extensionRegistry));
              break;
            }
            case 50: {
              if (!((mutable_bitField0_ & 0x00000020) == 0x00000020)) {
                applicationsToCleanup_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto>();
                mutable_bitField0_ |= 0x00000020;
              }
              applicationsToCleanup_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.PARSER, extensionRegistry));
              break;
            }
            case 56: {
              bitField0_ |= 0x00000010;
              nextHeartBeatInterval_ = input.readInt64();
              break;
            }
            case 66: {
              bitField0_ |= 0x00000020;
              diagnosticsMessage_ = input.readBytes();
              break;
            }
            case 74: {
              if (!((mutable_bitField0_ & 0x00000100) == 0x00000100)) {
                containersToBeRemovedFromNm_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto>();
                mutable_bitField0_ |= 0x00000100;
              }
              containersToBeRemovedFromNm_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.PARSER, extensionRegistry));
              break;
            }
            case 82: {
              if (!((mutable_bitField0_ & 0x00000200) == 0x00000200)) {
                systemCredentialsForApps_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto>();
                mutable_bitField0_ |= 0x00000200;
              }
              systemCredentialsForApps_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto.PARSER, extensionRegistry));
              break;
            }
            case 88: {
              bitField0_ |= 0x00000040;
              areNodeLabelsAcceptedByRM_ = input.readBool();
              break;
            }
            case 98: {
              if (!((mutable_bitField0_ & 0x00000800) == 0x00000800)) {
                containersToDecrease_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto>();
                mutable_bitField0_ |= 0x00000800;
              }
              containersToDecrease_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.PARSER, extensionRegistry));
              break;
            }
            case 106: {
              if (!((mutable_bitField0_ & 0x00001000) == 0x00001000)) {
                containersToSignal_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto>();
                mutable_bitField0_ |= 0x00001000;
              }
              containersToSignal_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto.PARSER, extensionRegistry));
              break;
            }
            case 114: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000080) == 0x00000080)) {
                subBuilder = resource_.toBuilder();
              }
              resource_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(resource_);
                resource_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000080;
              break;
            }
            case 122: {
              org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000100) == 0x00000100)) {
                subBuilder = containerQueuingLimit_.toBuilder();
              }
              containerQueuingLimit_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(containerQueuingLimit_);
                containerQueuingLimit_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000100;
              break;
            }
            case 130: {
              if (!((mutable_bitField0_ & 0x00008000) == 0x00008000)) {
                appCollectorsMap_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto>();
                mutable_bitField0_ |= 0x00008000;
              }
              appCollectorsMap_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000010) == 0x00000010)) {
          containersToCleanup_ = java.util.Collections.unmodifiableList(containersToCleanup_);
        }
        if (((mutable_bitField0_ & 0x00000020) == 0x00000020)) {
          applicationsToCleanup_ = java.util.Collections.unmodifiableList(applicationsToCleanup_);
        }
        if (((mutable_bitField0_ & 0x00000100) == 0x00000100)) {
          containersToBeRemovedFromNm_ = java.util.Collections.unmodifiableList(containersToBeRemovedFromNm_);
        }
        if (((mutable_bitField0_ & 0x00000200) == 0x00000200)) {
          systemCredentialsForApps_ = java.util.Collections.unmodifiableList(systemCredentialsForApps_);
        }
        if (((mutable_bitField0_ & 0x00000800) == 0x00000800)) {
          containersToDecrease_ = java.util.Collections.unmodifiableList(containersToDecrease_);
        }
        if (((mutable_bitField0_ & 0x00001000) == 0x00001000)) {
          containersToSignal_ = java.util.Collections.unmodifiableList(containersToSignal_);
        }
        if (((mutable_bitField0_ & 0x00008000) == 0x00008000)) {
          appCollectorsMap_ = java.util.Collections.unmodifiableList(appCollectorsMap_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_NodeHeartbeatResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_NodeHeartbeatResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto.Builder.class);
    }

    public static com.google.protobuf.Parser<NodeHeartbeatResponseProto> PARSER =
        new com.google.protobuf.AbstractParser<NodeHeartbeatResponseProto>() {
      public NodeHeartbeatResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new NodeHeartbeatResponseProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<NodeHeartbeatResponseProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional int32 response_id = 1;
    public static final int RESPONSE_ID_FIELD_NUMBER = 1;
    private int responseId_;
    /**
     * <code>optional int32 response_id = 1;</code>
     */
    public boolean hasResponseId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional int32 response_id = 1;</code>
     */
    public int getResponseId() {
      return responseId_;
    }

    // optional .hadoop.yarn.MasterKeyProto container_token_master_key = 2;
    public static final int CONTAINER_TOKEN_MASTER_KEY_FIELD_NUMBER = 2;
    private org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto containerTokenMasterKey_;
    /**
     * <code>optional .hadoop.yarn.MasterKeyProto container_token_master_key = 2;</code>
     */
    public boolean hasContainerTokenMasterKey() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.MasterKeyProto container_token_master_key = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto getContainerTokenMasterKey() {
      return containerTokenMasterKey_;
    }
    /**
     * <code>optional .hadoop.yarn.MasterKeyProto container_token_master_key = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProtoOrBuilder getContainerTokenMasterKeyOrBuilder() {
      return containerTokenMasterKey_;
    }

    // optional .hadoop.yarn.MasterKeyProto nm_token_master_key = 3;
    public static final int NM_TOKEN_MASTER_KEY_FIELD_NUMBER = 3;
    private org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto nmTokenMasterKey_;
    /**
     * <code>optional .hadoop.yarn.MasterKeyProto nm_token_master_key = 3;</code>
     */
    public boolean hasNmTokenMasterKey() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional .hadoop.yarn.MasterKeyProto nm_token_master_key = 3;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto getNmTokenMasterKey() {
      return nmTokenMasterKey_;
    }
    /**
     * <code>optional .hadoop.yarn.MasterKeyProto nm_token_master_key = 3;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProtoOrBuilder getNmTokenMasterKeyOrBuilder() {
      return nmTokenMasterKey_;
    }

    // optional .hadoop.yarn.NodeActionProto nodeAction = 4;
    public static final int NODEACTION_FIELD_NUMBER = 4;
    private org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeActionProto nodeAction_;
    /**
     * <code>optional .hadoop.yarn.NodeActionProto nodeAction = 4;</code>
     */
    public boolean hasNodeAction() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional .hadoop.yarn.NodeActionProto nodeAction = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeActionProto getNodeAction() {
      return nodeAction_;
    }

    // repeated .hadoop.yarn.ContainerIdProto containers_to_cleanup = 5;
    public static final int CONTAINERS_TO_CLEANUP_FIELD_NUMBER = 5;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto> containersToCleanup_;
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_cleanup = 5;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto> getContainersToCleanupList() {
      return containersToCleanup_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_cleanup = 5;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
        getContainersToCleanupOrBuilderList() {
      return containersToCleanup_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_cleanup = 5;</code>
     */
    public int getContainersToCleanupCount() {
      return containersToCleanup_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_cleanup = 5;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainersToCleanup(int index) {
      return containersToCleanup_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_cleanup = 5;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainersToCleanupOrBuilder(
        int index) {
      return containersToCleanup_.get(index);
    }

    // repeated .hadoop.yarn.ApplicationIdProto applications_to_cleanup = 6;
    public static final int APPLICATIONS_TO_CLEANUP_FIELD_NUMBER = 6;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto> applicationsToCleanup_;
    /**
     * <code>repeated .hadoop.yarn.ApplicationIdProto applications_to_cleanup = 6;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto> getApplicationsToCleanupList() {
      return applicationsToCleanup_;
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationIdProto applications_to_cleanup = 6;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> 
        getApplicationsToCleanupOrBuilderList() {
      return applicationsToCleanup_;
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationIdProto applications_to_cleanup = 6;</code>
     */
    public int getApplicationsToCleanupCount() {
      return applicationsToCleanup_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationIdProto applications_to_cleanup = 6;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationsToCleanup(int index) {
      return applicationsToCleanup_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationIdProto applications_to_cleanup = 6;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationsToCleanupOrBuilder(
        int index) {
      return applicationsToCleanup_.get(index);
    }

    // optional int64 nextHeartBeatInterval = 7;
    public static final int NEXTHEARTBEATINTERVAL_FIELD_NUMBER = 7;
    private long nextHeartBeatInterval_;
    /**
     * <code>optional int64 nextHeartBeatInterval = 7;</code>
     */
    public boolean hasNextHeartBeatInterval() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional int64 nextHeartBeatInterval = 7;</code>
     */
    public long getNextHeartBeatInterval() {
      return nextHeartBeatInterval_;
    }

    // optional string diagnostics_message = 8;
    public static final int DIAGNOSTICS_MESSAGE_FIELD_NUMBER = 8;
    private java.lang.Object diagnosticsMessage_;
    /**
     * <code>optional string diagnostics_message = 8;</code>
     */
    public boolean hasDiagnosticsMessage() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional string diagnostics_message = 8;</code>
     */
    public java.lang.String getDiagnosticsMessage() {
      java.lang.Object ref = diagnosticsMessage_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          diagnosticsMessage_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string diagnostics_message = 8;</code>
     */
    public com.google.protobuf.ByteString
        getDiagnosticsMessageBytes() {
      java.lang.Object ref = diagnosticsMessage_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        diagnosticsMessage_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // repeated .hadoop.yarn.ContainerIdProto containers_to_be_removed_from_nm = 9;
    public static final int CONTAINERS_TO_BE_REMOVED_FROM_NM_FIELD_NUMBER = 9;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto> containersToBeRemovedFromNm_;
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_be_removed_from_nm = 9;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto> getContainersToBeRemovedFromNmList() {
      return containersToBeRemovedFromNm_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_be_removed_from_nm = 9;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
        getContainersToBeRemovedFromNmOrBuilderList() {
      return containersToBeRemovedFromNm_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_be_removed_from_nm = 9;</code>
     */
    public int getContainersToBeRemovedFromNmCount() {
      return containersToBeRemovedFromNm_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_be_removed_from_nm = 9;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainersToBeRemovedFromNm(int index) {
      return containersToBeRemovedFromNm_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_be_removed_from_nm = 9;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainersToBeRemovedFromNmOrBuilder(
        int index) {
      return containersToBeRemovedFromNm_.get(index);
    }

    // repeated .hadoop.yarn.SystemCredentialsForAppsProto system_credentials_for_apps = 10;
    public static final int SYSTEM_CREDENTIALS_FOR_APPS_FIELD_NUMBER = 10;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto> systemCredentialsForApps_;
    /**
     * <code>repeated .hadoop.yarn.SystemCredentialsForAppsProto system_credentials_for_apps = 10;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto> getSystemCredentialsForAppsList() {
      return systemCredentialsForApps_;
    }
    /**
     * <code>repeated .hadoop.yarn.SystemCredentialsForAppsProto system_credentials_for_apps = 10;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProtoOrBuilder> 
        getSystemCredentialsForAppsOrBuilderList() {
      return systemCredentialsForApps_;
    }
    /**
     * <code>repeated .hadoop.yarn.SystemCredentialsForAppsProto system_credentials_for_apps = 10;</code>
     */
    public int getSystemCredentialsForAppsCount() {
      return systemCredentialsForApps_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.SystemCredentialsForAppsProto system_credentials_for_apps = 10;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto getSystemCredentialsForApps(int index) {
      return systemCredentialsForApps_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.SystemCredentialsForAppsProto system_credentials_for_apps = 10;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProtoOrBuilder getSystemCredentialsForAppsOrBuilder(
        int index) {
      return systemCredentialsForApps_.get(index);
    }

    // optional bool areNodeLabelsAcceptedByRM = 11 [default = false];
    public static final int ARENODELABELSACCEPTEDBYRM_FIELD_NUMBER = 11;
    private boolean areNodeLabelsAcceptedByRM_;
    /**
     * <code>optional bool areNodeLabelsAcceptedByRM = 11 [default = false];</code>
     */
    public boolean hasAreNodeLabelsAcceptedByRM() {
      return ((bitField0_ & 0x00000040) == 0x00000040);
    }
    /**
     * <code>optional bool areNodeLabelsAcceptedByRM = 11 [default = false];</code>
     */
    public boolean getAreNodeLabelsAcceptedByRM() {
      return areNodeLabelsAcceptedByRM_;
    }

    // repeated .hadoop.yarn.ContainerProto containers_to_decrease = 12;
    public static final int CONTAINERS_TO_DECREASE_FIELD_NUMBER = 12;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto> containersToDecrease_;
    /**
     * <code>repeated .hadoop.yarn.ContainerProto containers_to_decrease = 12;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto> getContainersToDecreaseList() {
      return containersToDecrease_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerProto containers_to_decrease = 12;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder> 
        getContainersToDecreaseOrBuilderList() {
      return containersToDecrease_;
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerProto containers_to_decrease = 12;</code>
     */
    public int getContainersToDecreaseCount() {
      return containersToDecrease_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerProto containers_to_decrease = 12;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto getContainersToDecrease(int index) {
      return containersToDecrease_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ContainerProto containers_to_decrease = 12;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder getContainersToDecreaseOrBuilder(
        int index) {
      return containersToDecrease_.get(index);
    }

    // repeated .hadoop.yarn.SignalContainerRequestProto containers_to_signal = 13;
    public static final int CONTAINERS_TO_SIGNAL_FIELD_NUMBER = 13;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto> containersToSignal_;
    /**
     * <code>repeated .hadoop.yarn.SignalContainerRequestProto containers_to_signal = 13;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto> getContainersToSignalList() {
      return containersToSignal_;
    }
    /**
     * <code>repeated .hadoop.yarn.SignalContainerRequestProto containers_to_signal = 13;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProtoOrBuilder> 
        getContainersToSignalOrBuilderList() {
      return containersToSignal_;
    }
    /**
     * <code>repeated .hadoop.yarn.SignalContainerRequestProto containers_to_signal = 13;</code>
     */
    public int getContainersToSignalCount() {
      return containersToSignal_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.SignalContainerRequestProto containers_to_signal = 13;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto getContainersToSignal(int index) {
      return containersToSignal_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.SignalContainerRequestProto containers_to_signal = 13;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProtoOrBuilder getContainersToSignalOrBuilder(
        int index) {
      return containersToSignal_.get(index);
    }

    // optional .hadoop.yarn.ResourceProto resource = 14;
    public static final int RESOURCE_FIELD_NUMBER = 14;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto resource_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 14;</code>
     */
    public boolean hasResource() {
      return ((bitField0_ & 0x00000080) == 0x00000080);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 14;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource() {
      return resource_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 14;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder() {
      return resource_;
    }

    // optional .hadoop.yarn.ContainerQueuingLimitProto container_queuing_limit = 15;
    public static final int CONTAINER_QUEUING_LIMIT_FIELD_NUMBER = 15;
    private org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto containerQueuingLimit_;
    /**
     * <code>optional .hadoop.yarn.ContainerQueuingLimitProto container_queuing_limit = 15;</code>
     */
    public boolean hasContainerQueuingLimit() {
      return ((bitField0_ & 0x00000100) == 0x00000100);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerQueuingLimitProto container_queuing_limit = 15;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto getContainerQueuingLimit() {
      return containerQueuingLimit_;
    }
    /**
     * <code>optional .hadoop.yarn.ContainerQueuingLimitProto container_queuing_limit = 15;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProtoOrBuilder getContainerQueuingLimitOrBuilder() {
      return containerQueuingLimit_;
    }

    // repeated .hadoop.yarn.AppCollectorsMapProto app_collectors_map = 16;
    public static final int APP_COLLECTORS_MAP_FIELD_NUMBER = 16;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto> appCollectorsMap_;
    /**
     * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors_map = 16;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto> getAppCollectorsMapList() {
      return appCollectorsMap_;
    }
    /**
     * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors_map = 16;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProtoOrBuilder> 
        getAppCollectorsMapOrBuilderList() {
      return appCollectorsMap_;
    }
    /**
     * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors_map = 16;</code>
     */
    public int getAppCollectorsMapCount() {
      return appCollectorsMap_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors_map = 16;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto getAppCollectorsMap(int index) {
      return appCollectorsMap_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors_map = 16;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProtoOrBuilder getAppCollectorsMapOrBuilder(
        int index) {
      return appCollectorsMap_.get(index);
    }

    private void initFields() {
      responseId_ = 0;
      containerTokenMasterKey_ = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.getDefaultInstance();
      nmTokenMasterKey_ = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.getDefaultInstance();
      nodeAction_ = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeActionProto.NORMAL;
      containersToCleanup_ = java.util.Collections.emptyList();
      applicationsToCleanup_ = java.util.Collections.emptyList();
      nextHeartBeatInterval_ = 0L;
      diagnosticsMessage_ = "";
      containersToBeRemovedFromNm_ = java.util.Collections.emptyList();
      systemCredentialsForApps_ = java.util.Collections.emptyList();
      areNodeLabelsAcceptedByRM_ = false;
      containersToDecrease_ = java.util.Collections.emptyList();
      containersToSignal_ = java.util.Collections.emptyList();
      resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      containerQueuingLimit_ = org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto.getDefaultInstance();
      appCollectorsMap_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      for (int i = 0; i < getContainersToDecreaseCount(); i++) {
        if (!getContainersToDecrease(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getContainersToSignalCount(); i++) {
        if (!getContainersToSignal(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeInt32(1, responseId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, containerTokenMasterKey_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(3, nmTokenMasterKey_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeEnum(4, nodeAction_.getNumber());
      }
      for (int i = 0; i < containersToCleanup_.size(); i++) {
        output.writeMessage(5, containersToCleanup_.get(i));
      }
      for (int i = 0; i < applicationsToCleanup_.size(); i++) {
        output.writeMessage(6, applicationsToCleanup_.get(i));
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeInt64(7, nextHeartBeatInterval_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeBytes(8, getDiagnosticsMessageBytes());
      }
      for (int i = 0; i < containersToBeRemovedFromNm_.size(); i++) {
        output.writeMessage(9, containersToBeRemovedFromNm_.get(i));
      }
      for (int i = 0; i < systemCredentialsForApps_.size(); i++) {
        output.writeMessage(10, systemCredentialsForApps_.get(i));
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        output.writeBool(11, areNodeLabelsAcceptedByRM_);
      }
      for (int i = 0; i < containersToDecrease_.size(); i++) {
        output.writeMessage(12, containersToDecrease_.get(i));
      }
      for (int i = 0; i < containersToSignal_.size(); i++) {
        output.writeMessage(13, containersToSignal_.get(i));
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        output.writeMessage(14, resource_);
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        output.writeMessage(15, containerQueuingLimit_);
      }
      for (int i = 0; i < appCollectorsMap_.size(); i++) {
        output.writeMessage(16, appCollectorsMap_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(1, responseId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, containerTokenMasterKey_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, nmTokenMasterKey_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(4, nodeAction_.getNumber());
      }
      for (int i = 0; i < containersToCleanup_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, containersToCleanup_.get(i));
      }
      for (int i = 0; i < applicationsToCleanup_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, applicationsToCleanup_.get(i));
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(7, nextHeartBeatInterval_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(8, getDiagnosticsMessageBytes());
      }
      for (int i = 0; i < containersToBeRemovedFromNm_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(9, containersToBeRemovedFromNm_.get(i));
      }
      for (int i = 0; i < systemCredentialsForApps_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(10, systemCredentialsForApps_.get(i));
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(11, areNodeLabelsAcceptedByRM_);
      }
      for (int i = 0; i < containersToDecrease_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(12, containersToDecrease_.get(i));
      }
      for (int i = 0; i < containersToSignal_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(13, containersToSignal_.get(i));
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(14, resource_);
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(15, containerQueuingLimit_);
      }
      for (int i = 0; i < appCollectorsMap_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(16, appCollectorsMap_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto other = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto) obj;

      boolean result = true;
      result = result && (hasResponseId() == other.hasResponseId());
      if (hasResponseId()) {
        result = result && (getResponseId()
            == other.getResponseId());
      }
      result = result && (hasContainerTokenMasterKey() == other.hasContainerTokenMasterKey());
      if (hasContainerTokenMasterKey()) {
        result = result && getContainerTokenMasterKey()
            .equals(other.getContainerTokenMasterKey());
      }
      result = result && (hasNmTokenMasterKey() == other.hasNmTokenMasterKey());
      if (hasNmTokenMasterKey()) {
        result = result && getNmTokenMasterKey()
            .equals(other.getNmTokenMasterKey());
      }
      result = result && (hasNodeAction() == other.hasNodeAction());
      if (hasNodeAction()) {
        result = result &&
            (getNodeAction() == other.getNodeAction());
      }
      result = result && getContainersToCleanupList()
          .equals(other.getContainersToCleanupList());
      result = result && getApplicationsToCleanupList()
          .equals(other.getApplicationsToCleanupList());
      result = result && (hasNextHeartBeatInterval() == other.hasNextHeartBeatInterval());
      if (hasNextHeartBeatInterval()) {
        result = result && (getNextHeartBeatInterval()
            == other.getNextHeartBeatInterval());
      }
      result = result && (hasDiagnosticsMessage() == other.hasDiagnosticsMessage());
      if (hasDiagnosticsMessage()) {
        result = result && getDiagnosticsMessage()
            .equals(other.getDiagnosticsMessage());
      }
      result = result && getContainersToBeRemovedFromNmList()
          .equals(other.getContainersToBeRemovedFromNmList());
      result = result && getSystemCredentialsForAppsList()
          .equals(other.getSystemCredentialsForAppsList());
      result = result && (hasAreNodeLabelsAcceptedByRM() == other.hasAreNodeLabelsAcceptedByRM());
      if (hasAreNodeLabelsAcceptedByRM()) {
        result = result && (getAreNodeLabelsAcceptedByRM()
            == other.getAreNodeLabelsAcceptedByRM());
      }
      result = result && getContainersToDecreaseList()
          .equals(other.getContainersToDecreaseList());
      result = result && getContainersToSignalList()
          .equals(other.getContainersToSignalList());
      result = result && (hasResource() == other.hasResource());
      if (hasResource()) {
        result = result && getResource()
            .equals(other.getResource());
      }
      result = result && (hasContainerQueuingLimit() == other.hasContainerQueuingLimit());
      if (hasContainerQueuingLimit()) {
        result = result && getContainerQueuingLimit()
            .equals(other.getContainerQueuingLimit());
      }
      result = result && getAppCollectorsMapList()
          .equals(other.getAppCollectorsMapList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasResponseId()) {
        hash = (37 * hash) + RESPONSE_ID_FIELD_NUMBER;
        hash = (53 * hash) + getResponseId();
      }
      if (hasContainerTokenMasterKey()) {
        hash = (37 * hash) + CONTAINER_TOKEN_MASTER_KEY_FIELD_NUMBER;
        hash = (53 * hash) + getContainerTokenMasterKey().hashCode();
      }
      if (hasNmTokenMasterKey()) {
        hash = (37 * hash) + NM_TOKEN_MASTER_KEY_FIELD_NUMBER;
        hash = (53 * hash) + getNmTokenMasterKey().hashCode();
      }
      if (hasNodeAction()) {
        hash = (37 * hash) + NODEACTION_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getNodeAction());
      }
      if (getContainersToCleanupCount() > 0) {
        hash = (37 * hash) + CONTAINERS_TO_CLEANUP_FIELD_NUMBER;
        hash = (53 * hash) + getContainersToCleanupList().hashCode();
      }
      if (getApplicationsToCleanupCount() > 0) {
        hash = (37 * hash) + APPLICATIONS_TO_CLEANUP_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationsToCleanupList().hashCode();
      }
      if (hasNextHeartBeatInterval()) {
        hash = (37 * hash) + NEXTHEARTBEATINTERVAL_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getNextHeartBeatInterval());
      }
      if (hasDiagnosticsMessage()) {
        hash = (37 * hash) + DIAGNOSTICS_MESSAGE_FIELD_NUMBER;
        hash = (53 * hash) + getDiagnosticsMessage().hashCode();
      }
      if (getContainersToBeRemovedFromNmCount() > 0) {
        hash = (37 * hash) + CONTAINERS_TO_BE_REMOVED_FROM_NM_FIELD_NUMBER;
        hash = (53 * hash) + getContainersToBeRemovedFromNmList().hashCode();
      }
      if (getSystemCredentialsForAppsCount() > 0) {
        hash = (37 * hash) + SYSTEM_CREDENTIALS_FOR_APPS_FIELD_NUMBER;
        hash = (53 * hash) + getSystemCredentialsForAppsList().hashCode();
      }
      if (hasAreNodeLabelsAcceptedByRM()) {
        hash = (37 * hash) + ARENODELABELSACCEPTEDBYRM_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getAreNodeLabelsAcceptedByRM());
      }
      if (getContainersToDecreaseCount() > 0) {
        hash = (37 * hash) + CONTAINERS_TO_DECREASE_FIELD_NUMBER;
        hash = (53 * hash) + getContainersToDecreaseList().hashCode();
      }
      if (getContainersToSignalCount() > 0) {
        hash = (37 * hash) + CONTAINERS_TO_SIGNAL_FIELD_NUMBER;
        hash = (53 * hash) + getContainersToSignalList().hashCode();
      }
      if (hasResource()) {
        hash = (37 * hash) + RESOURCE_FIELD_NUMBER;
        hash = (53 * hash) + getResource().hashCode();
      }
      if (hasContainerQueuingLimit()) {
        hash = (37 * hash) + CONTAINER_QUEUING_LIMIT_FIELD_NUMBER;
        hash = (53 * hash) + getContainerQueuingLimit().hashCode();
      }
      if (getAppCollectorsMapCount() > 0) {
        hash = (37 * hash) + APP_COLLECTORS_MAP_FIELD_NUMBER;
        hash = (53 * hash) + getAppCollectorsMapList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.NodeHeartbeatResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_NodeHeartbeatResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_NodeHeartbeatResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getContainerTokenMasterKeyFieldBuilder();
          getNmTokenMasterKeyFieldBuilder();
          getContainersToCleanupFieldBuilder();
          getApplicationsToCleanupFieldBuilder();
          getContainersToBeRemovedFromNmFieldBuilder();
          getSystemCredentialsForAppsFieldBuilder();
          getContainersToDecreaseFieldBuilder();
          getContainersToSignalFieldBuilder();
          getResourceFieldBuilder();
          getContainerQueuingLimitFieldBuilder();
          getAppCollectorsMapFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        responseId_ = 0;
        bitField0_ = (bitField0_ & ~0x00000001);
        if (containerTokenMasterKeyBuilder_ == null) {
          containerTokenMasterKey_ = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.getDefaultInstance();
        } else {
          containerTokenMasterKeyBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (nmTokenMasterKeyBuilder_ == null) {
          nmTokenMasterKey_ = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.getDefaultInstance();
        } else {
          nmTokenMasterKeyBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        nodeAction_ = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeActionProto.NORMAL;
        bitField0_ = (bitField0_ & ~0x00000008);
        if (containersToCleanupBuilder_ == null) {
          containersToCleanup_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000010);
        } else {
          containersToCleanupBuilder_.clear();
        }
        if (applicationsToCleanupBuilder_ == null) {
          applicationsToCleanup_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000020);
        } else {
          applicationsToCleanupBuilder_.clear();
        }
        nextHeartBeatInterval_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000040);
        diagnosticsMessage_ = "";
        bitField0_ = (bitField0_ & ~0x00000080);
        if (containersToBeRemovedFromNmBuilder_ == null) {
          containersToBeRemovedFromNm_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000100);
        } else {
          containersToBeRemovedFromNmBuilder_.clear();
        }
        if (systemCredentialsForAppsBuilder_ == null) {
          systemCredentialsForApps_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000200);
        } else {
          systemCredentialsForAppsBuilder_.clear();
        }
        areNodeLabelsAcceptedByRM_ = false;
        bitField0_ = (bitField0_ & ~0x00000400);
        if (containersToDecreaseBuilder_ == null) {
          containersToDecrease_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000800);
        } else {
          containersToDecreaseBuilder_.clear();
        }
        if (containersToSignalBuilder_ == null) {
          containersToSignal_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00001000);
        } else {
          containersToSignalBuilder_.clear();
        }
        if (resourceBuilder_ == null) {
          resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00002000);
        if (containerQueuingLimitBuilder_ == null) {
          containerQueuingLimit_ = org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto.getDefaultInstance();
        } else {
          containerQueuingLimitBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00004000);
        if (appCollectorsMapBuilder_ == null) {
          appCollectorsMap_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00008000);
        } else {
          appCollectorsMapBuilder_.clear();
        }
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_NodeHeartbeatResponseProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto build() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto result = new org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.responseId_ = responseId_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (containerTokenMasterKeyBuilder_ == null) {
          result.containerTokenMasterKey_ = containerTokenMasterKey_;
        } else {
          result.containerTokenMasterKey_ = containerTokenMasterKeyBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (nmTokenMasterKeyBuilder_ == null) {
          result.nmTokenMasterKey_ = nmTokenMasterKey_;
        } else {
          result.nmTokenMasterKey_ = nmTokenMasterKeyBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.nodeAction_ = nodeAction_;
        if (containersToCleanupBuilder_ == null) {
          if (((bitField0_ & 0x00000010) == 0x00000010)) {
            containersToCleanup_ = java.util.Collections.unmodifiableList(containersToCleanup_);
            bitField0_ = (bitField0_ & ~0x00000010);
          }
          result.containersToCleanup_ = containersToCleanup_;
        } else {
          result.containersToCleanup_ = containersToCleanupBuilder_.build();
        }
        if (applicationsToCleanupBuilder_ == null) {
          if (((bitField0_ & 0x00000020) == 0x00000020)) {
            applicationsToCleanup_ = java.util.Collections.unmodifiableList(applicationsToCleanup_);
            bitField0_ = (bitField0_ & ~0x00000020);
          }
          result.applicationsToCleanup_ = applicationsToCleanup_;
        } else {
          result.applicationsToCleanup_ = applicationsToCleanupBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
          to_bitField0_ |= 0x00000010;
        }
        result.nextHeartBeatInterval_ = nextHeartBeatInterval_;
        if (((from_bitField0_ & 0x00000080) == 0x00000080)) {
          to_bitField0_ |= 0x00000020;
        }
        result.diagnosticsMessage_ = diagnosticsMessage_;
        if (containersToBeRemovedFromNmBuilder_ == null) {
          if (((bitField0_ & 0x00000100) == 0x00000100)) {
            containersToBeRemovedFromNm_ = java.util.Collections.unmodifiableList(containersToBeRemovedFromNm_);
            bitField0_ = (bitField0_ & ~0x00000100);
          }
          result.containersToBeRemovedFromNm_ = containersToBeRemovedFromNm_;
        } else {
          result.containersToBeRemovedFromNm_ = containersToBeRemovedFromNmBuilder_.build();
        }
        if (systemCredentialsForAppsBuilder_ == null) {
          if (((bitField0_ & 0x00000200) == 0x00000200)) {
            systemCredentialsForApps_ = java.util.Collections.unmodifiableList(systemCredentialsForApps_);
            bitField0_ = (bitField0_ & ~0x00000200);
          }
          result.systemCredentialsForApps_ = systemCredentialsForApps_;
        } else {
          result.systemCredentialsForApps_ = systemCredentialsForAppsBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000400) == 0x00000400)) {
          to_bitField0_ |= 0x00000040;
        }
        result.areNodeLabelsAcceptedByRM_ = areNodeLabelsAcceptedByRM_;
        if (containersToDecreaseBuilder_ == null) {
          if (((bitField0_ & 0x00000800) == 0x00000800)) {
            containersToDecrease_ = java.util.Collections.unmodifiableList(containersToDecrease_);
            bitField0_ = (bitField0_ & ~0x00000800);
          }
          result.containersToDecrease_ = containersToDecrease_;
        } else {
          result.containersToDecrease_ = containersToDecreaseBuilder_.build();
        }
        if (containersToSignalBuilder_ == null) {
          if (((bitField0_ & 0x00001000) == 0x00001000)) {
            containersToSignal_ = java.util.Collections.unmodifiableList(containersToSignal_);
            bitField0_ = (bitField0_ & ~0x00001000);
          }
          result.containersToSignal_ = containersToSignal_;
        } else {
          result.containersToSignal_ = containersToSignalBuilder_.build();
        }
        if (((from_bitField0_ & 0x00002000) == 0x00002000)) {
          to_bitField0_ |= 0x00000080;
        }
        if (resourceBuilder_ == null) {
          result.resource_ = resource_;
        } else {
          result.resource_ = resourceBuilder_.build();
        }
        if (((from_bitField0_ & 0x00004000) == 0x00004000)) {
          to_bitField0_ |= 0x00000100;
        }
        if (containerQueuingLimitBuilder_ == null) {
          result.containerQueuingLimit_ = containerQueuingLimit_;
        } else {
          result.containerQueuingLimit_ = containerQueuingLimitBuilder_.build();
        }
        if (appCollectorsMapBuilder_ == null) {
          if (((bitField0_ & 0x00008000) == 0x00008000)) {
            appCollectorsMap_ = java.util.Collections.unmodifiableList(appCollectorsMap_);
            bitField0_ = (bitField0_ & ~0x00008000);
          }
          result.appCollectorsMap_ = appCollectorsMap_;
        } else {
          result.appCollectorsMap_ = appCollectorsMapBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto.getDefaultInstance()) return this;
        if (other.hasResponseId()) {
          setResponseId(other.getResponseId());
        }
        if (other.hasContainerTokenMasterKey()) {
          mergeContainerTokenMasterKey(other.getContainerTokenMasterKey());
        }
        if (other.hasNmTokenMasterKey()) {
          mergeNmTokenMasterKey(other.getNmTokenMasterKey());
        }
        if (other.hasNodeAction()) {
          setNodeAction(other.getNodeAction());
        }
        if (containersToCleanupBuilder_ == null) {
          if (!other.containersToCleanup_.isEmpty()) {
            if (containersToCleanup_.isEmpty()) {
              containersToCleanup_ = other.containersToCleanup_;
              bitField0_ = (bitField0_ & ~0x00000010);
            } else {
              ensureContainersToCleanupIsMutable();
              containersToCleanup_.addAll(other.containersToCleanup_);
            }
            onChanged();
          }
        } else {
          if (!other.containersToCleanup_.isEmpty()) {
            if (containersToCleanupBuilder_.isEmpty()) {
              containersToCleanupBuilder_.dispose();
              containersToCleanupBuilder_ = null;
              containersToCleanup_ = other.containersToCleanup_;
              bitField0_ = (bitField0_ & ~0x00000010);
              containersToCleanupBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getContainersToCleanupFieldBuilder() : null;
            } else {
              containersToCleanupBuilder_.addAllMessages(other.containersToCleanup_);
            }
          }
        }
        if (applicationsToCleanupBuilder_ == null) {
          if (!other.applicationsToCleanup_.isEmpty()) {
            if (applicationsToCleanup_.isEmpty()) {
              applicationsToCleanup_ = other.applicationsToCleanup_;
              bitField0_ = (bitField0_ & ~0x00000020);
            } else {
              ensureApplicationsToCleanupIsMutable();
              applicationsToCleanup_.addAll(other.applicationsToCleanup_);
            }
            onChanged();
          }
        } else {
          if (!other.applicationsToCleanup_.isEmpty()) {
            if (applicationsToCleanupBuilder_.isEmpty()) {
              applicationsToCleanupBuilder_.dispose();
              applicationsToCleanupBuilder_ = null;
              applicationsToCleanup_ = other.applicationsToCleanup_;
              bitField0_ = (bitField0_ & ~0x00000020);
              applicationsToCleanupBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getApplicationsToCleanupFieldBuilder() : null;
            } else {
              applicationsToCleanupBuilder_.addAllMessages(other.applicationsToCleanup_);
            }
          }
        }
        if (other.hasNextHeartBeatInterval()) {
          setNextHeartBeatInterval(other.getNextHeartBeatInterval());
        }
        if (other.hasDiagnosticsMessage()) {
          bitField0_ |= 0x00000080;
          diagnosticsMessage_ = other.diagnosticsMessage_;
          onChanged();
        }
        if (containersToBeRemovedFromNmBuilder_ == null) {
          if (!other.containersToBeRemovedFromNm_.isEmpty()) {
            if (containersToBeRemovedFromNm_.isEmpty()) {
              containersToBeRemovedFromNm_ = other.containersToBeRemovedFromNm_;
              bitField0_ = (bitField0_ & ~0x00000100);
            } else {
              ensureContainersToBeRemovedFromNmIsMutable();
              containersToBeRemovedFromNm_.addAll(other.containersToBeRemovedFromNm_);
            }
            onChanged();
          }
        } else {
          if (!other.containersToBeRemovedFromNm_.isEmpty()) {
            if (containersToBeRemovedFromNmBuilder_.isEmpty()) {
              containersToBeRemovedFromNmBuilder_.dispose();
              containersToBeRemovedFromNmBuilder_ = null;
              containersToBeRemovedFromNm_ = other.containersToBeRemovedFromNm_;
              bitField0_ = (bitField0_ & ~0x00000100);
              containersToBeRemovedFromNmBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getContainersToBeRemovedFromNmFieldBuilder() : null;
            } else {
              containersToBeRemovedFromNmBuilder_.addAllMessages(other.containersToBeRemovedFromNm_);
            }
          }
        }
        if (systemCredentialsForAppsBuilder_ == null) {
          if (!other.systemCredentialsForApps_.isEmpty()) {
            if (systemCredentialsForApps_.isEmpty()) {
              systemCredentialsForApps_ = other.systemCredentialsForApps_;
              bitField0_ = (bitField0_ & ~0x00000200);
            } else {
              ensureSystemCredentialsForAppsIsMutable();
              systemCredentialsForApps_.addAll(other.systemCredentialsForApps_);
            }
            onChanged();
          }
        } else {
          if (!other.systemCredentialsForApps_.isEmpty()) {
            if (systemCredentialsForAppsBuilder_.isEmpty()) {
              systemCredentialsForAppsBuilder_.dispose();
              systemCredentialsForAppsBuilder_ = null;
              systemCredentialsForApps_ = other.systemCredentialsForApps_;
              bitField0_ = (bitField0_ & ~0x00000200);
              systemCredentialsForAppsBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getSystemCredentialsForAppsFieldBuilder() : null;
            } else {
              systemCredentialsForAppsBuilder_.addAllMessages(other.systemCredentialsForApps_);
            }
          }
        }
        if (other.hasAreNodeLabelsAcceptedByRM()) {
          setAreNodeLabelsAcceptedByRM(other.getAreNodeLabelsAcceptedByRM());
        }
        if (containersToDecreaseBuilder_ == null) {
          if (!other.containersToDecrease_.isEmpty()) {
            if (containersToDecrease_.isEmpty()) {
              containersToDecrease_ = other.containersToDecrease_;
              bitField0_ = (bitField0_ & ~0x00000800);
            } else {
              ensureContainersToDecreaseIsMutable();
              containersToDecrease_.addAll(other.containersToDecrease_);
            }
            onChanged();
          }
        } else {
          if (!other.containersToDecrease_.isEmpty()) {
            if (containersToDecreaseBuilder_.isEmpty()) {
              containersToDecreaseBuilder_.dispose();
              containersToDecreaseBuilder_ = null;
              containersToDecrease_ = other.containersToDecrease_;
              bitField0_ = (bitField0_ & ~0x00000800);
              containersToDecreaseBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getContainersToDecreaseFieldBuilder() : null;
            } else {
              containersToDecreaseBuilder_.addAllMessages(other.containersToDecrease_);
            }
          }
        }
        if (containersToSignalBuilder_ == null) {
          if (!other.containersToSignal_.isEmpty()) {
            if (containersToSignal_.isEmpty()) {
              containersToSignal_ = other.containersToSignal_;
              bitField0_ = (bitField0_ & ~0x00001000);
            } else {
              ensureContainersToSignalIsMutable();
              containersToSignal_.addAll(other.containersToSignal_);
            }
            onChanged();
          }
        } else {
          if (!other.containersToSignal_.isEmpty()) {
            if (containersToSignalBuilder_.isEmpty()) {
              containersToSignalBuilder_.dispose();
              containersToSignalBuilder_ = null;
              containersToSignal_ = other.containersToSignal_;
              bitField0_ = (bitField0_ & ~0x00001000);
              containersToSignalBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getContainersToSignalFieldBuilder() : null;
            } else {
              containersToSignalBuilder_.addAllMessages(other.containersToSignal_);
            }
          }
        }
        if (other.hasResource()) {
          mergeResource(other.getResource());
        }
        if (other.hasContainerQueuingLimit()) {
          mergeContainerQueuingLimit(other.getContainerQueuingLimit());
        }
        if (appCollectorsMapBuilder_ == null) {
          if (!other.appCollectorsMap_.isEmpty()) {
            if (appCollectorsMap_.isEmpty()) {
              appCollectorsMap_ = other.appCollectorsMap_;
              bitField0_ = (bitField0_ & ~0x00008000);
            } else {
              ensureAppCollectorsMapIsMutable();
              appCollectorsMap_.addAll(other.appCollectorsMap_);
            }
            onChanged();
          }
        } else {
          if (!other.appCollectorsMap_.isEmpty()) {
            if (appCollectorsMapBuilder_.isEmpty()) {
              appCollectorsMapBuilder_.dispose();
              appCollectorsMapBuilder_ = null;
              appCollectorsMap_ = other.appCollectorsMap_;
              bitField0_ = (bitField0_ & ~0x00008000);
              appCollectorsMapBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getAppCollectorsMapFieldBuilder() : null;
            } else {
              appCollectorsMapBuilder_.addAllMessages(other.appCollectorsMap_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        for (int i = 0; i < getContainersToDecreaseCount(); i++) {
          if (!getContainersToDecrease(i).isInitialized()) {
            
            return false;
          }
        }
        for (int i = 0; i < getContainersToSignalCount(); i++) {
          if (!getContainersToSignal(i).isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NodeHeartbeatResponseProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional int32 response_id = 1;
      private int responseId_ ;
      /**
       * <code>optional int32 response_id = 1;</code>
       */
      public boolean hasResponseId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional int32 response_id = 1;</code>
       */
      public int getResponseId() {
        return responseId_;
      }
      /**
       * <code>optional int32 response_id = 1;</code>
       */
      public Builder setResponseId(int value) {
        bitField0_ |= 0x00000001;
        responseId_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 response_id = 1;</code>
       */
      public Builder clearResponseId() {
        bitField0_ = (bitField0_ & ~0x00000001);
        responseId_ = 0;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.MasterKeyProto container_token_master_key = 2;
      private org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto containerTokenMasterKey_ = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProtoOrBuilder> containerTokenMasterKeyBuilder_;
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto container_token_master_key = 2;</code>
       */
      public boolean hasContainerTokenMasterKey() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto container_token_master_key = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto getContainerTokenMasterKey() {
        if (containerTokenMasterKeyBuilder_ == null) {
          return containerTokenMasterKey_;
        } else {
          return containerTokenMasterKeyBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto container_token_master_key = 2;</code>
       */
      public Builder setContainerTokenMasterKey(org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto value) {
        if (containerTokenMasterKeyBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          containerTokenMasterKey_ = value;
          onChanged();
        } else {
          containerTokenMasterKeyBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto container_token_master_key = 2;</code>
       */
      public Builder setContainerTokenMasterKey(
          org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.Builder builderForValue) {
        if (containerTokenMasterKeyBuilder_ == null) {
          containerTokenMasterKey_ = builderForValue.build();
          onChanged();
        } else {
          containerTokenMasterKeyBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto container_token_master_key = 2;</code>
       */
      public Builder mergeContainerTokenMasterKey(org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto value) {
        if (containerTokenMasterKeyBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              containerTokenMasterKey_ != org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.getDefaultInstance()) {
            containerTokenMasterKey_ =
              org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.newBuilder(containerTokenMasterKey_).mergeFrom(value).buildPartial();
          } else {
            containerTokenMasterKey_ = value;
          }
          onChanged();
        } else {
          containerTokenMasterKeyBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto container_token_master_key = 2;</code>
       */
      public Builder clearContainerTokenMasterKey() {
        if (containerTokenMasterKeyBuilder_ == null) {
          containerTokenMasterKey_ = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.getDefaultInstance();
          onChanged();
        } else {
          containerTokenMasterKeyBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto container_token_master_key = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.Builder getContainerTokenMasterKeyBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getContainerTokenMasterKeyFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto container_token_master_key = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProtoOrBuilder getContainerTokenMasterKeyOrBuilder() {
        if (containerTokenMasterKeyBuilder_ != null) {
          return containerTokenMasterKeyBuilder_.getMessageOrBuilder();
        } else {
          return containerTokenMasterKey_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto container_token_master_key = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProtoOrBuilder> 
          getContainerTokenMasterKeyFieldBuilder() {
        if (containerTokenMasterKeyBuilder_ == null) {
          containerTokenMasterKeyBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProtoOrBuilder>(
                  containerTokenMasterKey_,
                  getParentForChildren(),
                  isClean());
          containerTokenMasterKey_ = null;
        }
        return containerTokenMasterKeyBuilder_;
      }

      // optional .hadoop.yarn.MasterKeyProto nm_token_master_key = 3;
      private org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto nmTokenMasterKey_ = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProtoOrBuilder> nmTokenMasterKeyBuilder_;
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto nm_token_master_key = 3;</code>
       */
      public boolean hasNmTokenMasterKey() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto nm_token_master_key = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto getNmTokenMasterKey() {
        if (nmTokenMasterKeyBuilder_ == null) {
          return nmTokenMasterKey_;
        } else {
          return nmTokenMasterKeyBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto nm_token_master_key = 3;</code>
       */
      public Builder setNmTokenMasterKey(org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto value) {
        if (nmTokenMasterKeyBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          nmTokenMasterKey_ = value;
          onChanged();
        } else {
          nmTokenMasterKeyBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto nm_token_master_key = 3;</code>
       */
      public Builder setNmTokenMasterKey(
          org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.Builder builderForValue) {
        if (nmTokenMasterKeyBuilder_ == null) {
          nmTokenMasterKey_ = builderForValue.build();
          onChanged();
        } else {
          nmTokenMasterKeyBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto nm_token_master_key = 3;</code>
       */
      public Builder mergeNmTokenMasterKey(org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto value) {
        if (nmTokenMasterKeyBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              nmTokenMasterKey_ != org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.getDefaultInstance()) {
            nmTokenMasterKey_ =
              org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.newBuilder(nmTokenMasterKey_).mergeFrom(value).buildPartial();
          } else {
            nmTokenMasterKey_ = value;
          }
          onChanged();
        } else {
          nmTokenMasterKeyBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto nm_token_master_key = 3;</code>
       */
      public Builder clearNmTokenMasterKey() {
        if (nmTokenMasterKeyBuilder_ == null) {
          nmTokenMasterKey_ = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.getDefaultInstance();
          onChanged();
        } else {
          nmTokenMasterKeyBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto nm_token_master_key = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.Builder getNmTokenMasterKeyBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getNmTokenMasterKeyFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto nm_token_master_key = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProtoOrBuilder getNmTokenMasterKeyOrBuilder() {
        if (nmTokenMasterKeyBuilder_ != null) {
          return nmTokenMasterKeyBuilder_.getMessageOrBuilder();
        } else {
          return nmTokenMasterKey_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.MasterKeyProto nm_token_master_key = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProtoOrBuilder> 
          getNmTokenMasterKeyFieldBuilder() {
        if (nmTokenMasterKeyBuilder_ == null) {
          nmTokenMasterKeyBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonProtos.MasterKeyProtoOrBuilder>(
                  nmTokenMasterKey_,
                  getParentForChildren(),
                  isClean());
          nmTokenMasterKey_ = null;
        }
        return nmTokenMasterKeyBuilder_;
      }

      // optional .hadoop.yarn.NodeActionProto nodeAction = 4;
      private org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeActionProto nodeAction_ = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeActionProto.NORMAL;
      /**
       * <code>optional .hadoop.yarn.NodeActionProto nodeAction = 4;</code>
       */
      public boolean hasNodeAction() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional .hadoop.yarn.NodeActionProto nodeAction = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeActionProto getNodeAction() {
        return nodeAction_;
      }
      /**
       * <code>optional .hadoop.yarn.NodeActionProto nodeAction = 4;</code>
       */
      public Builder setNodeAction(org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeActionProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000008;
        nodeAction_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeActionProto nodeAction = 4;</code>
       */
      public Builder clearNodeAction() {
        bitField0_ = (bitField0_ & ~0x00000008);
        nodeAction_ = org.apache.hadoop.yarn.proto.YarnServerCommonProtos.NodeActionProto.NORMAL;
        onChanged();
        return this;
      }

      // repeated .hadoop.yarn.ContainerIdProto containers_to_cleanup = 5;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto> containersToCleanup_ =
        java.util.Collections.emptyList();
      private void ensureContainersToCleanupIsMutable() {
        if (!((bitField0_ & 0x00000010) == 0x00000010)) {
          containersToCleanup_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto>(containersToCleanup_);
          bitField0_ |= 0x00000010;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> containersToCleanupBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_cleanup = 5;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto> getContainersToCleanupList() {
        if (containersToCleanupBuilder_ == null) {
          return java.util.Collections.unmodifiableList(containersToCleanup_);
        } else {
          return containersToCleanupBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_cleanup = 5;</code>
       */
      public int getContainersToCleanupCount() {
        if (containersToCleanupBuilder_ == null) {
          return containersToCleanup_.size();
        } else {
          return containersToCleanupBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_cleanup = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainersToCleanup(int index) {
        if (containersToCleanupBuilder_ == null) {
          return containersToCleanup_.get(index);
        } else {
          return containersToCleanupBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_cleanup = 5;</code>
       */
      public Builder setContainersToCleanup(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containersToCleanupBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainersToCleanupIsMutable();
          containersToCleanup_.set(index, value);
          onChanged();
        } else {
          containersToCleanupBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_cleanup = 5;</code>
       */
      public Builder setContainersToCleanup(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (containersToCleanupBuilder_ == null) {
          ensureContainersToCleanupIsMutable();
          containersToCleanup_.set(index, builderForValue.build());
          onChanged();
        } else {
          containersToCleanupBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_cleanup = 5;</code>
       */
      public Builder addContainersToCleanup(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containersToCleanupBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainersToCleanupIsMutable();
          containersToCleanup_.add(value);
          onChanged();
        } else {
          containersToCleanupBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_cleanup = 5;</code>
       */
      public Builder addContainersToCleanup(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containersToCleanupBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainersToCleanupIsMutable();
          containersToCleanup_.add(index, value);
          onChanged();
        } else {
          containersToCleanupBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_cleanup = 5;</code>
       */
      public Builder addContainersToCleanup(
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (containersToCleanupBuilder_ == null) {
          ensureContainersToCleanupIsMutable();
          containersToCleanup_.add(builderForValue.build());
          onChanged();
        } else {
          containersToCleanupBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_cleanup = 5;</code>
       */
      public Builder addContainersToCleanup(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (containersToCleanupBuilder_ == null) {
          ensureContainersToCleanupIsMutable();
          containersToCleanup_.add(index, builderForValue.build());
          onChanged();
        } else {
          containersToCleanupBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_cleanup = 5;</code>
       */
      public Builder addAllContainersToCleanup(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto> values) {
        if (containersToCleanupBuilder_ == null) {
          ensureContainersToCleanupIsMutable();
          super.addAll(values, containersToCleanup_);
          onChanged();
        } else {
          containersToCleanupBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_cleanup = 5;</code>
       */
      public Builder clearContainersToCleanup() {
        if (containersToCleanupBuilder_ == null) {
          containersToCleanup_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000010);
          onChanged();
        } else {
          containersToCleanupBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_cleanup = 5;</code>
       */
      public Builder removeContainersToCleanup(int index) {
        if (containersToCleanupBuilder_ == null) {
          ensureContainersToCleanupIsMutable();
          containersToCleanup_.remove(index);
          onChanged();
        } else {
          containersToCleanupBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_cleanup = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder getContainersToCleanupBuilder(
          int index) {
        return getContainersToCleanupFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_cleanup = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainersToCleanupOrBuilder(
          int index) {
        if (containersToCleanupBuilder_ == null) {
          return containersToCleanup_.get(index);  } else {
          return containersToCleanupBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_cleanup = 5;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
           getContainersToCleanupOrBuilderList() {
        if (containersToCleanupBuilder_ != null) {
          return containersToCleanupBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(containersToCleanup_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_cleanup = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder addContainersToCleanupBuilder() {
        return getContainersToCleanupFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_cleanup = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder addContainersToCleanupBuilder(
          int index) {
        return getContainersToCleanupFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_cleanup = 5;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder> 
           getContainersToCleanupBuilderList() {
        return getContainersToCleanupFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
          getContainersToCleanupFieldBuilder() {
        if (containersToCleanupBuilder_ == null) {
          containersToCleanupBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder>(
                  containersToCleanup_,
                  ((bitField0_ & 0x00000010) == 0x00000010),
                  getParentForChildren(),
                  isClean());
          containersToCleanup_ = null;
        }
        return containersToCleanupBuilder_;
      }

      // repeated .hadoop.yarn.ApplicationIdProto applications_to_cleanup = 6;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto> applicationsToCleanup_ =
        java.util.Collections.emptyList();
      private void ensureApplicationsToCleanupIsMutable() {
        if (!((bitField0_ & 0x00000020) == 0x00000020)) {
          applicationsToCleanup_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto>(applicationsToCleanup_);
          bitField0_ |= 0x00000020;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> applicationsToCleanupBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto applications_to_cleanup = 6;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto> getApplicationsToCleanupList() {
        if (applicationsToCleanupBuilder_ == null) {
          return java.util.Collections.unmodifiableList(applicationsToCleanup_);
        } else {
          return applicationsToCleanupBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto applications_to_cleanup = 6;</code>
       */
      public int getApplicationsToCleanupCount() {
        if (applicationsToCleanupBuilder_ == null) {
          return applicationsToCleanup_.size();
        } else {
          return applicationsToCleanupBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto applications_to_cleanup = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationsToCleanup(int index) {
        if (applicationsToCleanupBuilder_ == null) {
          return applicationsToCleanup_.get(index);
        } else {
          return applicationsToCleanupBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto applications_to_cleanup = 6;</code>
       */
      public Builder setApplicationsToCleanup(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationsToCleanupBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationsToCleanupIsMutable();
          applicationsToCleanup_.set(index, value);
          onChanged();
        } else {
          applicationsToCleanupBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto applications_to_cleanup = 6;</code>
       */
      public Builder setApplicationsToCleanup(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder builderForValue) {
        if (applicationsToCleanupBuilder_ == null) {
          ensureApplicationsToCleanupIsMutable();
          applicationsToCleanup_.set(index, builderForValue.build());
          onChanged();
        } else {
          applicationsToCleanupBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto applications_to_cleanup = 6;</code>
       */
      public Builder addApplicationsToCleanup(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationsToCleanupBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationsToCleanupIsMutable();
          applicationsToCleanup_.add(value);
          onChanged();
        } else {
          applicationsToCleanupBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto applications_to_cleanup = 6;</code>
       */
      public Builder addApplicationsToCleanup(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationsToCleanupBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationsToCleanupIsMutable();
          applicationsToCleanup_.add(index, value);
          onChanged();
        } else {
          applicationsToCleanupBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto applications_to_cleanup = 6;</code>
       */
      public Builder addApplicationsToCleanup(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder builderForValue) {
        if (applicationsToCleanupBuilder_ == null) {
          ensureApplicationsToCleanupIsMutable();
          applicationsToCleanup_.add(builderForValue.build());
          onChanged();
        } else {
          applicationsToCleanupBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto applications_to_cleanup = 6;</code>
       */
      public Builder addApplicationsToCleanup(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder builderForValue) {
        if (applicationsToCleanupBuilder_ == null) {
          ensureApplicationsToCleanupIsMutable();
          applicationsToCleanup_.add(index, builderForValue.build());
          onChanged();
        } else {
          applicationsToCleanupBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto applications_to_cleanup = 6;</code>
       */
      public Builder addAllApplicationsToCleanup(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto> values) {
        if (applicationsToCleanupBuilder_ == null) {
          ensureApplicationsToCleanupIsMutable();
          super.addAll(values, applicationsToCleanup_);
          onChanged();
        } else {
          applicationsToCleanupBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto applications_to_cleanup = 6;</code>
       */
      public Builder clearApplicationsToCleanup() {
        if (applicationsToCleanupBuilder_ == null) {
          applicationsToCleanup_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000020);
          onChanged();
        } else {
          applicationsToCleanupBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto applications_to_cleanup = 6;</code>
       */
      public Builder removeApplicationsToCleanup(int index) {
        if (applicationsToCleanupBuilder_ == null) {
          ensureApplicationsToCleanupIsMutable();
          applicationsToCleanup_.remove(index);
          onChanged();
        } else {
          applicationsToCleanupBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto applications_to_cleanup = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder getApplicationsToCleanupBuilder(
          int index) {
        return getApplicationsToCleanupFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto applications_to_cleanup = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationsToCleanupOrBuilder(
          int index) {
        if (applicationsToCleanupBuilder_ == null) {
          return applicationsToCleanup_.get(index);  } else {
          return applicationsToCleanupBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto applications_to_cleanup = 6;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> 
           getApplicationsToCleanupOrBuilderList() {
        if (applicationsToCleanupBuilder_ != null) {
          return applicationsToCleanupBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(applicationsToCleanup_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto applications_to_cleanup = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder addApplicationsToCleanupBuilder() {
        return getApplicationsToCleanupFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto applications_to_cleanup = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder addApplicationsToCleanupBuilder(
          int index) {
        return getApplicationsToCleanupFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationIdProto applications_to_cleanup = 6;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder> 
           getApplicationsToCleanupBuilderList() {
        return getApplicationsToCleanupFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> 
          getApplicationsToCleanupFieldBuilder() {
        if (applicationsToCleanupBuilder_ == null) {
          applicationsToCleanupBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder>(
                  applicationsToCleanup_,
                  ((bitField0_ & 0x00000020) == 0x00000020),
                  getParentForChildren(),
                  isClean());
          applicationsToCleanup_ = null;
        }
        return applicationsToCleanupBuilder_;
      }

      // optional int64 nextHeartBeatInterval = 7;
      private long nextHeartBeatInterval_ ;
      /**
       * <code>optional int64 nextHeartBeatInterval = 7;</code>
       */
      public boolean hasNextHeartBeatInterval() {
        return ((bitField0_ & 0x00000040) == 0x00000040);
      }
      /**
       * <code>optional int64 nextHeartBeatInterval = 7;</code>
       */
      public long getNextHeartBeatInterval() {
        return nextHeartBeatInterval_;
      }
      /**
       * <code>optional int64 nextHeartBeatInterval = 7;</code>
       */
      public Builder setNextHeartBeatInterval(long value) {
        bitField0_ |= 0x00000040;
        nextHeartBeatInterval_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 nextHeartBeatInterval = 7;</code>
       */
      public Builder clearNextHeartBeatInterval() {
        bitField0_ = (bitField0_ & ~0x00000040);
        nextHeartBeatInterval_ = 0L;
        onChanged();
        return this;
      }

      // optional string diagnostics_message = 8;
      private java.lang.Object diagnosticsMessage_ = "";
      /**
       * <code>optional string diagnostics_message = 8;</code>
       */
      public boolean hasDiagnosticsMessage() {
        return ((bitField0_ & 0x00000080) == 0x00000080);
      }
      /**
       * <code>optional string diagnostics_message = 8;</code>
       */
      public java.lang.String getDiagnosticsMessage() {
        java.lang.Object ref = diagnosticsMessage_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          diagnosticsMessage_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string diagnostics_message = 8;</code>
       */
      public com.google.protobuf.ByteString
          getDiagnosticsMessageBytes() {
        java.lang.Object ref = diagnosticsMessage_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          diagnosticsMessage_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string diagnostics_message = 8;</code>
       */
      public Builder setDiagnosticsMessage(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000080;
        diagnosticsMessage_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string diagnostics_message = 8;</code>
       */
      public Builder clearDiagnosticsMessage() {
        bitField0_ = (bitField0_ & ~0x00000080);
        diagnosticsMessage_ = getDefaultInstance().getDiagnosticsMessage();
        onChanged();
        return this;
      }
      /**
       * <code>optional string diagnostics_message = 8;</code>
       */
      public Builder setDiagnosticsMessageBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000080;
        diagnosticsMessage_ = value;
        onChanged();
        return this;
      }

      // repeated .hadoop.yarn.ContainerIdProto containers_to_be_removed_from_nm = 9;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto> containersToBeRemovedFromNm_ =
        java.util.Collections.emptyList();
      private void ensureContainersToBeRemovedFromNmIsMutable() {
        if (!((bitField0_ & 0x00000100) == 0x00000100)) {
          containersToBeRemovedFromNm_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto>(containersToBeRemovedFromNm_);
          bitField0_ |= 0x00000100;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> containersToBeRemovedFromNmBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_be_removed_from_nm = 9;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto> getContainersToBeRemovedFromNmList() {
        if (containersToBeRemovedFromNmBuilder_ == null) {
          return java.util.Collections.unmodifiableList(containersToBeRemovedFromNm_);
        } else {
          return containersToBeRemovedFromNmBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_be_removed_from_nm = 9;</code>
       */
      public int getContainersToBeRemovedFromNmCount() {
        if (containersToBeRemovedFromNmBuilder_ == null) {
          return containersToBeRemovedFromNm_.size();
        } else {
          return containersToBeRemovedFromNmBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_be_removed_from_nm = 9;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainersToBeRemovedFromNm(int index) {
        if (containersToBeRemovedFromNmBuilder_ == null) {
          return containersToBeRemovedFromNm_.get(index);
        } else {
          return containersToBeRemovedFromNmBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_be_removed_from_nm = 9;</code>
       */
      public Builder setContainersToBeRemovedFromNm(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containersToBeRemovedFromNmBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainersToBeRemovedFromNmIsMutable();
          containersToBeRemovedFromNm_.set(index, value);
          onChanged();
        } else {
          containersToBeRemovedFromNmBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_be_removed_from_nm = 9;</code>
       */
      public Builder setContainersToBeRemovedFromNm(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (containersToBeRemovedFromNmBuilder_ == null) {
          ensureContainersToBeRemovedFromNmIsMutable();
          containersToBeRemovedFromNm_.set(index, builderForValue.build());
          onChanged();
        } else {
          containersToBeRemovedFromNmBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_be_removed_from_nm = 9;</code>
       */
      public Builder addContainersToBeRemovedFromNm(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containersToBeRemovedFromNmBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainersToBeRemovedFromNmIsMutable();
          containersToBeRemovedFromNm_.add(value);
          onChanged();
        } else {
          containersToBeRemovedFromNmBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_be_removed_from_nm = 9;</code>
       */
      public Builder addContainersToBeRemovedFromNm(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containersToBeRemovedFromNmBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainersToBeRemovedFromNmIsMutable();
          containersToBeRemovedFromNm_.add(index, value);
          onChanged();
        } else {
          containersToBeRemovedFromNmBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_be_removed_from_nm = 9;</code>
       */
      public Builder addContainersToBeRemovedFromNm(
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (containersToBeRemovedFromNmBuilder_ == null) {
          ensureContainersToBeRemovedFromNmIsMutable();
          containersToBeRemovedFromNm_.add(builderForValue.build());
          onChanged();
        } else {
          containersToBeRemovedFromNmBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_be_removed_from_nm = 9;</code>
       */
      public Builder addContainersToBeRemovedFromNm(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (containersToBeRemovedFromNmBuilder_ == null) {
          ensureContainersToBeRemovedFromNmIsMutable();
          containersToBeRemovedFromNm_.add(index, builderForValue.build());
          onChanged();
        } else {
          containersToBeRemovedFromNmBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_be_removed_from_nm = 9;</code>
       */
      public Builder addAllContainersToBeRemovedFromNm(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto> values) {
        if (containersToBeRemovedFromNmBuilder_ == null) {
          ensureContainersToBeRemovedFromNmIsMutable();
          super.addAll(values, containersToBeRemovedFromNm_);
          onChanged();
        } else {
          containersToBeRemovedFromNmBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_be_removed_from_nm = 9;</code>
       */
      public Builder clearContainersToBeRemovedFromNm() {
        if (containersToBeRemovedFromNmBuilder_ == null) {
          containersToBeRemovedFromNm_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000100);
          onChanged();
        } else {
          containersToBeRemovedFromNmBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_be_removed_from_nm = 9;</code>
       */
      public Builder removeContainersToBeRemovedFromNm(int index) {
        if (containersToBeRemovedFromNmBuilder_ == null) {
          ensureContainersToBeRemovedFromNmIsMutable();
          containersToBeRemovedFromNm_.remove(index);
          onChanged();
        } else {
          containersToBeRemovedFromNmBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_be_removed_from_nm = 9;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder getContainersToBeRemovedFromNmBuilder(
          int index) {
        return getContainersToBeRemovedFromNmFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_be_removed_from_nm = 9;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainersToBeRemovedFromNmOrBuilder(
          int index) {
        if (containersToBeRemovedFromNmBuilder_ == null) {
          return containersToBeRemovedFromNm_.get(index);  } else {
          return containersToBeRemovedFromNmBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_be_removed_from_nm = 9;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
           getContainersToBeRemovedFromNmOrBuilderList() {
        if (containersToBeRemovedFromNmBuilder_ != null) {
          return containersToBeRemovedFromNmBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(containersToBeRemovedFromNm_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_be_removed_from_nm = 9;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder addContainersToBeRemovedFromNmBuilder() {
        return getContainersToBeRemovedFromNmFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_be_removed_from_nm = 9;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder addContainersToBeRemovedFromNmBuilder(
          int index) {
        return getContainersToBeRemovedFromNmFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerIdProto containers_to_be_removed_from_nm = 9;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder> 
           getContainersToBeRemovedFromNmBuilderList() {
        return getContainersToBeRemovedFromNmFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
          getContainersToBeRemovedFromNmFieldBuilder() {
        if (containersToBeRemovedFromNmBuilder_ == null) {
          containersToBeRemovedFromNmBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder>(
                  containersToBeRemovedFromNm_,
                  ((bitField0_ & 0x00000100) == 0x00000100),
                  getParentForChildren(),
                  isClean());
          containersToBeRemovedFromNm_ = null;
        }
        return containersToBeRemovedFromNmBuilder_;
      }

      // repeated .hadoop.yarn.SystemCredentialsForAppsProto system_credentials_for_apps = 10;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto> systemCredentialsForApps_ =
        java.util.Collections.emptyList();
      private void ensureSystemCredentialsForAppsIsMutable() {
        if (!((bitField0_ & 0x00000200) == 0x00000200)) {
          systemCredentialsForApps_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto>(systemCredentialsForApps_);
          bitField0_ |= 0x00000200;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProtoOrBuilder> systemCredentialsForAppsBuilder_;

      /**
       * <code>repeated .hadoop.yarn.SystemCredentialsForAppsProto system_credentials_for_apps = 10;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto> getSystemCredentialsForAppsList() {
        if (systemCredentialsForAppsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(systemCredentialsForApps_);
        } else {
          return systemCredentialsForAppsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.SystemCredentialsForAppsProto system_credentials_for_apps = 10;</code>
       */
      public int getSystemCredentialsForAppsCount() {
        if (systemCredentialsForAppsBuilder_ == null) {
          return systemCredentialsForApps_.size();
        } else {
          return systemCredentialsForAppsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.SystemCredentialsForAppsProto system_credentials_for_apps = 10;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto getSystemCredentialsForApps(int index) {
        if (systemCredentialsForAppsBuilder_ == null) {
          return systemCredentialsForApps_.get(index);
        } else {
          return systemCredentialsForAppsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.SystemCredentialsForAppsProto system_credentials_for_apps = 10;</code>
       */
      public Builder setSystemCredentialsForApps(
          int index, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto value) {
        if (systemCredentialsForAppsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureSystemCredentialsForAppsIsMutable();
          systemCredentialsForApps_.set(index, value);
          onChanged();
        } else {
          systemCredentialsForAppsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.SystemCredentialsForAppsProto system_credentials_for_apps = 10;</code>
       */
      public Builder setSystemCredentialsForApps(
          int index, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto.Builder builderForValue) {
        if (systemCredentialsForAppsBuilder_ == null) {
          ensureSystemCredentialsForAppsIsMutable();
          systemCredentialsForApps_.set(index, builderForValue.build());
          onChanged();
        } else {
          systemCredentialsForAppsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.SystemCredentialsForAppsProto system_credentials_for_apps = 10;</code>
       */
      public Builder addSystemCredentialsForApps(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto value) {
        if (systemCredentialsForAppsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureSystemCredentialsForAppsIsMutable();
          systemCredentialsForApps_.add(value);
          onChanged();
        } else {
          systemCredentialsForAppsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.SystemCredentialsForAppsProto system_credentials_for_apps = 10;</code>
       */
      public Builder addSystemCredentialsForApps(
          int index, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto value) {
        if (systemCredentialsForAppsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureSystemCredentialsForAppsIsMutable();
          systemCredentialsForApps_.add(index, value);
          onChanged();
        } else {
          systemCredentialsForAppsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.SystemCredentialsForAppsProto system_credentials_for_apps = 10;</code>
       */
      public Builder addSystemCredentialsForApps(
          org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto.Builder builderForValue) {
        if (systemCredentialsForAppsBuilder_ == null) {
          ensureSystemCredentialsForAppsIsMutable();
          systemCredentialsForApps_.add(builderForValue.build());
          onChanged();
        } else {
          systemCredentialsForAppsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.SystemCredentialsForAppsProto system_credentials_for_apps = 10;</code>
       */
      public Builder addSystemCredentialsForApps(
          int index, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto.Builder builderForValue) {
        if (systemCredentialsForAppsBuilder_ == null) {
          ensureSystemCredentialsForAppsIsMutable();
          systemCredentialsForApps_.add(index, builderForValue.build());
          onChanged();
        } else {
          systemCredentialsForAppsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.SystemCredentialsForAppsProto system_credentials_for_apps = 10;</code>
       */
      public Builder addAllSystemCredentialsForApps(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto> values) {
        if (systemCredentialsForAppsBuilder_ == null) {
          ensureSystemCredentialsForAppsIsMutable();
          super.addAll(values, systemCredentialsForApps_);
          onChanged();
        } else {
          systemCredentialsForAppsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.SystemCredentialsForAppsProto system_credentials_for_apps = 10;</code>
       */
      public Builder clearSystemCredentialsForApps() {
        if (systemCredentialsForAppsBuilder_ == null) {
          systemCredentialsForApps_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000200);
          onChanged();
        } else {
          systemCredentialsForAppsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.SystemCredentialsForAppsProto system_credentials_for_apps = 10;</code>
       */
      public Builder removeSystemCredentialsForApps(int index) {
        if (systemCredentialsForAppsBuilder_ == null) {
          ensureSystemCredentialsForAppsIsMutable();
          systemCredentialsForApps_.remove(index);
          onChanged();
        } else {
          systemCredentialsForAppsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.SystemCredentialsForAppsProto system_credentials_for_apps = 10;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto.Builder getSystemCredentialsForAppsBuilder(
          int index) {
        return getSystemCredentialsForAppsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.SystemCredentialsForAppsProto system_credentials_for_apps = 10;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProtoOrBuilder getSystemCredentialsForAppsOrBuilder(
          int index) {
        if (systemCredentialsForAppsBuilder_ == null) {
          return systemCredentialsForApps_.get(index);  } else {
          return systemCredentialsForAppsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.SystemCredentialsForAppsProto system_credentials_for_apps = 10;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProtoOrBuilder> 
           getSystemCredentialsForAppsOrBuilderList() {
        if (systemCredentialsForAppsBuilder_ != null) {
          return systemCredentialsForAppsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(systemCredentialsForApps_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.SystemCredentialsForAppsProto system_credentials_for_apps = 10;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto.Builder addSystemCredentialsForAppsBuilder() {
        return getSystemCredentialsForAppsFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.SystemCredentialsForAppsProto system_credentials_for_apps = 10;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto.Builder addSystemCredentialsForAppsBuilder(
          int index) {
        return getSystemCredentialsForAppsFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.SystemCredentialsForAppsProto system_credentials_for_apps = 10;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto.Builder> 
           getSystemCredentialsForAppsBuilderList() {
        return getSystemCredentialsForAppsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProtoOrBuilder> 
          getSystemCredentialsForAppsFieldBuilder() {
        if (systemCredentialsForAppsBuilder_ == null) {
          systemCredentialsForAppsBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProtoOrBuilder>(
                  systemCredentialsForApps_,
                  ((bitField0_ & 0x00000200) == 0x00000200),
                  getParentForChildren(),
                  isClean());
          systemCredentialsForApps_ = null;
        }
        return systemCredentialsForAppsBuilder_;
      }

      // optional bool areNodeLabelsAcceptedByRM = 11 [default = false];
      private boolean areNodeLabelsAcceptedByRM_ ;
      /**
       * <code>optional bool areNodeLabelsAcceptedByRM = 11 [default = false];</code>
       */
      public boolean hasAreNodeLabelsAcceptedByRM() {
        return ((bitField0_ & 0x00000400) == 0x00000400);
      }
      /**
       * <code>optional bool areNodeLabelsAcceptedByRM = 11 [default = false];</code>
       */
      public boolean getAreNodeLabelsAcceptedByRM() {
        return areNodeLabelsAcceptedByRM_;
      }
      /**
       * <code>optional bool areNodeLabelsAcceptedByRM = 11 [default = false];</code>
       */
      public Builder setAreNodeLabelsAcceptedByRM(boolean value) {
        bitField0_ |= 0x00000400;
        areNodeLabelsAcceptedByRM_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool areNodeLabelsAcceptedByRM = 11 [default = false];</code>
       */
      public Builder clearAreNodeLabelsAcceptedByRM() {
        bitField0_ = (bitField0_ & ~0x00000400);
        areNodeLabelsAcceptedByRM_ = false;
        onChanged();
        return this;
      }

      // repeated .hadoop.yarn.ContainerProto containers_to_decrease = 12;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto> containersToDecrease_ =
        java.util.Collections.emptyList();
      private void ensureContainersToDecreaseIsMutable() {
        if (!((bitField0_ & 0x00000800) == 0x00000800)) {
          containersToDecrease_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto>(containersToDecrease_);
          bitField0_ |= 0x00000800;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder> containersToDecreaseBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ContainerProto containers_to_decrease = 12;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto> getContainersToDecreaseList() {
        if (containersToDecreaseBuilder_ == null) {
          return java.util.Collections.unmodifiableList(containersToDecrease_);
        } else {
          return containersToDecreaseBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto containers_to_decrease = 12;</code>
       */
      public int getContainersToDecreaseCount() {
        if (containersToDecreaseBuilder_ == null) {
          return containersToDecrease_.size();
        } else {
          return containersToDecreaseBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto containers_to_decrease = 12;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto getContainersToDecrease(int index) {
        if (containersToDecreaseBuilder_ == null) {
          return containersToDecrease_.get(index);
        } else {
          return containersToDecreaseBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto containers_to_decrease = 12;</code>
       */
      public Builder setContainersToDecrease(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto value) {
        if (containersToDecreaseBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainersToDecreaseIsMutable();
          containersToDecrease_.set(index, value);
          onChanged();
        } else {
          containersToDecreaseBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto containers_to_decrease = 12;</code>
       */
      public Builder setContainersToDecrease(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder builderForValue) {
        if (containersToDecreaseBuilder_ == null) {
          ensureContainersToDecreaseIsMutable();
          containersToDecrease_.set(index, builderForValue.build());
          onChanged();
        } else {
          containersToDecreaseBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto containers_to_decrease = 12;</code>
       */
      public Builder addContainersToDecrease(org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto value) {
        if (containersToDecreaseBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainersToDecreaseIsMutable();
          containersToDecrease_.add(value);
          onChanged();
        } else {
          containersToDecreaseBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto containers_to_decrease = 12;</code>
       */
      public Builder addContainersToDecrease(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto value) {
        if (containersToDecreaseBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainersToDecreaseIsMutable();
          containersToDecrease_.add(index, value);
          onChanged();
        } else {
          containersToDecreaseBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto containers_to_decrease = 12;</code>
       */
      public Builder addContainersToDecrease(
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder builderForValue) {
        if (containersToDecreaseBuilder_ == null) {
          ensureContainersToDecreaseIsMutable();
          containersToDecrease_.add(builderForValue.build());
          onChanged();
        } else {
          containersToDecreaseBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto containers_to_decrease = 12;</code>
       */
      public Builder addContainersToDecrease(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder builderForValue) {
        if (containersToDecreaseBuilder_ == null) {
          ensureContainersToDecreaseIsMutable();
          containersToDecrease_.add(index, builderForValue.build());
          onChanged();
        } else {
          containersToDecreaseBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto containers_to_decrease = 12;</code>
       */
      public Builder addAllContainersToDecrease(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto> values) {
        if (containersToDecreaseBuilder_ == null) {
          ensureContainersToDecreaseIsMutable();
          super.addAll(values, containersToDecrease_);
          onChanged();
        } else {
          containersToDecreaseBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto containers_to_decrease = 12;</code>
       */
      public Builder clearContainersToDecrease() {
        if (containersToDecreaseBuilder_ == null) {
          containersToDecrease_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000800);
          onChanged();
        } else {
          containersToDecreaseBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto containers_to_decrease = 12;</code>
       */
      public Builder removeContainersToDecrease(int index) {
        if (containersToDecreaseBuilder_ == null) {
          ensureContainersToDecreaseIsMutable();
          containersToDecrease_.remove(index);
          onChanged();
        } else {
          containersToDecreaseBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto containers_to_decrease = 12;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder getContainersToDecreaseBuilder(
          int index) {
        return getContainersToDecreaseFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto containers_to_decrease = 12;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder getContainersToDecreaseOrBuilder(
          int index) {
        if (containersToDecreaseBuilder_ == null) {
          return containersToDecrease_.get(index);  } else {
          return containersToDecreaseBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto containers_to_decrease = 12;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder> 
           getContainersToDecreaseOrBuilderList() {
        if (containersToDecreaseBuilder_ != null) {
          return containersToDecreaseBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(containersToDecrease_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto containers_to_decrease = 12;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder addContainersToDecreaseBuilder() {
        return getContainersToDecreaseFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto containers_to_decrease = 12;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder addContainersToDecreaseBuilder(
          int index) {
        return getContainersToDecreaseFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ContainerProto containers_to_decrease = 12;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder> 
           getContainersToDecreaseBuilderList() {
        return getContainersToDecreaseFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder> 
          getContainersToDecreaseFieldBuilder() {
        if (containersToDecreaseBuilder_ == null) {
          containersToDecreaseBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder>(
                  containersToDecrease_,
                  ((bitField0_ & 0x00000800) == 0x00000800),
                  getParentForChildren(),
                  isClean());
          containersToDecrease_ = null;
        }
        return containersToDecreaseBuilder_;
      }

      // repeated .hadoop.yarn.SignalContainerRequestProto containers_to_signal = 13;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto> containersToSignal_ =
        java.util.Collections.emptyList();
      private void ensureContainersToSignalIsMutable() {
        if (!((bitField0_ & 0x00001000) == 0x00001000)) {
          containersToSignal_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto>(containersToSignal_);
          bitField0_ |= 0x00001000;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto, org.apache.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProtoOrBuilder> containersToSignalBuilder_;

      /**
       * <code>repeated .hadoop.yarn.SignalContainerRequestProto containers_to_signal = 13;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto> getContainersToSignalList() {
        if (containersToSignalBuilder_ == null) {
          return java.util.Collections.unmodifiableList(containersToSignal_);
        } else {
          return containersToSignalBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.SignalContainerRequestProto containers_to_signal = 13;</code>
       */
      public int getContainersToSignalCount() {
        if (containersToSignalBuilder_ == null) {
          return containersToSignal_.size();
        } else {
          return containersToSignalBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.SignalContainerRequestProto containers_to_signal = 13;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto getContainersToSignal(int index) {
        if (containersToSignalBuilder_ == null) {
          return containersToSignal_.get(index);
        } else {
          return containersToSignalBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.SignalContainerRequestProto containers_to_signal = 13;</code>
       */
      public Builder setContainersToSignal(
          int index, org.apache.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto value) {
        if (containersToSignalBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainersToSignalIsMutable();
          containersToSignal_.set(index, value);
          onChanged();
        } else {
          containersToSignalBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.SignalContainerRequestProto containers_to_signal = 13;</code>
       */
      public Builder setContainersToSignal(
          int index, org.apache.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto.Builder builderForValue) {
        if (containersToSignalBuilder_ == null) {
          ensureContainersToSignalIsMutable();
          containersToSignal_.set(index, builderForValue.build());
          onChanged();
        } else {
          containersToSignalBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.SignalContainerRequestProto containers_to_signal = 13;</code>
       */
      public Builder addContainersToSignal(org.apache.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto value) {
        if (containersToSignalBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainersToSignalIsMutable();
          containersToSignal_.add(value);
          onChanged();
        } else {
          containersToSignalBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.SignalContainerRequestProto containers_to_signal = 13;</code>
       */
      public Builder addContainersToSignal(
          int index, org.apache.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto value) {
        if (containersToSignalBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainersToSignalIsMutable();
          containersToSignal_.add(index, value);
          onChanged();
        } else {
          containersToSignalBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.SignalContainerRequestProto containers_to_signal = 13;</code>
       */
      public Builder addContainersToSignal(
          org.apache.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto.Builder builderForValue) {
        if (containersToSignalBuilder_ == null) {
          ensureContainersToSignalIsMutable();
          containersToSignal_.add(builderForValue.build());
          onChanged();
        } else {
          containersToSignalBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.SignalContainerRequestProto containers_to_signal = 13;</code>
       */
      public Builder addContainersToSignal(
          int index, org.apache.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto.Builder builderForValue) {
        if (containersToSignalBuilder_ == null) {
          ensureContainersToSignalIsMutable();
          containersToSignal_.add(index, builderForValue.build());
          onChanged();
        } else {
          containersToSignalBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.SignalContainerRequestProto containers_to_signal = 13;</code>
       */
      public Builder addAllContainersToSignal(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto> values) {
        if (containersToSignalBuilder_ == null) {
          ensureContainersToSignalIsMutable();
          super.addAll(values, containersToSignal_);
          onChanged();
        } else {
          containersToSignalBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.SignalContainerRequestProto containers_to_signal = 13;</code>
       */
      public Builder clearContainersToSignal() {
        if (containersToSignalBuilder_ == null) {
          containersToSignal_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00001000);
          onChanged();
        } else {
          containersToSignalBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.SignalContainerRequestProto containers_to_signal = 13;</code>
       */
      public Builder removeContainersToSignal(int index) {
        if (containersToSignalBuilder_ == null) {
          ensureContainersToSignalIsMutable();
          containersToSignal_.remove(index);
          onChanged();
        } else {
          containersToSignalBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.SignalContainerRequestProto containers_to_signal = 13;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto.Builder getContainersToSignalBuilder(
          int index) {
        return getContainersToSignalFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.SignalContainerRequestProto containers_to_signal = 13;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProtoOrBuilder getContainersToSignalOrBuilder(
          int index) {
        if (containersToSignalBuilder_ == null) {
          return containersToSignal_.get(index);  } else {
          return containersToSignalBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.SignalContainerRequestProto containers_to_signal = 13;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProtoOrBuilder> 
           getContainersToSignalOrBuilderList() {
        if (containersToSignalBuilder_ != null) {
          return containersToSignalBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(containersToSignal_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.SignalContainerRequestProto containers_to_signal = 13;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto.Builder addContainersToSignalBuilder() {
        return getContainersToSignalFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.SignalContainerRequestProto containers_to_signal = 13;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto.Builder addContainersToSignalBuilder(
          int index) {
        return getContainersToSignalFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.SignalContainerRequestProto containers_to_signal = 13;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto.Builder> 
           getContainersToSignalBuilderList() {
        return getContainersToSignalFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto, org.apache.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProtoOrBuilder> 
          getContainersToSignalFieldBuilder() {
        if (containersToSignalBuilder_ == null) {
          containersToSignalBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto, org.apache.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnServiceProtos.SignalContainerRequestProtoOrBuilder>(
                  containersToSignal_,
                  ((bitField0_ & 0x00001000) == 0x00001000),
                  getParentForChildren(),
                  isClean());
          containersToSignal_ = null;
        }
        return containersToSignalBuilder_;
      }

      // optional .hadoop.yarn.ResourceProto resource = 14;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> resourceBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 14;</code>
       */
      public boolean hasResource() {
        return ((bitField0_ & 0x00002000) == 0x00002000);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 14;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource() {
        if (resourceBuilder_ == null) {
          return resource_;
        } else {
          return resourceBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 14;</code>
       */
      public Builder setResource(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (resourceBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          resource_ = value;
          onChanged();
        } else {
          resourceBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00002000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 14;</code>
       */
      public Builder setResource(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (resourceBuilder_ == null) {
          resource_ = builderForValue.build();
          onChanged();
        } else {
          resourceBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00002000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 14;</code>
       */
      public Builder mergeResource(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (resourceBuilder_ == null) {
          if (((bitField0_ & 0x00002000) == 0x00002000) &&
              resource_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            resource_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(resource_).mergeFrom(value).buildPartial();
          } else {
            resource_ = value;
          }
          onChanged();
        } else {
          resourceBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00002000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 14;</code>
       */
      public Builder clearResource() {
        if (resourceBuilder_ == null) {
          resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
          onChanged();
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00002000);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 14;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getResourceBuilder() {
        bitField0_ |= 0x00002000;
        onChanged();
        return getResourceFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 14;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder() {
        if (resourceBuilder_ != null) {
          return resourceBuilder_.getMessageOrBuilder();
        } else {
          return resource_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 14;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getResourceFieldBuilder() {
        if (resourceBuilder_ == null) {
          resourceBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  resource_,
                  getParentForChildren(),
                  isClean());
          resource_ = null;
        }
        return resourceBuilder_;
      }

      // optional .hadoop.yarn.ContainerQueuingLimitProto container_queuing_limit = 15;
      private org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto containerQueuingLimit_ = org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProtoOrBuilder> containerQueuingLimitBuilder_;
      /**
       * <code>optional .hadoop.yarn.ContainerQueuingLimitProto container_queuing_limit = 15;</code>
       */
      public boolean hasContainerQueuingLimit() {
        return ((bitField0_ & 0x00004000) == 0x00004000);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerQueuingLimitProto container_queuing_limit = 15;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto getContainerQueuingLimit() {
        if (containerQueuingLimitBuilder_ == null) {
          return containerQueuingLimit_;
        } else {
          return containerQueuingLimitBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerQueuingLimitProto container_queuing_limit = 15;</code>
       */
      public Builder setContainerQueuingLimit(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto value) {
        if (containerQueuingLimitBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          containerQueuingLimit_ = value;
          onChanged();
        } else {
          containerQueuingLimitBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00004000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerQueuingLimitProto container_queuing_limit = 15;</code>
       */
      public Builder setContainerQueuingLimit(
          org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto.Builder builderForValue) {
        if (containerQueuingLimitBuilder_ == null) {
          containerQueuingLimit_ = builderForValue.build();
          onChanged();
        } else {
          containerQueuingLimitBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00004000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerQueuingLimitProto container_queuing_limit = 15;</code>
       */
      public Builder mergeContainerQueuingLimit(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto value) {
        if (containerQueuingLimitBuilder_ == null) {
          if (((bitField0_ & 0x00004000) == 0x00004000) &&
              containerQueuingLimit_ != org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto.getDefaultInstance()) {
            containerQueuingLimit_ =
              org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto.newBuilder(containerQueuingLimit_).mergeFrom(value).buildPartial();
          } else {
            containerQueuingLimit_ = value;
          }
          onChanged();
        } else {
          containerQueuingLimitBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00004000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerQueuingLimitProto container_queuing_limit = 15;</code>
       */
      public Builder clearContainerQueuingLimit() {
        if (containerQueuingLimitBuilder_ == null) {
          containerQueuingLimit_ = org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto.getDefaultInstance();
          onChanged();
        } else {
          containerQueuingLimitBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00004000);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerQueuingLimitProto container_queuing_limit = 15;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto.Builder getContainerQueuingLimitBuilder() {
        bitField0_ |= 0x00004000;
        onChanged();
        return getContainerQueuingLimitFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ContainerQueuingLimitProto container_queuing_limit = 15;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProtoOrBuilder getContainerQueuingLimitOrBuilder() {
        if (containerQueuingLimitBuilder_ != null) {
          return containerQueuingLimitBuilder_.getMessageOrBuilder();
        } else {
          return containerQueuingLimit_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerQueuingLimitProto container_queuing_limit = 15;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProtoOrBuilder> 
          getContainerQueuingLimitFieldBuilder() {
        if (containerQueuingLimitBuilder_ == null) {
          containerQueuingLimitBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProtoOrBuilder>(
                  containerQueuingLimit_,
                  getParentForChildren(),
                  isClean());
          containerQueuingLimit_ = null;
        }
        return containerQueuingLimitBuilder_;
      }

      // repeated .hadoop.yarn.AppCollectorsMapProto app_collectors_map = 16;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto> appCollectorsMap_ =
        java.util.Collections.emptyList();
      private void ensureAppCollectorsMapIsMutable() {
        if (!((bitField0_ & 0x00008000) == 0x00008000)) {
          appCollectorsMap_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto>(appCollectorsMap_);
          bitField0_ |= 0x00008000;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProtoOrBuilder> appCollectorsMapBuilder_;

      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors_map = 16;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto> getAppCollectorsMapList() {
        if (appCollectorsMapBuilder_ == null) {
          return java.util.Collections.unmodifiableList(appCollectorsMap_);
        } else {
          return appCollectorsMapBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors_map = 16;</code>
       */
      public int getAppCollectorsMapCount() {
        if (appCollectorsMapBuilder_ == null) {
          return appCollectorsMap_.size();
        } else {
          return appCollectorsMapBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors_map = 16;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto getAppCollectorsMap(int index) {
        if (appCollectorsMapBuilder_ == null) {
          return appCollectorsMap_.get(index);
        } else {
          return appCollectorsMapBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors_map = 16;</code>
       */
      public Builder setAppCollectorsMap(
          int index, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto value) {
        if (appCollectorsMapBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAppCollectorsMapIsMutable();
          appCollectorsMap_.set(index, value);
          onChanged();
        } else {
          appCollectorsMapBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors_map = 16;</code>
       */
      public Builder setAppCollectorsMap(
          int index, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.Builder builderForValue) {
        if (appCollectorsMapBuilder_ == null) {
          ensureAppCollectorsMapIsMutable();
          appCollectorsMap_.set(index, builderForValue.build());
          onChanged();
        } else {
          appCollectorsMapBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors_map = 16;</code>
       */
      public Builder addAppCollectorsMap(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto value) {
        if (appCollectorsMapBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAppCollectorsMapIsMutable();
          appCollectorsMap_.add(value);
          onChanged();
        } else {
          appCollectorsMapBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors_map = 16;</code>
       */
      public Builder addAppCollectorsMap(
          int index, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto value) {
        if (appCollectorsMapBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAppCollectorsMapIsMutable();
          appCollectorsMap_.add(index, value);
          onChanged();
        } else {
          appCollectorsMapBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors_map = 16;</code>
       */
      public Builder addAppCollectorsMap(
          org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.Builder builderForValue) {
        if (appCollectorsMapBuilder_ == null) {
          ensureAppCollectorsMapIsMutable();
          appCollectorsMap_.add(builderForValue.build());
          onChanged();
        } else {
          appCollectorsMapBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors_map = 16;</code>
       */
      public Builder addAppCollectorsMap(
          int index, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.Builder builderForValue) {
        if (appCollectorsMapBuilder_ == null) {
          ensureAppCollectorsMapIsMutable();
          appCollectorsMap_.add(index, builderForValue.build());
          onChanged();
        } else {
          appCollectorsMapBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors_map = 16;</code>
       */
      public Builder addAllAppCollectorsMap(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto> values) {
        if (appCollectorsMapBuilder_ == null) {
          ensureAppCollectorsMapIsMutable();
          super.addAll(values, appCollectorsMap_);
          onChanged();
        } else {
          appCollectorsMapBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors_map = 16;</code>
       */
      public Builder clearAppCollectorsMap() {
        if (appCollectorsMapBuilder_ == null) {
          appCollectorsMap_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00008000);
          onChanged();
        } else {
          appCollectorsMapBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors_map = 16;</code>
       */
      public Builder removeAppCollectorsMap(int index) {
        if (appCollectorsMapBuilder_ == null) {
          ensureAppCollectorsMapIsMutable();
          appCollectorsMap_.remove(index);
          onChanged();
        } else {
          appCollectorsMapBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors_map = 16;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.Builder getAppCollectorsMapBuilder(
          int index) {
        return getAppCollectorsMapFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors_map = 16;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProtoOrBuilder getAppCollectorsMapOrBuilder(
          int index) {
        if (appCollectorsMapBuilder_ == null) {
          return appCollectorsMap_.get(index);  } else {
          return appCollectorsMapBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors_map = 16;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProtoOrBuilder> 
           getAppCollectorsMapOrBuilderList() {
        if (appCollectorsMapBuilder_ != null) {
          return appCollectorsMapBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(appCollectorsMap_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors_map = 16;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.Builder addAppCollectorsMapBuilder() {
        return getAppCollectorsMapFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors_map = 16;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.Builder addAppCollectorsMapBuilder(
          int index) {
        return getAppCollectorsMapFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors_map = 16;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.Builder> 
           getAppCollectorsMapBuilderList() {
        return getAppCollectorsMapFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProtoOrBuilder> 
          getAppCollectorsMapFieldBuilder() {
        if (appCollectorsMapBuilder_ == null) {
          appCollectorsMapBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProtoOrBuilder>(
                  appCollectorsMap_,
                  ((bitField0_ & 0x00008000) == 0x00008000),
                  getParentForChildren(),
                  isClean());
          appCollectorsMap_ = null;
        }
        return appCollectorsMapBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.NodeHeartbeatResponseProto)
    }

    static {
      defaultInstance = new NodeHeartbeatResponseProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.NodeHeartbeatResponseProto)
  }

  public interface ContainerQueuingLimitProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional int32 max_queue_length = 1;
    /**
     * <code>optional int32 max_queue_length = 1;</code>
     */
    boolean hasMaxQueueLength();
    /**
     * <code>optional int32 max_queue_length = 1;</code>
     */
    int getMaxQueueLength();

    // optional int32 max_queue_wait_time_in_ms = 2;
    /**
     * <code>optional int32 max_queue_wait_time_in_ms = 2;</code>
     */
    boolean hasMaxQueueWaitTimeInMs();
    /**
     * <code>optional int32 max_queue_wait_time_in_ms = 2;</code>
     */
    int getMaxQueueWaitTimeInMs();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ContainerQueuingLimitProto}
   */
  public static final class ContainerQueuingLimitProto extends
      com.google.protobuf.GeneratedMessage
      implements ContainerQueuingLimitProtoOrBuilder {
    // Use ContainerQueuingLimitProto.newBuilder() to construct.
    private ContainerQueuingLimitProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ContainerQueuingLimitProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ContainerQueuingLimitProto defaultInstance;
    public static ContainerQueuingLimitProto getDefaultInstance() {
      return defaultInstance;
    }

    public ContainerQueuingLimitProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ContainerQueuingLimitProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              maxQueueLength_ = input.readInt32();
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              maxQueueWaitTimeInMs_ = input.readInt32();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_ContainerQueuingLimitProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_ContainerQueuingLimitProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ContainerQueuingLimitProto> PARSER =
        new com.google.protobuf.AbstractParser<ContainerQueuingLimitProto>() {
      public ContainerQueuingLimitProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ContainerQueuingLimitProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ContainerQueuingLimitProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional int32 max_queue_length = 1;
    public static final int MAX_QUEUE_LENGTH_FIELD_NUMBER = 1;
    private int maxQueueLength_;
    /**
     * <code>optional int32 max_queue_length = 1;</code>
     */
    public boolean hasMaxQueueLength() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional int32 max_queue_length = 1;</code>
     */
    public int getMaxQueueLength() {
      return maxQueueLength_;
    }

    // optional int32 max_queue_wait_time_in_ms = 2;
    public static final int MAX_QUEUE_WAIT_TIME_IN_MS_FIELD_NUMBER = 2;
    private int maxQueueWaitTimeInMs_;
    /**
     * <code>optional int32 max_queue_wait_time_in_ms = 2;</code>
     */
    public boolean hasMaxQueueWaitTimeInMs() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int32 max_queue_wait_time_in_ms = 2;</code>
     */
    public int getMaxQueueWaitTimeInMs() {
      return maxQueueWaitTimeInMs_;
    }

    private void initFields() {
      maxQueueLength_ = 0;
      maxQueueWaitTimeInMs_ = 0;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeInt32(1, maxQueueLength_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt32(2, maxQueueWaitTimeInMs_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(1, maxQueueLength_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, maxQueueWaitTimeInMs_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto other = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto) obj;

      boolean result = true;
      result = result && (hasMaxQueueLength() == other.hasMaxQueueLength());
      if (hasMaxQueueLength()) {
        result = result && (getMaxQueueLength()
            == other.getMaxQueueLength());
      }
      result = result && (hasMaxQueueWaitTimeInMs() == other.hasMaxQueueWaitTimeInMs());
      if (hasMaxQueueWaitTimeInMs()) {
        result = result && (getMaxQueueWaitTimeInMs()
            == other.getMaxQueueWaitTimeInMs());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasMaxQueueLength()) {
        hash = (37 * hash) + MAX_QUEUE_LENGTH_FIELD_NUMBER;
        hash = (53 * hash) + getMaxQueueLength();
      }
      if (hasMaxQueueWaitTimeInMs()) {
        hash = (37 * hash) + MAX_QUEUE_WAIT_TIME_IN_MS_FIELD_NUMBER;
        hash = (53 * hash) + getMaxQueueWaitTimeInMs();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ContainerQueuingLimitProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_ContainerQueuingLimitProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_ContainerQueuingLimitProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        maxQueueLength_ = 0;
        bitField0_ = (bitField0_ & ~0x00000001);
        maxQueueWaitTimeInMs_ = 0;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_ContainerQueuingLimitProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto build() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto result = new org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.maxQueueLength_ = maxQueueLength_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.maxQueueWaitTimeInMs_ = maxQueueWaitTimeInMs_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto.getDefaultInstance()) return this;
        if (other.hasMaxQueueLength()) {
          setMaxQueueLength(other.getMaxQueueLength());
        }
        if (other.hasMaxQueueWaitTimeInMs()) {
          setMaxQueueWaitTimeInMs(other.getMaxQueueWaitTimeInMs());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ContainerQueuingLimitProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional int32 max_queue_length = 1;
      private int maxQueueLength_ ;
      /**
       * <code>optional int32 max_queue_length = 1;</code>
       */
      public boolean hasMaxQueueLength() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional int32 max_queue_length = 1;</code>
       */
      public int getMaxQueueLength() {
        return maxQueueLength_;
      }
      /**
       * <code>optional int32 max_queue_length = 1;</code>
       */
      public Builder setMaxQueueLength(int value) {
        bitField0_ |= 0x00000001;
        maxQueueLength_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 max_queue_length = 1;</code>
       */
      public Builder clearMaxQueueLength() {
        bitField0_ = (bitField0_ & ~0x00000001);
        maxQueueLength_ = 0;
        onChanged();
        return this;
      }

      // optional int32 max_queue_wait_time_in_ms = 2;
      private int maxQueueWaitTimeInMs_ ;
      /**
       * <code>optional int32 max_queue_wait_time_in_ms = 2;</code>
       */
      public boolean hasMaxQueueWaitTimeInMs() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional int32 max_queue_wait_time_in_ms = 2;</code>
       */
      public int getMaxQueueWaitTimeInMs() {
        return maxQueueWaitTimeInMs_;
      }
      /**
       * <code>optional int32 max_queue_wait_time_in_ms = 2;</code>
       */
      public Builder setMaxQueueWaitTimeInMs(int value) {
        bitField0_ |= 0x00000002;
        maxQueueWaitTimeInMs_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 max_queue_wait_time_in_ms = 2;</code>
       */
      public Builder clearMaxQueueWaitTimeInMs() {
        bitField0_ = (bitField0_ & ~0x00000002);
        maxQueueWaitTimeInMs_ = 0;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ContainerQueuingLimitProto)
    }

    static {
      defaultInstance = new ContainerQueuingLimitProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ContainerQueuingLimitProto)
  }

  public interface SystemCredentialsForAppsProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.ApplicationIdProto appId = 1;
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
     */
    boolean hasAppId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getAppId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getAppIdOrBuilder();

    // optional bytes credentialsForApp = 2;
    /**
     * <code>optional bytes credentialsForApp = 2;</code>
     */
    boolean hasCredentialsForApp();
    /**
     * <code>optional bytes credentialsForApp = 2;</code>
     */
    com.google.protobuf.ByteString getCredentialsForApp();
  }
  /**
   * Protobuf type {@code hadoop.yarn.SystemCredentialsForAppsProto}
   */
  public static final class SystemCredentialsForAppsProto extends
      com.google.protobuf.GeneratedMessage
      implements SystemCredentialsForAppsProtoOrBuilder {
    // Use SystemCredentialsForAppsProto.newBuilder() to construct.
    private SystemCredentialsForAppsProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private SystemCredentialsForAppsProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final SystemCredentialsForAppsProto defaultInstance;
    public static SystemCredentialsForAppsProto getDefaultInstance() {
      return defaultInstance;
    }

    public SystemCredentialsForAppsProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private SystemCredentialsForAppsProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = appId_.toBuilder();
              }
              appId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(appId_);
                appId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              credentialsForApp_ = input.readBytes();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_SystemCredentialsForAppsProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_SystemCredentialsForAppsProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto.Builder.class);
    }

    public static com.google.protobuf.Parser<SystemCredentialsForAppsProto> PARSER =
        new com.google.protobuf.AbstractParser<SystemCredentialsForAppsProto>() {
      public SystemCredentialsForAppsProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new SystemCredentialsForAppsProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<SystemCredentialsForAppsProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.ApplicationIdProto appId = 1;
    public static final int APPID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto appId_;
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
     */
    public boolean hasAppId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getAppId() {
      return appId_;
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getAppIdOrBuilder() {
      return appId_;
    }

    // optional bytes credentialsForApp = 2;
    public static final int CREDENTIALSFORAPP_FIELD_NUMBER = 2;
    private com.google.protobuf.ByteString credentialsForApp_;
    /**
     * <code>optional bytes credentialsForApp = 2;</code>
     */
    public boolean hasCredentialsForApp() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional bytes credentialsForApp = 2;</code>
     */
    public com.google.protobuf.ByteString getCredentialsForApp() {
      return credentialsForApp_;
    }

    private void initFields() {
      appId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
      credentialsForApp_ = com.google.protobuf.ByteString.EMPTY;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, appId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, credentialsForApp_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, appId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, credentialsForApp_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto other = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto) obj;

      boolean result = true;
      result = result && (hasAppId() == other.hasAppId());
      if (hasAppId()) {
        result = result && getAppId()
            .equals(other.getAppId());
      }
      result = result && (hasCredentialsForApp() == other.hasCredentialsForApp());
      if (hasCredentialsForApp()) {
        result = result && getCredentialsForApp()
            .equals(other.getCredentialsForApp());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasAppId()) {
        hash = (37 * hash) + APPID_FIELD_NUMBER;
        hash = (53 * hash) + getAppId().hashCode();
      }
      if (hasCredentialsForApp()) {
        hash = (37 * hash) + CREDENTIALSFORAPP_FIELD_NUMBER;
        hash = (53 * hash) + getCredentialsForApp().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.SystemCredentialsForAppsProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_SystemCredentialsForAppsProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_SystemCredentialsForAppsProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getAppIdFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (appIdBuilder_ == null) {
          appId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
        } else {
          appIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        credentialsForApp_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_SystemCredentialsForAppsProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto build() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto result = new org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (appIdBuilder_ == null) {
          result.appId_ = appId_;
        } else {
          result.appId_ = appIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.credentialsForApp_ = credentialsForApp_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto.getDefaultInstance()) return this;
        if (other.hasAppId()) {
          mergeAppId(other.getAppId());
        }
        if (other.hasCredentialsForApp()) {
          setCredentialsForApp(other.getCredentialsForApp());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SystemCredentialsForAppsProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.ApplicationIdProto appId = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto appId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> appIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
       */
      public boolean hasAppId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getAppId() {
        if (appIdBuilder_ == null) {
          return appId_;
        } else {
          return appIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
       */
      public Builder setAppId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (appIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          appId_ = value;
          onChanged();
        } else {
          appIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
       */
      public Builder setAppId(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder builderForValue) {
        if (appIdBuilder_ == null) {
          appId_ = builderForValue.build();
          onChanged();
        } else {
          appIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
       */
      public Builder mergeAppId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (appIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              appId_ != org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance()) {
            appId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.newBuilder(appId_).mergeFrom(value).buildPartial();
          } else {
            appId_ = value;
          }
          onChanged();
        } else {
          appIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
       */
      public Builder clearAppId() {
        if (appIdBuilder_ == null) {
          appId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
          onChanged();
        } else {
          appIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder getAppIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getAppIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getAppIdOrBuilder() {
        if (appIdBuilder_ != null) {
          return appIdBuilder_.getMessageOrBuilder();
        } else {
          return appId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> 
          getAppIdFieldBuilder() {
        if (appIdBuilder_ == null) {
          appIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder>(
                  appId_,
                  getParentForChildren(),
                  isClean());
          appId_ = null;
        }
        return appIdBuilder_;
      }

      // optional bytes credentialsForApp = 2;
      private com.google.protobuf.ByteString credentialsForApp_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes credentialsForApp = 2;</code>
       */
      public boolean hasCredentialsForApp() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional bytes credentialsForApp = 2;</code>
       */
      public com.google.protobuf.ByteString getCredentialsForApp() {
        return credentialsForApp_;
      }
      /**
       * <code>optional bytes credentialsForApp = 2;</code>
       */
      public Builder setCredentialsForApp(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        credentialsForApp_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes credentialsForApp = 2;</code>
       */
      public Builder clearCredentialsForApp() {
        bitField0_ = (bitField0_ & ~0x00000002);
        credentialsForApp_ = getDefaultInstance().getCredentialsForApp();
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.SystemCredentialsForAppsProto)
    }

    static {
      defaultInstance = new SystemCredentialsForAppsProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.SystemCredentialsForAppsProto)
  }

  public interface AppCollectorsMapProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.ApplicationIdProto appId = 1;
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
     */
    boolean hasAppId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getAppId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getAppIdOrBuilder();

    // optional string appCollectorAddr = 2;
    /**
     * <code>optional string appCollectorAddr = 2;</code>
     */
    boolean hasAppCollectorAddr();
    /**
     * <code>optional string appCollectorAddr = 2;</code>
     */
    java.lang.String getAppCollectorAddr();
    /**
     * <code>optional string appCollectorAddr = 2;</code>
     */
    com.google.protobuf.ByteString
        getAppCollectorAddrBytes();
  }
  /**
   * Protobuf type {@code hadoop.yarn.AppCollectorsMapProto}
   *
   * <pre>
   *&#47;/////////////////////////////////////////////////////////////////////
   * //// From collector_nodemanager_protocol ////////////////////////////
   * //////////////////////////////////////////////////////////////////////
   * </pre>
   */
  public static final class AppCollectorsMapProto extends
      com.google.protobuf.GeneratedMessage
      implements AppCollectorsMapProtoOrBuilder {
    // Use AppCollectorsMapProto.newBuilder() to construct.
    private AppCollectorsMapProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private AppCollectorsMapProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final AppCollectorsMapProto defaultInstance;
    public static AppCollectorsMapProto getDefaultInstance() {
      return defaultInstance;
    }

    public AppCollectorsMapProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private AppCollectorsMapProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = appId_.toBuilder();
              }
              appId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(appId_);
                appId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              appCollectorAddr_ = input.readBytes();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_AppCollectorsMapProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_AppCollectorsMapProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.Builder.class);
    }

    public static com.google.protobuf.Parser<AppCollectorsMapProto> PARSER =
        new com.google.protobuf.AbstractParser<AppCollectorsMapProto>() {
      public AppCollectorsMapProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new AppCollectorsMapProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<AppCollectorsMapProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.ApplicationIdProto appId = 1;
    public static final int APPID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto appId_;
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
     */
    public boolean hasAppId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getAppId() {
      return appId_;
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getAppIdOrBuilder() {
      return appId_;
    }

    // optional string appCollectorAddr = 2;
    public static final int APPCOLLECTORADDR_FIELD_NUMBER = 2;
    private java.lang.Object appCollectorAddr_;
    /**
     * <code>optional string appCollectorAddr = 2;</code>
     */
    public boolean hasAppCollectorAddr() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional string appCollectorAddr = 2;</code>
     */
    public java.lang.String getAppCollectorAddr() {
      java.lang.Object ref = appCollectorAddr_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          appCollectorAddr_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string appCollectorAddr = 2;</code>
     */
    public com.google.protobuf.ByteString
        getAppCollectorAddrBytes() {
      java.lang.Object ref = appCollectorAddr_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        appCollectorAddr_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private void initFields() {
      appId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
      appCollectorAddr_ = "";
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, appId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, getAppCollectorAddrBytes());
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, appId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, getAppCollectorAddrBytes());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto other = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto) obj;

      boolean result = true;
      result = result && (hasAppId() == other.hasAppId());
      if (hasAppId()) {
        result = result && getAppId()
            .equals(other.getAppId());
      }
      result = result && (hasAppCollectorAddr() == other.hasAppCollectorAddr());
      if (hasAppCollectorAddr()) {
        result = result && getAppCollectorAddr()
            .equals(other.getAppCollectorAddr());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasAppId()) {
        hash = (37 * hash) + APPID_FIELD_NUMBER;
        hash = (53 * hash) + getAppId().hashCode();
      }
      if (hasAppCollectorAddr()) {
        hash = (37 * hash) + APPCOLLECTORADDR_FIELD_NUMBER;
        hash = (53 * hash) + getAppCollectorAddr().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.AppCollectorsMapProto}
     *
     * <pre>
     *&#47;/////////////////////////////////////////////////////////////////////
     * //// From collector_nodemanager_protocol ////////////////////////////
     * //////////////////////////////////////////////////////////////////////
     * </pre>
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_AppCollectorsMapProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_AppCollectorsMapProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getAppIdFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (appIdBuilder_ == null) {
          appId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
        } else {
          appIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        appCollectorAddr_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_AppCollectorsMapProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto build() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto result = new org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (appIdBuilder_ == null) {
          result.appId_ = appId_;
        } else {
          result.appId_ = appIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.appCollectorAddr_ = appCollectorAddr_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.getDefaultInstance()) return this;
        if (other.hasAppId()) {
          mergeAppId(other.getAppId());
        }
        if (other.hasAppCollectorAddr()) {
          bitField0_ |= 0x00000002;
          appCollectorAddr_ = other.appCollectorAddr_;
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.ApplicationIdProto appId = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto appId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> appIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
       */
      public boolean hasAppId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getAppId() {
        if (appIdBuilder_ == null) {
          return appId_;
        } else {
          return appIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
       */
      public Builder setAppId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (appIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          appId_ = value;
          onChanged();
        } else {
          appIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
       */
      public Builder setAppId(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder builderForValue) {
        if (appIdBuilder_ == null) {
          appId_ = builderForValue.build();
          onChanged();
        } else {
          appIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
       */
      public Builder mergeAppId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (appIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              appId_ != org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance()) {
            appId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.newBuilder(appId_).mergeFrom(value).buildPartial();
          } else {
            appId_ = value;
          }
          onChanged();
        } else {
          appIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
       */
      public Builder clearAppId() {
        if (appIdBuilder_ == null) {
          appId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
          onChanged();
        } else {
          appIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder getAppIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getAppIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getAppIdOrBuilder() {
        if (appIdBuilder_ != null) {
          return appIdBuilder_.getMessageOrBuilder();
        } else {
          return appId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> 
          getAppIdFieldBuilder() {
        if (appIdBuilder_ == null) {
          appIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder>(
                  appId_,
                  getParentForChildren(),
                  isClean());
          appId_ = null;
        }
        return appIdBuilder_;
      }

      // optional string appCollectorAddr = 2;
      private java.lang.Object appCollectorAddr_ = "";
      /**
       * <code>optional string appCollectorAddr = 2;</code>
       */
      public boolean hasAppCollectorAddr() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional string appCollectorAddr = 2;</code>
       */
      public java.lang.String getAppCollectorAddr() {
        java.lang.Object ref = appCollectorAddr_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          appCollectorAddr_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string appCollectorAddr = 2;</code>
       */
      public com.google.protobuf.ByteString
          getAppCollectorAddrBytes() {
        java.lang.Object ref = appCollectorAddr_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          appCollectorAddr_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string appCollectorAddr = 2;</code>
       */
      public Builder setAppCollectorAddr(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        appCollectorAddr_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string appCollectorAddr = 2;</code>
       */
      public Builder clearAppCollectorAddr() {
        bitField0_ = (bitField0_ & ~0x00000002);
        appCollectorAddr_ = getDefaultInstance().getAppCollectorAddr();
        onChanged();
        return this;
      }
      /**
       * <code>optional string appCollectorAddr = 2;</code>
       */
      public Builder setAppCollectorAddrBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        appCollectorAddr_ = value;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.AppCollectorsMapProto)
    }

    static {
      defaultInstance = new AppCollectorsMapProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.AppCollectorsMapProto)
  }

  public interface ReportNewCollectorInfoRequestProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // repeated .hadoop.yarn.AppCollectorsMapProto app_collectors = 1;
    /**
     * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors = 1;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto> 
        getAppCollectorsList();
    /**
     * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto getAppCollectors(int index);
    /**
     * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors = 1;</code>
     */
    int getAppCollectorsCount();
    /**
     * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProtoOrBuilder> 
        getAppCollectorsOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProtoOrBuilder getAppCollectorsOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.ReportNewCollectorInfoRequestProto}
   *
   * <pre>
   *&#47;///////////////////////////////////////////////////
   * ///// collector_nodemanager_protocol //////////////
   * ////////////////////////////////////////////////////
   * </pre>
   */
  public static final class ReportNewCollectorInfoRequestProto extends
      com.google.protobuf.GeneratedMessage
      implements ReportNewCollectorInfoRequestProtoOrBuilder {
    // Use ReportNewCollectorInfoRequestProto.newBuilder() to construct.
    private ReportNewCollectorInfoRequestProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ReportNewCollectorInfoRequestProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ReportNewCollectorInfoRequestProto defaultInstance;
    public static ReportNewCollectorInfoRequestProto getDefaultInstance() {
      return defaultInstance;
    }

    public ReportNewCollectorInfoRequestProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ReportNewCollectorInfoRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                appCollectors_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto>();
                mutable_bitField0_ |= 0x00000001;
              }
              appCollectors_.add(input.readMessage(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          appCollectors_ = java.util.Collections.unmodifiableList(appCollectors_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_ReportNewCollectorInfoRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_ReportNewCollectorInfoRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoRequestProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoRequestProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ReportNewCollectorInfoRequestProto> PARSER =
        new com.google.protobuf.AbstractParser<ReportNewCollectorInfoRequestProto>() {
      public ReportNewCollectorInfoRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ReportNewCollectorInfoRequestProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ReportNewCollectorInfoRequestProto> getParserForType() {
      return PARSER;
    }

    // repeated .hadoop.yarn.AppCollectorsMapProto app_collectors = 1;
    public static final int APP_COLLECTORS_FIELD_NUMBER = 1;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto> appCollectors_;
    /**
     * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors = 1;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto> getAppCollectorsList() {
      return appCollectors_;
    }
    /**
     * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors = 1;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProtoOrBuilder> 
        getAppCollectorsOrBuilderList() {
      return appCollectors_;
    }
    /**
     * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors = 1;</code>
     */
    public int getAppCollectorsCount() {
      return appCollectors_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto getAppCollectors(int index) {
      return appCollectors_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProtoOrBuilder getAppCollectorsOrBuilder(
        int index) {
      return appCollectors_.get(index);
    }

    private void initFields() {
      appCollectors_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      for (int i = 0; i < appCollectors_.size(); i++) {
        output.writeMessage(1, appCollectors_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < appCollectors_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, appCollectors_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoRequestProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoRequestProto other = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoRequestProto) obj;

      boolean result = true;
      result = result && getAppCollectorsList()
          .equals(other.getAppCollectorsList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getAppCollectorsCount() > 0) {
        hash = (37 * hash) + APP_COLLECTORS_FIELD_NUMBER;
        hash = (53 * hash) + getAppCollectorsList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoRequestProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ReportNewCollectorInfoRequestProto}
     *
     * <pre>
     *&#47;///////////////////////////////////////////////////
     * ///// collector_nodemanager_protocol //////////////
     * ////////////////////////////////////////////////////
     * </pre>
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_ReportNewCollectorInfoRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_ReportNewCollectorInfoRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoRequestProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoRequestProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getAppCollectorsFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (appCollectorsBuilder_ == null) {
          appCollectors_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          appCollectorsBuilder_.clear();
        }
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_ReportNewCollectorInfoRequestProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoRequestProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoRequestProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoRequestProto build() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoRequestProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoRequestProto result = new org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoRequestProto(this);
        int from_bitField0_ = bitField0_;
        if (appCollectorsBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            appCollectors_ = java.util.Collections.unmodifiableList(appCollectors_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.appCollectors_ = appCollectors_;
        } else {
          result.appCollectors_ = appCollectorsBuilder_.build();
        }
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoRequestProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoRequestProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoRequestProto.getDefaultInstance()) return this;
        if (appCollectorsBuilder_ == null) {
          if (!other.appCollectors_.isEmpty()) {
            if (appCollectors_.isEmpty()) {
              appCollectors_ = other.appCollectors_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureAppCollectorsIsMutable();
              appCollectors_.addAll(other.appCollectors_);
            }
            onChanged();
          }
        } else {
          if (!other.appCollectors_.isEmpty()) {
            if (appCollectorsBuilder_.isEmpty()) {
              appCollectorsBuilder_.dispose();
              appCollectorsBuilder_ = null;
              appCollectors_ = other.appCollectors_;
              bitField0_ = (bitField0_ & ~0x00000001);
              appCollectorsBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getAppCollectorsFieldBuilder() : null;
            } else {
              appCollectorsBuilder_.addAllMessages(other.appCollectors_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoRequestProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // repeated .hadoop.yarn.AppCollectorsMapProto app_collectors = 1;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto> appCollectors_ =
        java.util.Collections.emptyList();
      private void ensureAppCollectorsIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          appCollectors_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto>(appCollectors_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProtoOrBuilder> appCollectorsBuilder_;

      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors = 1;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto> getAppCollectorsList() {
        if (appCollectorsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(appCollectors_);
        } else {
          return appCollectorsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors = 1;</code>
       */
      public int getAppCollectorsCount() {
        if (appCollectorsBuilder_ == null) {
          return appCollectors_.size();
        } else {
          return appCollectorsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto getAppCollectors(int index) {
        if (appCollectorsBuilder_ == null) {
          return appCollectors_.get(index);
        } else {
          return appCollectorsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors = 1;</code>
       */
      public Builder setAppCollectors(
          int index, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto value) {
        if (appCollectorsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAppCollectorsIsMutable();
          appCollectors_.set(index, value);
          onChanged();
        } else {
          appCollectorsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors = 1;</code>
       */
      public Builder setAppCollectors(
          int index, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.Builder builderForValue) {
        if (appCollectorsBuilder_ == null) {
          ensureAppCollectorsIsMutable();
          appCollectors_.set(index, builderForValue.build());
          onChanged();
        } else {
          appCollectorsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors = 1;</code>
       */
      public Builder addAppCollectors(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto value) {
        if (appCollectorsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAppCollectorsIsMutable();
          appCollectors_.add(value);
          onChanged();
        } else {
          appCollectorsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors = 1;</code>
       */
      public Builder addAppCollectors(
          int index, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto value) {
        if (appCollectorsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAppCollectorsIsMutable();
          appCollectors_.add(index, value);
          onChanged();
        } else {
          appCollectorsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors = 1;</code>
       */
      public Builder addAppCollectors(
          org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.Builder builderForValue) {
        if (appCollectorsBuilder_ == null) {
          ensureAppCollectorsIsMutable();
          appCollectors_.add(builderForValue.build());
          onChanged();
        } else {
          appCollectorsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors = 1;</code>
       */
      public Builder addAppCollectors(
          int index, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.Builder builderForValue) {
        if (appCollectorsBuilder_ == null) {
          ensureAppCollectorsIsMutable();
          appCollectors_.add(index, builderForValue.build());
          onChanged();
        } else {
          appCollectorsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors = 1;</code>
       */
      public Builder addAllAppCollectors(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto> values) {
        if (appCollectorsBuilder_ == null) {
          ensureAppCollectorsIsMutable();
          super.addAll(values, appCollectors_);
          onChanged();
        } else {
          appCollectorsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors = 1;</code>
       */
      public Builder clearAppCollectors() {
        if (appCollectorsBuilder_ == null) {
          appCollectors_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          appCollectorsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors = 1;</code>
       */
      public Builder removeAppCollectors(int index) {
        if (appCollectorsBuilder_ == null) {
          ensureAppCollectorsIsMutable();
          appCollectors_.remove(index);
          onChanged();
        } else {
          appCollectorsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.Builder getAppCollectorsBuilder(
          int index) {
        return getAppCollectorsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProtoOrBuilder getAppCollectorsOrBuilder(
          int index) {
        if (appCollectorsBuilder_ == null) {
          return appCollectors_.get(index);  } else {
          return appCollectorsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProtoOrBuilder> 
           getAppCollectorsOrBuilderList() {
        if (appCollectorsBuilder_ != null) {
          return appCollectorsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(appCollectors_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.Builder addAppCollectorsBuilder() {
        return getAppCollectorsFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.Builder addAppCollectorsBuilder(
          int index) {
        return getAppCollectorsFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.AppCollectorsMapProto app_collectors = 1;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.Builder> 
           getAppCollectorsBuilderList() {
        return getAppCollectorsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProtoOrBuilder> 
          getAppCollectorsFieldBuilder() {
        if (appCollectorsBuilder_ == null) {
          appCollectorsBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProto.Builder, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.AppCollectorsMapProtoOrBuilder>(
                  appCollectors_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          appCollectors_ = null;
        }
        return appCollectorsBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ReportNewCollectorInfoRequestProto)
    }

    static {
      defaultInstance = new ReportNewCollectorInfoRequestProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ReportNewCollectorInfoRequestProto)
  }

  public interface ReportNewCollectorInfoResponseProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hadoop.yarn.ReportNewCollectorInfoResponseProto}
   */
  public static final class ReportNewCollectorInfoResponseProto extends
      com.google.protobuf.GeneratedMessage
      implements ReportNewCollectorInfoResponseProtoOrBuilder {
    // Use ReportNewCollectorInfoResponseProto.newBuilder() to construct.
    private ReportNewCollectorInfoResponseProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ReportNewCollectorInfoResponseProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ReportNewCollectorInfoResponseProto defaultInstance;
    public static ReportNewCollectorInfoResponseProto getDefaultInstance() {
      return defaultInstance;
    }

    public ReportNewCollectorInfoResponseProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ReportNewCollectorInfoResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_ReportNewCollectorInfoResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_ReportNewCollectorInfoResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoResponseProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoResponseProto.Builder.class);
    }

    public static com.google.protobuf.Parser<ReportNewCollectorInfoResponseProto> PARSER =
        new com.google.protobuf.AbstractParser<ReportNewCollectorInfoResponseProto>() {
      public ReportNewCollectorInfoResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ReportNewCollectorInfoResponseProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ReportNewCollectorInfoResponseProto> getParserForType() {
      return PARSER;
    }

    private void initFields() {
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoResponseProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoResponseProto other = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoResponseProto) obj;

      boolean result = true;
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoResponseProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ReportNewCollectorInfoResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_ReportNewCollectorInfoResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_ReportNewCollectorInfoResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoResponseProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoResponseProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_ReportNewCollectorInfoResponseProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoResponseProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoResponseProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoResponseProto build() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoResponseProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoResponseProto result = new org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoResponseProto(this);
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoResponseProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoResponseProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoResponseProto.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.ReportNewCollectorInfoResponseProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ReportNewCollectorInfoResponseProto)
    }

    static {
      defaultInstance = new ReportNewCollectorInfoResponseProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ReportNewCollectorInfoResponseProto)
  }

  public interface GetTimelineCollectorContextRequestProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.ApplicationIdProto appId = 1;
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
     */
    boolean hasAppId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getAppId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getAppIdOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.GetTimelineCollectorContextRequestProto}
   */
  public static final class GetTimelineCollectorContextRequestProto extends
      com.google.protobuf.GeneratedMessage
      implements GetTimelineCollectorContextRequestProtoOrBuilder {
    // Use GetTimelineCollectorContextRequestProto.newBuilder() to construct.
    private GetTimelineCollectorContextRequestProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private GetTimelineCollectorContextRequestProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final GetTimelineCollectorContextRequestProto defaultInstance;
    public static GetTimelineCollectorContextRequestProto getDefaultInstance() {
      return defaultInstance;
    }

    public GetTimelineCollectorContextRequestProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private GetTimelineCollectorContextRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = appId_.toBuilder();
              }
              appId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(appId_);
                appId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_GetTimelineCollectorContextRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_GetTimelineCollectorContextRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextRequestProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextRequestProto.Builder.class);
    }

    public static com.google.protobuf.Parser<GetTimelineCollectorContextRequestProto> PARSER =
        new com.google.protobuf.AbstractParser<GetTimelineCollectorContextRequestProto>() {
      public GetTimelineCollectorContextRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new GetTimelineCollectorContextRequestProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<GetTimelineCollectorContextRequestProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.ApplicationIdProto appId = 1;
    public static final int APPID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto appId_;
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
     */
    public boolean hasAppId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getAppId() {
      return appId_;
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getAppIdOrBuilder() {
      return appId_;
    }

    private void initFields() {
      appId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, appId_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, appId_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextRequestProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextRequestProto other = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextRequestProto) obj;

      boolean result = true;
      result = result && (hasAppId() == other.hasAppId());
      if (hasAppId()) {
        result = result && getAppId()
            .equals(other.getAppId());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasAppId()) {
        hash = (37 * hash) + APPID_FIELD_NUMBER;
        hash = (53 * hash) + getAppId().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextRequestProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.GetTimelineCollectorContextRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_GetTimelineCollectorContextRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_GetTimelineCollectorContextRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextRequestProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextRequestProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getAppIdFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (appIdBuilder_ == null) {
          appId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
        } else {
          appIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_GetTimelineCollectorContextRequestProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextRequestProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextRequestProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextRequestProto build() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextRequestProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextRequestProto result = new org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (appIdBuilder_ == null) {
          result.appId_ = appId_;
        } else {
          result.appId_ = appIdBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextRequestProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextRequestProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextRequestProto.getDefaultInstance()) return this;
        if (other.hasAppId()) {
          mergeAppId(other.getAppId());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextRequestProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.ApplicationIdProto appId = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto appId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> appIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
       */
      public boolean hasAppId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getAppId() {
        if (appIdBuilder_ == null) {
          return appId_;
        } else {
          return appIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
       */
      public Builder setAppId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (appIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          appId_ = value;
          onChanged();
        } else {
          appIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
       */
      public Builder setAppId(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder builderForValue) {
        if (appIdBuilder_ == null) {
          appId_ = builderForValue.build();
          onChanged();
        } else {
          appIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
       */
      public Builder mergeAppId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (appIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              appId_ != org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance()) {
            appId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.newBuilder(appId_).mergeFrom(value).buildPartial();
          } else {
            appId_ = value;
          }
          onChanged();
        } else {
          appIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
       */
      public Builder clearAppId() {
        if (appIdBuilder_ == null) {
          appId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
          onChanged();
        } else {
          appIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder getAppIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getAppIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getAppIdOrBuilder() {
        if (appIdBuilder_ != null) {
          return appIdBuilder_.getMessageOrBuilder();
        } else {
          return appId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto appId = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> 
          getAppIdFieldBuilder() {
        if (appIdBuilder_ == null) {
          appIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder>(
                  appId_,
                  getParentForChildren(),
                  isClean());
          appId_ = null;
        }
        return appIdBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.GetTimelineCollectorContextRequestProto)
    }

    static {
      defaultInstance = new GetTimelineCollectorContextRequestProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.GetTimelineCollectorContextRequestProto)
  }

  public interface GetTimelineCollectorContextResponseProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional string user_id = 1;
    /**
     * <code>optional string user_id = 1;</code>
     */
    boolean hasUserId();
    /**
     * <code>optional string user_id = 1;</code>
     */
    java.lang.String getUserId();
    /**
     * <code>optional string user_id = 1;</code>
     */
    com.google.protobuf.ByteString
        getUserIdBytes();

    // optional string flow_name = 2;
    /**
     * <code>optional string flow_name = 2;</code>
     */
    boolean hasFlowName();
    /**
     * <code>optional string flow_name = 2;</code>
     */
    java.lang.String getFlowName();
    /**
     * <code>optional string flow_name = 2;</code>
     */
    com.google.protobuf.ByteString
        getFlowNameBytes();

    // optional string flow_version = 3;
    /**
     * <code>optional string flow_version = 3;</code>
     */
    boolean hasFlowVersion();
    /**
     * <code>optional string flow_version = 3;</code>
     */
    java.lang.String getFlowVersion();
    /**
     * <code>optional string flow_version = 3;</code>
     */
    com.google.protobuf.ByteString
        getFlowVersionBytes();

    // optional int64 flow_run_id = 4;
    /**
     * <code>optional int64 flow_run_id = 4;</code>
     */
    boolean hasFlowRunId();
    /**
     * <code>optional int64 flow_run_id = 4;</code>
     */
    long getFlowRunId();
  }
  /**
   * Protobuf type {@code hadoop.yarn.GetTimelineCollectorContextResponseProto}
   */
  public static final class GetTimelineCollectorContextResponseProto extends
      com.google.protobuf.GeneratedMessage
      implements GetTimelineCollectorContextResponseProtoOrBuilder {
    // Use GetTimelineCollectorContextResponseProto.newBuilder() to construct.
    private GetTimelineCollectorContextResponseProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private GetTimelineCollectorContextResponseProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final GetTimelineCollectorContextResponseProto defaultInstance;
    public static GetTimelineCollectorContextResponseProto getDefaultInstance() {
      return defaultInstance;
    }

    public GetTimelineCollectorContextResponseProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private GetTimelineCollectorContextResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              userId_ = input.readBytes();
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              flowName_ = input.readBytes();
              break;
            }
            case 26: {
              bitField0_ |= 0x00000004;
              flowVersion_ = input.readBytes();
              break;
            }
            case 32: {
              bitField0_ |= 0x00000008;
              flowRunId_ = input.readInt64();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_GetTimelineCollectorContextResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_GetTimelineCollectorContextResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextResponseProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextResponseProto.Builder.class);
    }

    public static com.google.protobuf.Parser<GetTimelineCollectorContextResponseProto> PARSER =
        new com.google.protobuf.AbstractParser<GetTimelineCollectorContextResponseProto>() {
      public GetTimelineCollectorContextResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new GetTimelineCollectorContextResponseProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<GetTimelineCollectorContextResponseProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional string user_id = 1;
    public static final int USER_ID_FIELD_NUMBER = 1;
    private java.lang.Object userId_;
    /**
     * <code>optional string user_id = 1;</code>
     */
    public boolean hasUserId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional string user_id = 1;</code>
     */
    public java.lang.String getUserId() {
      java.lang.Object ref = userId_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          userId_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string user_id = 1;</code>
     */
    public com.google.protobuf.ByteString
        getUserIdBytes() {
      java.lang.Object ref = userId_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        userId_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional string flow_name = 2;
    public static final int FLOW_NAME_FIELD_NUMBER = 2;
    private java.lang.Object flowName_;
    /**
     * <code>optional string flow_name = 2;</code>
     */
    public boolean hasFlowName() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional string flow_name = 2;</code>
     */
    public java.lang.String getFlowName() {
      java.lang.Object ref = flowName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          flowName_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string flow_name = 2;</code>
     */
    public com.google.protobuf.ByteString
        getFlowNameBytes() {
      java.lang.Object ref = flowName_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        flowName_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional string flow_version = 3;
    public static final int FLOW_VERSION_FIELD_NUMBER = 3;
    private java.lang.Object flowVersion_;
    /**
     * <code>optional string flow_version = 3;</code>
     */
    public boolean hasFlowVersion() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional string flow_version = 3;</code>
     */
    public java.lang.String getFlowVersion() {
      java.lang.Object ref = flowVersion_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          flowVersion_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string flow_version = 3;</code>
     */
    public com.google.protobuf.ByteString
        getFlowVersionBytes() {
      java.lang.Object ref = flowVersion_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        flowVersion_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional int64 flow_run_id = 4;
    public static final int FLOW_RUN_ID_FIELD_NUMBER = 4;
    private long flowRunId_;
    /**
     * <code>optional int64 flow_run_id = 4;</code>
     */
    public boolean hasFlowRunId() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional int64 flow_run_id = 4;</code>
     */
    public long getFlowRunId() {
      return flowRunId_;
    }

    private void initFields() {
      userId_ = "";
      flowName_ = "";
      flowVersion_ = "";
      flowRunId_ = 0L;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, getUserIdBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, getFlowNameBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBytes(3, getFlowVersionBytes());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeInt64(4, flowRunId_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, getUserIdBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, getFlowNameBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(3, getFlowVersionBytes());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(4, flowRunId_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextResponseProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextResponseProto other = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextResponseProto) obj;

      boolean result = true;
      result = result && (hasUserId() == other.hasUserId());
      if (hasUserId()) {
        result = result && getUserId()
            .equals(other.getUserId());
      }
      result = result && (hasFlowName() == other.hasFlowName());
      if (hasFlowName()) {
        result = result && getFlowName()
            .equals(other.getFlowName());
      }
      result = result && (hasFlowVersion() == other.hasFlowVersion());
      if (hasFlowVersion()) {
        result = result && getFlowVersion()
            .equals(other.getFlowVersion());
      }
      result = result && (hasFlowRunId() == other.hasFlowRunId());
      if (hasFlowRunId()) {
        result = result && (getFlowRunId()
            == other.getFlowRunId());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasUserId()) {
        hash = (37 * hash) + USER_ID_FIELD_NUMBER;
        hash = (53 * hash) + getUserId().hashCode();
      }
      if (hasFlowName()) {
        hash = (37 * hash) + FLOW_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getFlowName().hashCode();
      }
      if (hasFlowVersion()) {
        hash = (37 * hash) + FLOW_VERSION_FIELD_NUMBER;
        hash = (53 * hash) + getFlowVersion().hashCode();
      }
      if (hasFlowRunId()) {
        hash = (37 * hash) + FLOW_RUN_ID_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getFlowRunId());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextResponseProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.GetTimelineCollectorContextResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_GetTimelineCollectorContextResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_GetTimelineCollectorContextResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextResponseProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextResponseProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        userId_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        flowName_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        flowVersion_ = "";
        bitField0_ = (bitField0_ & ~0x00000004);
        flowRunId_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_GetTimelineCollectorContextResponseProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextResponseProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextResponseProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextResponseProto build() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextResponseProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextResponseProto result = new org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextResponseProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.userId_ = userId_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.flowName_ = flowName_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.flowVersion_ = flowVersion_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.flowRunId_ = flowRunId_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextResponseProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextResponseProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextResponseProto.getDefaultInstance()) return this;
        if (other.hasUserId()) {
          bitField0_ |= 0x00000001;
          userId_ = other.userId_;
          onChanged();
        }
        if (other.hasFlowName()) {
          bitField0_ |= 0x00000002;
          flowName_ = other.flowName_;
          onChanged();
        }
        if (other.hasFlowVersion()) {
          bitField0_ |= 0x00000004;
          flowVersion_ = other.flowVersion_;
          onChanged();
        }
        if (other.hasFlowRunId()) {
          setFlowRunId(other.getFlowRunId());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.GetTimelineCollectorContextResponseProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional string user_id = 1;
      private java.lang.Object userId_ = "";
      /**
       * <code>optional string user_id = 1;</code>
       */
      public boolean hasUserId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional string user_id = 1;</code>
       */
      public java.lang.String getUserId() {
        java.lang.Object ref = userId_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          userId_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string user_id = 1;</code>
       */
      public com.google.protobuf.ByteString
          getUserIdBytes() {
        java.lang.Object ref = userId_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          userId_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string user_id = 1;</code>
       */
      public Builder setUserId(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        userId_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string user_id = 1;</code>
       */
      public Builder clearUserId() {
        bitField0_ = (bitField0_ & ~0x00000001);
        userId_ = getDefaultInstance().getUserId();
        onChanged();
        return this;
      }
      /**
       * <code>optional string user_id = 1;</code>
       */
      public Builder setUserIdBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        userId_ = value;
        onChanged();
        return this;
      }

      // optional string flow_name = 2;
      private java.lang.Object flowName_ = "";
      /**
       * <code>optional string flow_name = 2;</code>
       */
      public boolean hasFlowName() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional string flow_name = 2;</code>
       */
      public java.lang.String getFlowName() {
        java.lang.Object ref = flowName_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          flowName_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string flow_name = 2;</code>
       */
      public com.google.protobuf.ByteString
          getFlowNameBytes() {
        java.lang.Object ref = flowName_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          flowName_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string flow_name = 2;</code>
       */
      public Builder setFlowName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        flowName_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string flow_name = 2;</code>
       */
      public Builder clearFlowName() {
        bitField0_ = (bitField0_ & ~0x00000002);
        flowName_ = getDefaultInstance().getFlowName();
        onChanged();
        return this;
      }
      /**
       * <code>optional string flow_name = 2;</code>
       */
      public Builder setFlowNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        flowName_ = value;
        onChanged();
        return this;
      }

      // optional string flow_version = 3;
      private java.lang.Object flowVersion_ = "";
      /**
       * <code>optional string flow_version = 3;</code>
       */
      public boolean hasFlowVersion() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional string flow_version = 3;</code>
       */
      public java.lang.String getFlowVersion() {
        java.lang.Object ref = flowVersion_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          flowVersion_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string flow_version = 3;</code>
       */
      public com.google.protobuf.ByteString
          getFlowVersionBytes() {
        java.lang.Object ref = flowVersion_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          flowVersion_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string flow_version = 3;</code>
       */
      public Builder setFlowVersion(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        flowVersion_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string flow_version = 3;</code>
       */
      public Builder clearFlowVersion() {
        bitField0_ = (bitField0_ & ~0x00000004);
        flowVersion_ = getDefaultInstance().getFlowVersion();
        onChanged();
        return this;
      }
      /**
       * <code>optional string flow_version = 3;</code>
       */
      public Builder setFlowVersionBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        flowVersion_ = value;
        onChanged();
        return this;
      }

      // optional int64 flow_run_id = 4;
      private long flowRunId_ ;
      /**
       * <code>optional int64 flow_run_id = 4;</code>
       */
      public boolean hasFlowRunId() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional int64 flow_run_id = 4;</code>
       */
      public long getFlowRunId() {
        return flowRunId_;
      }
      /**
       * <code>optional int64 flow_run_id = 4;</code>
       */
      public Builder setFlowRunId(long value) {
        bitField0_ |= 0x00000008;
        flowRunId_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 flow_run_id = 4;</code>
       */
      public Builder clearFlowRunId() {
        bitField0_ = (bitField0_ & ~0x00000008);
        flowRunId_ = 0L;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.GetTimelineCollectorContextResponseProto)
    }

    static {
      defaultInstance = new GetTimelineCollectorContextResponseProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.GetTimelineCollectorContextResponseProto)
  }

  public interface NMContainerStatusProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hadoop.yarn.ContainerIdProto container_id = 1;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    boolean hasContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder();

    // optional .hadoop.yarn.ContainerStateProto container_state = 2;
    /**
     * <code>optional .hadoop.yarn.ContainerStateProto container_state = 2;</code>
     */
    boolean hasContainerState();
    /**
     * <code>optional .hadoop.yarn.ContainerStateProto container_state = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto getContainerState();

    // optional .hadoop.yarn.ResourceProto resource = 3;
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 3;</code>
     */
    boolean hasResource();
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 3;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource();
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 3;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder();

    // optional .hadoop.yarn.PriorityProto priority = 4;
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
     */
    boolean hasPriority();
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority();
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder();

    // optional string diagnostics = 5 [default = "N/A"];
    /**
     * <code>optional string diagnostics = 5 [default = "N/A"];</code>
     */
    boolean hasDiagnostics();
    /**
     * <code>optional string diagnostics = 5 [default = "N/A"];</code>
     */
    java.lang.String getDiagnostics();
    /**
     * <code>optional string diagnostics = 5 [default = "N/A"];</code>
     */
    com.google.protobuf.ByteString
        getDiagnosticsBytes();

    // optional int32 container_exit_status = 6;
    /**
     * <code>optional int32 container_exit_status = 6;</code>
     */
    boolean hasContainerExitStatus();
    /**
     * <code>optional int32 container_exit_status = 6;</code>
     */
    int getContainerExitStatus();

    // optional int64 creation_time = 7;
    /**
     * <code>optional int64 creation_time = 7;</code>
     */
    boolean hasCreationTime();
    /**
     * <code>optional int64 creation_time = 7;</code>
     */
    long getCreationTime();

    // optional string nodeLabelExpression = 8;
    /**
     * <code>optional string nodeLabelExpression = 8;</code>
     */
    boolean hasNodeLabelExpression();
    /**
     * <code>optional string nodeLabelExpression = 8;</code>
     */
    java.lang.String getNodeLabelExpression();
    /**
     * <code>optional string nodeLabelExpression = 8;</code>
     */
    com.google.protobuf.ByteString
        getNodeLabelExpressionBytes();
  }
  /**
   * Protobuf type {@code hadoop.yarn.NMContainerStatusProto}
   */
  public static final class NMContainerStatusProto extends
      com.google.protobuf.GeneratedMessage
      implements NMContainerStatusProtoOrBuilder {
    // Use NMContainerStatusProto.newBuilder() to construct.
    private NMContainerStatusProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private NMContainerStatusProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final NMContainerStatusProto defaultInstance;
    public static NMContainerStatusProto getDefaultInstance() {
      return defaultInstance;
    }

    public NMContainerStatusProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private NMContainerStatusProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = containerId_.toBuilder();
              }
              containerId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(containerId_);
                containerId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 16: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto value = org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(2, rawValue);
              } else {
                bitField0_ |= 0x00000002;
                containerState_ = value;
              }
              break;
            }
            case 26: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = resource_.toBuilder();
              }
              resource_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(resource_);
                resource_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
            case 34: {
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000008) == 0x00000008)) {
                subBuilder = priority_.toBuilder();
              }
              priority_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(priority_);
                priority_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000008;
              break;
            }
            case 42: {
              bitField0_ |= 0x00000010;
              diagnostics_ = input.readBytes();
              break;
            }
            case 48: {
              bitField0_ |= 0x00000020;
              containerExitStatus_ = input.readInt32();
              break;
            }
            case 56: {
              bitField0_ |= 0x00000040;
              creationTime_ = input.readInt64();
              break;
            }
            case 66: {
              bitField0_ |= 0x00000080;
              nodeLabelExpression_ = input.readBytes();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_NMContainerStatusProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_NMContainerStatusProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto.Builder.class);
    }

    public static com.google.protobuf.Parser<NMContainerStatusProto> PARSER =
        new com.google.protobuf.AbstractParser<NMContainerStatusProto>() {
      public NMContainerStatusProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new NMContainerStatusProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<NMContainerStatusProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hadoop.yarn.ContainerIdProto container_id = 1;
    public static final int CONTAINER_ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public boolean hasContainerId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
      return containerId_;
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
      return containerId_;
    }

    // optional .hadoop.yarn.ContainerStateProto container_state = 2;
    public static final int CONTAINER_STATE_FIELD_NUMBER = 2;
    private org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto containerState_;
    /**
     * <code>optional .hadoop.yarn.ContainerStateProto container_state = 2;</code>
     */
    public boolean hasContainerState() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerStateProto container_state = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto getContainerState() {
      return containerState_;
    }

    // optional .hadoop.yarn.ResourceProto resource = 3;
    public static final int RESOURCE_FIELD_NUMBER = 3;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto resource_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 3;</code>
     */
    public boolean hasResource() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 3;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource() {
      return resource_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 3;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder() {
      return resource_;
    }

    // optional .hadoop.yarn.PriorityProto priority = 4;
    public static final int PRIORITY_FIELD_NUMBER = 4;
    private org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto priority_;
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
     */
    public boolean hasPriority() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority() {
      return priority_;
    }
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder() {
      return priority_;
    }

    // optional string diagnostics = 5 [default = "N/A"];
    public static final int DIAGNOSTICS_FIELD_NUMBER = 5;
    private java.lang.Object diagnostics_;
    /**
     * <code>optional string diagnostics = 5 [default = "N/A"];</code>
     */
    public boolean hasDiagnostics() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional string diagnostics = 5 [default = "N/A"];</code>
     */
    public java.lang.String getDiagnostics() {
      java.lang.Object ref = diagnostics_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          diagnostics_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string diagnostics = 5 [default = "N/A"];</code>
     */
    public com.google.protobuf.ByteString
        getDiagnosticsBytes() {
      java.lang.Object ref = diagnostics_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        diagnostics_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional int32 container_exit_status = 6;
    public static final int CONTAINER_EXIT_STATUS_FIELD_NUMBER = 6;
    private int containerExitStatus_;
    /**
     * <code>optional int32 container_exit_status = 6;</code>
     */
    public boolean hasContainerExitStatus() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional int32 container_exit_status = 6;</code>
     */
    public int getContainerExitStatus() {
      return containerExitStatus_;
    }

    // optional int64 creation_time = 7;
    public static final int CREATION_TIME_FIELD_NUMBER = 7;
    private long creationTime_;
    /**
     * <code>optional int64 creation_time = 7;</code>
     */
    public boolean hasCreationTime() {
      return ((bitField0_ & 0x00000040) == 0x00000040);
    }
    /**
     * <code>optional int64 creation_time = 7;</code>
     */
    public long getCreationTime() {
      return creationTime_;
    }

    // optional string nodeLabelExpression = 8;
    public static final int NODELABELEXPRESSION_FIELD_NUMBER = 8;
    private java.lang.Object nodeLabelExpression_;
    /**
     * <code>optional string nodeLabelExpression = 8;</code>
     */
    public boolean hasNodeLabelExpression() {
      return ((bitField0_ & 0x00000080) == 0x00000080);
    }
    /**
     * <code>optional string nodeLabelExpression = 8;</code>
     */
    public java.lang.String getNodeLabelExpression() {
      java.lang.Object ref = nodeLabelExpression_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          nodeLabelExpression_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string nodeLabelExpression = 8;</code>
     */
    public com.google.protobuf.ByteString
        getNodeLabelExpressionBytes() {
      java.lang.Object ref = nodeLabelExpression_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        nodeLabelExpression_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private void initFields() {
      containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
      containerState_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto.C_NEW;
      resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      priority_ = org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
      diagnostics_ = "N/A";
      containerExitStatus_ = 0;
      creationTime_ = 0L;
      nodeLabelExpression_ = "";
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, containerId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeEnum(2, containerState_.getNumber());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(3, resource_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeMessage(4, priority_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeBytes(5, getDiagnosticsBytes());
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeInt32(6, containerExitStatus_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        output.writeInt64(7, creationTime_);
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        output.writeBytes(8, getNodeLabelExpressionBytes());
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, containerId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(2, containerState_.getNumber());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, resource_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, priority_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(5, getDiagnosticsBytes());
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(6, containerExitStatus_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(7, creationTime_);
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(8, getNodeLabelExpressionBytes());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto other = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto) obj;

      boolean result = true;
      result = result && (hasContainerId() == other.hasContainerId());
      if (hasContainerId()) {
        result = result && getContainerId()
            .equals(other.getContainerId());
      }
      result = result && (hasContainerState() == other.hasContainerState());
      if (hasContainerState()) {
        result = result &&
            (getContainerState() == other.getContainerState());
      }
      result = result && (hasResource() == other.hasResource());
      if (hasResource()) {
        result = result && getResource()
            .equals(other.getResource());
      }
      result = result && (hasPriority() == other.hasPriority());
      if (hasPriority()) {
        result = result && getPriority()
            .equals(other.getPriority());
      }
      result = result && (hasDiagnostics() == other.hasDiagnostics());
      if (hasDiagnostics()) {
        result = result && getDiagnostics()
            .equals(other.getDiagnostics());
      }
      result = result && (hasContainerExitStatus() == other.hasContainerExitStatus());
      if (hasContainerExitStatus()) {
        result = result && (getContainerExitStatus()
            == other.getContainerExitStatus());
      }
      result = result && (hasCreationTime() == other.hasCreationTime());
      if (hasCreationTime()) {
        result = result && (getCreationTime()
            == other.getCreationTime());
      }
      result = result && (hasNodeLabelExpression() == other.hasNodeLabelExpression());
      if (hasNodeLabelExpression()) {
        result = result && getNodeLabelExpression()
            .equals(other.getNodeLabelExpression());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasContainerId()) {
        hash = (37 * hash) + CONTAINER_ID_FIELD_NUMBER;
        hash = (53 * hash) + getContainerId().hashCode();
      }
      if (hasContainerState()) {
        hash = (37 * hash) + CONTAINER_STATE_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getContainerState());
      }
      if (hasResource()) {
        hash = (37 * hash) + RESOURCE_FIELD_NUMBER;
        hash = (53 * hash) + getResource().hashCode();
      }
      if (hasPriority()) {
        hash = (37 * hash) + PRIORITY_FIELD_NUMBER;
        hash = (53 * hash) + getPriority().hashCode();
      }
      if (hasDiagnostics()) {
        hash = (37 * hash) + DIAGNOSTICS_FIELD_NUMBER;
        hash = (53 * hash) + getDiagnostics().hashCode();
      }
      if (hasContainerExitStatus()) {
        hash = (37 * hash) + CONTAINER_EXIT_STATUS_FIELD_NUMBER;
        hash = (53 * hash) + getContainerExitStatus();
      }
      if (hasCreationTime()) {
        hash = (37 * hash) + CREATION_TIME_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getCreationTime());
      }
      if (hasNodeLabelExpression()) {
        hash = (37 * hash) + NODELABELEXPRESSION_FIELD_NUMBER;
        hash = (53 * hash) + getNodeLabelExpression().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.NMContainerStatusProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_NMContainerStatusProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_NMContainerStatusProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getContainerIdFieldBuilder();
          getResourceFieldBuilder();
          getPriorityFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (containerIdBuilder_ == null) {
          containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        containerState_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto.C_NEW;
        bitField0_ = (bitField0_ & ~0x00000002);
        if (resourceBuilder_ == null) {
          resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        if (priorityBuilder_ == null) {
          priority_ = org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
        } else {
          priorityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        diagnostics_ = "N/A";
        bitField0_ = (bitField0_ & ~0x00000010);
        containerExitStatus_ = 0;
        bitField0_ = (bitField0_ & ~0x00000020);
        creationTime_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000040);
        nodeLabelExpression_ = "";
        bitField0_ = (bitField0_ & ~0x00000080);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_NMContainerStatusProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto build() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto result = new org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (containerIdBuilder_ == null) {
          result.containerId_ = containerId_;
        } else {
          result.containerId_ = containerIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.containerState_ = containerState_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (resourceBuilder_ == null) {
          result.resource_ = resource_;
        } else {
          result.resource_ = resourceBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        if (priorityBuilder_ == null) {
          result.priority_ = priority_;
        } else {
          result.priority_ = priorityBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.diagnostics_ = diagnostics_;
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000020;
        }
        result.containerExitStatus_ = containerExitStatus_;
        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
          to_bitField0_ |= 0x00000040;
        }
        result.creationTime_ = creationTime_;
        if (((from_bitField0_ & 0x00000080) == 0x00000080)) {
          to_bitField0_ |= 0x00000080;
        }
        result.nodeLabelExpression_ = nodeLabelExpression_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto.getDefaultInstance()) return this;
        if (other.hasContainerId()) {
          mergeContainerId(other.getContainerId());
        }
        if (other.hasContainerState()) {
          setContainerState(other.getContainerState());
        }
        if (other.hasResource()) {
          mergeResource(other.getResource());
        }
        if (other.hasPriority()) {
          mergePriority(other.getPriority());
        }
        if (other.hasDiagnostics()) {
          bitField0_ |= 0x00000010;
          diagnostics_ = other.diagnostics_;
          onChanged();
        }
        if (other.hasContainerExitStatus()) {
          setContainerExitStatus(other.getContainerExitStatus());
        }
        if (other.hasCreationTime()) {
          setCreationTime(other.getCreationTime());
        }
        if (other.hasNodeLabelExpression()) {
          bitField0_ |= 0x00000080;
          nodeLabelExpression_ = other.nodeLabelExpression_;
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.NMContainerStatusProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hadoop.yarn.ContainerIdProto container_id = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> containerIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public boolean hasContainerId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
        if (containerIdBuilder_ == null) {
          return containerId_;
        } else {
          return containerIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          containerId_ = value;
          onChanged();
        } else {
          containerIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (containerIdBuilder_ == null) {
          containerId_ = builderForValue.build();
          onChanged();
        } else {
          containerIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder mergeContainerId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              containerId_ != org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance()) {
            containerId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.newBuilder(containerId_).mergeFrom(value).buildPartial();
          } else {
            containerId_ = value;
          }
          onChanged();
        } else {
          containerIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder clearContainerId() {
        if (containerIdBuilder_ == null) {
          containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
          onChanged();
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder getContainerIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getContainerIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
        if (containerIdBuilder_ != null) {
          return containerIdBuilder_.getMessageOrBuilder();
        } else {
          return containerId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
          getContainerIdFieldBuilder() {
        if (containerIdBuilder_ == null) {
          containerIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder>(
                  containerId_,
                  getParentForChildren(),
                  isClean());
          containerId_ = null;
        }
        return containerIdBuilder_;
      }

      // optional .hadoop.yarn.ContainerStateProto container_state = 2;
      private org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto containerState_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto.C_NEW;
      /**
       * <code>optional .hadoop.yarn.ContainerStateProto container_state = 2;</code>
       */
      public boolean hasContainerState() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerStateProto container_state = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto getContainerState() {
        return containerState_;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerStateProto container_state = 2;</code>
       */
      public Builder setContainerState(org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000002;
        containerState_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerStateProto container_state = 2;</code>
       */
      public Builder clearContainerState() {
        bitField0_ = (bitField0_ & ~0x00000002);
        containerState_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto.C_NEW;
        onChanged();
        return this;
      }

      // optional .hadoop.yarn.ResourceProto resource = 3;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> resourceBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 3;</code>
       */
      public boolean hasResource() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource() {
        if (resourceBuilder_ == null) {
          return resource_;
        } else {
          return resourceBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 3;</code>
       */
      public Builder setResource(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (resourceBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          resource_ = value;
          onChanged();
        } else {
          resourceBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 3;</code>
       */
      public Builder setResource(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (resourceBuilder_ == null) {
          resource_ = builderForValue.build();
          onChanged();
        } else {
          resourceBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 3;</code>
       */
      public Builder mergeResource(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (resourceBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              resource_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            resource_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(resource_).mergeFrom(value).buildPartial();
          } else {
            resource_ = value;
          }
          onChanged();
        } else {
          resourceBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 3;</code>
       */
      public Builder clearResource() {
        if (resourceBuilder_ == null) {
          resource_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
          onChanged();
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getResourceBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getResourceFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder() {
        if (resourceBuilder_ != null) {
          return resourceBuilder_.getMessageOrBuilder();
        } else {
          return resource_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getResourceFieldBuilder() {
        if (resourceBuilder_ == null) {
          resourceBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  resource_,
                  getParentForChildren(),
                  isClean());
          resource_ = null;
        }
        return resourceBuilder_;
      }

      // optional .hadoop.yarn.PriorityProto priority = 4;
      private org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto priority_ = org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder> priorityBuilder_;
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public boolean hasPriority() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority() {
        if (priorityBuilder_ == null) {
          return priority_;
        } else {
          return priorityBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public Builder setPriority(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto value) {
        if (priorityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          priority_ = value;
          onChanged();
        } else {
          priorityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public Builder setPriority(
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder builderForValue) {
        if (priorityBuilder_ == null) {
          priority_ = builderForValue.build();
          onChanged();
        } else {
          priorityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public Builder mergePriority(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto value) {
        if (priorityBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008) &&
              priority_ != org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance()) {
            priority_ =
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.newBuilder(priority_).mergeFrom(value).buildPartial();
          } else {
            priority_ = value;
          }
          onChanged();
        } else {
          priorityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public Builder clearPriority() {
        if (priorityBuilder_ == null) {
          priority_ = org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
          onChanged();
        } else {
          priorityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder getPriorityBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getPriorityFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder() {
        if (priorityBuilder_ != null) {
          return priorityBuilder_.getMessageOrBuilder();
        } else {
          return priority_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder> 
          getPriorityFieldBuilder() {
        if (priorityBuilder_ == null) {
          priorityBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder>(
                  priority_,
                  getParentForChildren(),
                  isClean());
          priority_ = null;
        }
        return priorityBuilder_;
      }

      // optional string diagnostics = 5 [default = "N/A"];
      private java.lang.Object diagnostics_ = "N/A";
      /**
       * <code>optional string diagnostics = 5 [default = "N/A"];</code>
       */
      public boolean hasDiagnostics() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional string diagnostics = 5 [default = "N/A"];</code>
       */
      public java.lang.String getDiagnostics() {
        java.lang.Object ref = diagnostics_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          diagnostics_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string diagnostics = 5 [default = "N/A"];</code>
       */
      public com.google.protobuf.ByteString
          getDiagnosticsBytes() {
        java.lang.Object ref = diagnostics_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          diagnostics_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string diagnostics = 5 [default = "N/A"];</code>
       */
      public Builder setDiagnostics(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000010;
        diagnostics_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string diagnostics = 5 [default = "N/A"];</code>
       */
      public Builder clearDiagnostics() {
        bitField0_ = (bitField0_ & ~0x00000010);
        diagnostics_ = getDefaultInstance().getDiagnostics();
        onChanged();
        return this;
      }
      /**
       * <code>optional string diagnostics = 5 [default = "N/A"];</code>
       */
      public Builder setDiagnosticsBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000010;
        diagnostics_ = value;
        onChanged();
        return this;
      }

      // optional int32 container_exit_status = 6;
      private int containerExitStatus_ ;
      /**
       * <code>optional int32 container_exit_status = 6;</code>
       */
      public boolean hasContainerExitStatus() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional int32 container_exit_status = 6;</code>
       */
      public int getContainerExitStatus() {
        return containerExitStatus_;
      }
      /**
       * <code>optional int32 container_exit_status = 6;</code>
       */
      public Builder setContainerExitStatus(int value) {
        bitField0_ |= 0x00000020;
        containerExitStatus_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 container_exit_status = 6;</code>
       */
      public Builder clearContainerExitStatus() {
        bitField0_ = (bitField0_ & ~0x00000020);
        containerExitStatus_ = 0;
        onChanged();
        return this;
      }

      // optional int64 creation_time = 7;
      private long creationTime_ ;
      /**
       * <code>optional int64 creation_time = 7;</code>
       */
      public boolean hasCreationTime() {
        return ((bitField0_ & 0x00000040) == 0x00000040);
      }
      /**
       * <code>optional int64 creation_time = 7;</code>
       */
      public long getCreationTime() {
        return creationTime_;
      }
      /**
       * <code>optional int64 creation_time = 7;</code>
       */
      public Builder setCreationTime(long value) {
        bitField0_ |= 0x00000040;
        creationTime_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 creation_time = 7;</code>
       */
      public Builder clearCreationTime() {
        bitField0_ = (bitField0_ & ~0x00000040);
        creationTime_ = 0L;
        onChanged();
        return this;
      }

      // optional string nodeLabelExpression = 8;
      private java.lang.Object nodeLabelExpression_ = "";
      /**
       * <code>optional string nodeLabelExpression = 8;</code>
       */
      public boolean hasNodeLabelExpression() {
        return ((bitField0_ & 0x00000080) == 0x00000080);
      }
      /**
       * <code>optional string nodeLabelExpression = 8;</code>
       */
      public java.lang.String getNodeLabelExpression() {
        java.lang.Object ref = nodeLabelExpression_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          nodeLabelExpression_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string nodeLabelExpression = 8;</code>
       */
      public com.google.protobuf.ByteString
          getNodeLabelExpressionBytes() {
        java.lang.Object ref = nodeLabelExpression_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          nodeLabelExpression_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string nodeLabelExpression = 8;</code>
       */
      public Builder setNodeLabelExpression(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000080;
        nodeLabelExpression_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string nodeLabelExpression = 8;</code>
       */
      public Builder clearNodeLabelExpression() {
        bitField0_ = (bitField0_ & ~0x00000080);
        nodeLabelExpression_ = getDefaultInstance().getNodeLabelExpression();
        onChanged();
        return this;
      }
      /**
       * <code>optional string nodeLabelExpression = 8;</code>
       */
      public Builder setNodeLabelExpressionBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000080;
        nodeLabelExpression_ = value;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.NMContainerStatusProto)
    }

    static {
      defaultInstance = new NMContainerStatusProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.NMContainerStatusProto)
  }

  public interface SCMUploaderNotifyRequestProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional string resource_key = 1;
    /**
     * <code>optional string resource_key = 1;</code>
     */
    boolean hasResourceKey();
    /**
     * <code>optional string resource_key = 1;</code>
     */
    java.lang.String getResourceKey();
    /**
     * <code>optional string resource_key = 1;</code>
     */
    com.google.protobuf.ByteString
        getResourceKeyBytes();

    // optional string filename = 2;
    /**
     * <code>optional string filename = 2;</code>
     */
    boolean hasFilename();
    /**
     * <code>optional string filename = 2;</code>
     */
    java.lang.String getFilename();
    /**
     * <code>optional string filename = 2;</code>
     */
    com.google.protobuf.ByteString
        getFilenameBytes();
  }
  /**
   * Protobuf type {@code hadoop.yarn.SCMUploaderNotifyRequestProto}
   */
  public static final class SCMUploaderNotifyRequestProto extends
      com.google.protobuf.GeneratedMessage
      implements SCMUploaderNotifyRequestProtoOrBuilder {
    // Use SCMUploaderNotifyRequestProto.newBuilder() to construct.
    private SCMUploaderNotifyRequestProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private SCMUploaderNotifyRequestProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final SCMUploaderNotifyRequestProto defaultInstance;
    public static SCMUploaderNotifyRequestProto getDefaultInstance() {
      return defaultInstance;
    }

    public SCMUploaderNotifyRequestProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private SCMUploaderNotifyRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              resourceKey_ = input.readBytes();
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              filename_ = input.readBytes();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_SCMUploaderNotifyRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_SCMUploaderNotifyRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyRequestProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyRequestProto.Builder.class);
    }

    public static com.google.protobuf.Parser<SCMUploaderNotifyRequestProto> PARSER =
        new com.google.protobuf.AbstractParser<SCMUploaderNotifyRequestProto>() {
      public SCMUploaderNotifyRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new SCMUploaderNotifyRequestProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<SCMUploaderNotifyRequestProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional string resource_key = 1;
    public static final int RESOURCE_KEY_FIELD_NUMBER = 1;
    private java.lang.Object resourceKey_;
    /**
     * <code>optional string resource_key = 1;</code>
     */
    public boolean hasResourceKey() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional string resource_key = 1;</code>
     */
    public java.lang.String getResourceKey() {
      java.lang.Object ref = resourceKey_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          resourceKey_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string resource_key = 1;</code>
     */
    public com.google.protobuf.ByteString
        getResourceKeyBytes() {
      java.lang.Object ref = resourceKey_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        resourceKey_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional string filename = 2;
    public static final int FILENAME_FIELD_NUMBER = 2;
    private java.lang.Object filename_;
    /**
     * <code>optional string filename = 2;</code>
     */
    public boolean hasFilename() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional string filename = 2;</code>
     */
    public java.lang.String getFilename() {
      java.lang.Object ref = filename_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          filename_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string filename = 2;</code>
     */
    public com.google.protobuf.ByteString
        getFilenameBytes() {
      java.lang.Object ref = filename_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        filename_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private void initFields() {
      resourceKey_ = "";
      filename_ = "";
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, getResourceKeyBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, getFilenameBytes());
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, getResourceKeyBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, getFilenameBytes());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyRequestProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyRequestProto other = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyRequestProto) obj;

      boolean result = true;
      result = result && (hasResourceKey() == other.hasResourceKey());
      if (hasResourceKey()) {
        result = result && getResourceKey()
            .equals(other.getResourceKey());
      }
      result = result && (hasFilename() == other.hasFilename());
      if (hasFilename()) {
        result = result && getFilename()
            .equals(other.getFilename());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasResourceKey()) {
        hash = (37 * hash) + RESOURCE_KEY_FIELD_NUMBER;
        hash = (53 * hash) + getResourceKey().hashCode();
      }
      if (hasFilename()) {
        hash = (37 * hash) + FILENAME_FIELD_NUMBER;
        hash = (53 * hash) + getFilename().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyRequestProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.SCMUploaderNotifyRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_SCMUploaderNotifyRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_SCMUploaderNotifyRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyRequestProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyRequestProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        resourceKey_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        filename_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_SCMUploaderNotifyRequestProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyRequestProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyRequestProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyRequestProto build() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyRequestProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyRequestProto result = new org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.resourceKey_ = resourceKey_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.filename_ = filename_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyRequestProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyRequestProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyRequestProto.getDefaultInstance()) return this;
        if (other.hasResourceKey()) {
          bitField0_ |= 0x00000001;
          resourceKey_ = other.resourceKey_;
          onChanged();
        }
        if (other.hasFilename()) {
          bitField0_ |= 0x00000002;
          filename_ = other.filename_;
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyRequestProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional string resource_key = 1;
      private java.lang.Object resourceKey_ = "";
      /**
       * <code>optional string resource_key = 1;</code>
       */
      public boolean hasResourceKey() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional string resource_key = 1;</code>
       */
      public java.lang.String getResourceKey() {
        java.lang.Object ref = resourceKey_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          resourceKey_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string resource_key = 1;</code>
       */
      public com.google.protobuf.ByteString
          getResourceKeyBytes() {
        java.lang.Object ref = resourceKey_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          resourceKey_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string resource_key = 1;</code>
       */
      public Builder setResourceKey(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        resourceKey_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string resource_key = 1;</code>
       */
      public Builder clearResourceKey() {
        bitField0_ = (bitField0_ & ~0x00000001);
        resourceKey_ = getDefaultInstance().getResourceKey();
        onChanged();
        return this;
      }
      /**
       * <code>optional string resource_key = 1;</code>
       */
      public Builder setResourceKeyBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        resourceKey_ = value;
        onChanged();
        return this;
      }

      // optional string filename = 2;
      private java.lang.Object filename_ = "";
      /**
       * <code>optional string filename = 2;</code>
       */
      public boolean hasFilename() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional string filename = 2;</code>
       */
      public java.lang.String getFilename() {
        java.lang.Object ref = filename_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          filename_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string filename = 2;</code>
       */
      public com.google.protobuf.ByteString
          getFilenameBytes() {
        java.lang.Object ref = filename_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          filename_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string filename = 2;</code>
       */
      public Builder setFilename(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        filename_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string filename = 2;</code>
       */
      public Builder clearFilename() {
        bitField0_ = (bitField0_ & ~0x00000002);
        filename_ = getDefaultInstance().getFilename();
        onChanged();
        return this;
      }
      /**
       * <code>optional string filename = 2;</code>
       */
      public Builder setFilenameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        filename_ = value;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.SCMUploaderNotifyRequestProto)
    }

    static {
      defaultInstance = new SCMUploaderNotifyRequestProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.SCMUploaderNotifyRequestProto)
  }

  public interface SCMUploaderNotifyResponseProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional bool accepted = 1;
    /**
     * <code>optional bool accepted = 1;</code>
     */
    boolean hasAccepted();
    /**
     * <code>optional bool accepted = 1;</code>
     */
    boolean getAccepted();
  }
  /**
   * Protobuf type {@code hadoop.yarn.SCMUploaderNotifyResponseProto}
   */
  public static final class SCMUploaderNotifyResponseProto extends
      com.google.protobuf.GeneratedMessage
      implements SCMUploaderNotifyResponseProtoOrBuilder {
    // Use SCMUploaderNotifyResponseProto.newBuilder() to construct.
    private SCMUploaderNotifyResponseProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private SCMUploaderNotifyResponseProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final SCMUploaderNotifyResponseProto defaultInstance;
    public static SCMUploaderNotifyResponseProto getDefaultInstance() {
      return defaultInstance;
    }

    public SCMUploaderNotifyResponseProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private SCMUploaderNotifyResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              accepted_ = input.readBool();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_SCMUploaderNotifyResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_SCMUploaderNotifyResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyResponseProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyResponseProto.Builder.class);
    }

    public static com.google.protobuf.Parser<SCMUploaderNotifyResponseProto> PARSER =
        new com.google.protobuf.AbstractParser<SCMUploaderNotifyResponseProto>() {
      public SCMUploaderNotifyResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new SCMUploaderNotifyResponseProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<SCMUploaderNotifyResponseProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional bool accepted = 1;
    public static final int ACCEPTED_FIELD_NUMBER = 1;
    private boolean accepted_;
    /**
     * <code>optional bool accepted = 1;</code>
     */
    public boolean hasAccepted() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional bool accepted = 1;</code>
     */
    public boolean getAccepted() {
      return accepted_;
    }

    private void initFields() {
      accepted_ = false;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBool(1, accepted_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(1, accepted_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyResponseProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyResponseProto other = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyResponseProto) obj;

      boolean result = true;
      result = result && (hasAccepted() == other.hasAccepted());
      if (hasAccepted()) {
        result = result && (getAccepted()
            == other.getAccepted());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasAccepted()) {
        hash = (37 * hash) + ACCEPTED_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getAccepted());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyResponseProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.SCMUploaderNotifyResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_SCMUploaderNotifyResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_SCMUploaderNotifyResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyResponseProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyResponseProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        accepted_ = false;
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_SCMUploaderNotifyResponseProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyResponseProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyResponseProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyResponseProto build() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyResponseProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyResponseProto result = new org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyResponseProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.accepted_ = accepted_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyResponseProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyResponseProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyResponseProto.getDefaultInstance()) return this;
        if (other.hasAccepted()) {
          setAccepted(other.getAccepted());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderNotifyResponseProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional bool accepted = 1;
      private boolean accepted_ ;
      /**
       * <code>optional bool accepted = 1;</code>
       */
      public boolean hasAccepted() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional bool accepted = 1;</code>
       */
      public boolean getAccepted() {
        return accepted_;
      }
      /**
       * <code>optional bool accepted = 1;</code>
       */
      public Builder setAccepted(boolean value) {
        bitField0_ |= 0x00000001;
        accepted_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool accepted = 1;</code>
       */
      public Builder clearAccepted() {
        bitField0_ = (bitField0_ & ~0x00000001);
        accepted_ = false;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.SCMUploaderNotifyResponseProto)
    }

    static {
      defaultInstance = new SCMUploaderNotifyResponseProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.SCMUploaderNotifyResponseProto)
  }

  public interface SCMUploaderCanUploadRequestProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional string resource_key = 1;
    /**
     * <code>optional string resource_key = 1;</code>
     */
    boolean hasResourceKey();
    /**
     * <code>optional string resource_key = 1;</code>
     */
    java.lang.String getResourceKey();
    /**
     * <code>optional string resource_key = 1;</code>
     */
    com.google.protobuf.ByteString
        getResourceKeyBytes();
  }
  /**
   * Protobuf type {@code hadoop.yarn.SCMUploaderCanUploadRequestProto}
   */
  public static final class SCMUploaderCanUploadRequestProto extends
      com.google.protobuf.GeneratedMessage
      implements SCMUploaderCanUploadRequestProtoOrBuilder {
    // Use SCMUploaderCanUploadRequestProto.newBuilder() to construct.
    private SCMUploaderCanUploadRequestProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private SCMUploaderCanUploadRequestProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final SCMUploaderCanUploadRequestProto defaultInstance;
    public static SCMUploaderCanUploadRequestProto getDefaultInstance() {
      return defaultInstance;
    }

    public SCMUploaderCanUploadRequestProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private SCMUploaderCanUploadRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              resourceKey_ = input.readBytes();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_SCMUploaderCanUploadRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_SCMUploaderCanUploadRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadRequestProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadRequestProto.Builder.class);
    }

    public static com.google.protobuf.Parser<SCMUploaderCanUploadRequestProto> PARSER =
        new com.google.protobuf.AbstractParser<SCMUploaderCanUploadRequestProto>() {
      public SCMUploaderCanUploadRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new SCMUploaderCanUploadRequestProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<SCMUploaderCanUploadRequestProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional string resource_key = 1;
    public static final int RESOURCE_KEY_FIELD_NUMBER = 1;
    private java.lang.Object resourceKey_;
    /**
     * <code>optional string resource_key = 1;</code>
     */
    public boolean hasResourceKey() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional string resource_key = 1;</code>
     */
    public java.lang.String getResourceKey() {
      java.lang.Object ref = resourceKey_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          resourceKey_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string resource_key = 1;</code>
     */
    public com.google.protobuf.ByteString
        getResourceKeyBytes() {
      java.lang.Object ref = resourceKey_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        resourceKey_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private void initFields() {
      resourceKey_ = "";
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, getResourceKeyBytes());
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, getResourceKeyBytes());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadRequestProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadRequestProto other = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadRequestProto) obj;

      boolean result = true;
      result = result && (hasResourceKey() == other.hasResourceKey());
      if (hasResourceKey()) {
        result = result && getResourceKey()
            .equals(other.getResourceKey());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasResourceKey()) {
        hash = (37 * hash) + RESOURCE_KEY_FIELD_NUMBER;
        hash = (53 * hash) + getResourceKey().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadRequestProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.SCMUploaderCanUploadRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_SCMUploaderCanUploadRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_SCMUploaderCanUploadRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadRequestProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadRequestProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        resourceKey_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_SCMUploaderCanUploadRequestProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadRequestProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadRequestProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadRequestProto build() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadRequestProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadRequestProto result = new org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.resourceKey_ = resourceKey_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadRequestProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadRequestProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadRequestProto.getDefaultInstance()) return this;
        if (other.hasResourceKey()) {
          bitField0_ |= 0x00000001;
          resourceKey_ = other.resourceKey_;
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadRequestProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional string resource_key = 1;
      private java.lang.Object resourceKey_ = "";
      /**
       * <code>optional string resource_key = 1;</code>
       */
      public boolean hasResourceKey() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional string resource_key = 1;</code>
       */
      public java.lang.String getResourceKey() {
        java.lang.Object ref = resourceKey_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          resourceKey_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string resource_key = 1;</code>
       */
      public com.google.protobuf.ByteString
          getResourceKeyBytes() {
        java.lang.Object ref = resourceKey_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          resourceKey_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string resource_key = 1;</code>
       */
      public Builder setResourceKey(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        resourceKey_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string resource_key = 1;</code>
       */
      public Builder clearResourceKey() {
        bitField0_ = (bitField0_ & ~0x00000001);
        resourceKey_ = getDefaultInstance().getResourceKey();
        onChanged();
        return this;
      }
      /**
       * <code>optional string resource_key = 1;</code>
       */
      public Builder setResourceKeyBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        resourceKey_ = value;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.SCMUploaderCanUploadRequestProto)
    }

    static {
      defaultInstance = new SCMUploaderCanUploadRequestProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.SCMUploaderCanUploadRequestProto)
  }

  public interface SCMUploaderCanUploadResponseProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional bool uploadable = 1;
    /**
     * <code>optional bool uploadable = 1;</code>
     */
    boolean hasUploadable();
    /**
     * <code>optional bool uploadable = 1;</code>
     */
    boolean getUploadable();
  }
  /**
   * Protobuf type {@code hadoop.yarn.SCMUploaderCanUploadResponseProto}
   */
  public static final class SCMUploaderCanUploadResponseProto extends
      com.google.protobuf.GeneratedMessage
      implements SCMUploaderCanUploadResponseProtoOrBuilder {
    // Use SCMUploaderCanUploadResponseProto.newBuilder() to construct.
    private SCMUploaderCanUploadResponseProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private SCMUploaderCanUploadResponseProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final SCMUploaderCanUploadResponseProto defaultInstance;
    public static SCMUploaderCanUploadResponseProto getDefaultInstance() {
      return defaultInstance;
    }

    public SCMUploaderCanUploadResponseProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private SCMUploaderCanUploadResponseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              uploadable_ = input.readBool();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_SCMUploaderCanUploadResponseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_SCMUploaderCanUploadResponseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadResponseProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadResponseProto.Builder.class);
    }

    public static com.google.protobuf.Parser<SCMUploaderCanUploadResponseProto> PARSER =
        new com.google.protobuf.AbstractParser<SCMUploaderCanUploadResponseProto>() {
      public SCMUploaderCanUploadResponseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new SCMUploaderCanUploadResponseProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<SCMUploaderCanUploadResponseProto> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional bool uploadable = 1;
    public static final int UPLOADABLE_FIELD_NUMBER = 1;
    private boolean uploadable_;
    /**
     * <code>optional bool uploadable = 1;</code>
     */
    public boolean hasUploadable() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional bool uploadable = 1;</code>
     */
    public boolean getUploadable() {
      return uploadable_;
    }

    private void initFields() {
      uploadable_ = false;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBool(1, uploadable_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(1, uploadable_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadResponseProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadResponseProto other = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadResponseProto) obj;

      boolean result = true;
      result = result && (hasUploadable() == other.hasUploadable());
      if (hasUploadable()) {
        result = result && (getUploadable()
            == other.getUploadable());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasUploadable()) {
        hash = (37 * hash) + UPLOADABLE_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getUploadable());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadResponseProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.SCMUploaderCanUploadResponseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_SCMUploaderCanUploadResponseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_SCMUploaderCanUploadResponseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadResponseProto.class, org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadResponseProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        uploadable_ = false;
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.internal_static_hadoop_yarn_SCMUploaderCanUploadResponseProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadResponseProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadResponseProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadResponseProto build() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadResponseProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadResponseProto result = new org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadResponseProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.uploadable_ = uploadable_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadResponseProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadResponseProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadResponseProto.getDefaultInstance()) return this;
        if (other.hasUploadable()) {
          setUploadable(other.getUploadable());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadResponseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnServerCommonServiceProtos.SCMUploaderCanUploadResponseProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional bool uploadable = 1;
      private boolean uploadable_ ;
      /**
       * <code>optional bool uploadable = 1;</code>
       */
      public boolean hasUploadable() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional bool uploadable = 1;</code>
       */
      public boolean getUploadable() {
        return uploadable_;
      }
      /**
       * <code>optional bool uploadable = 1;</code>
       */
      public Builder setUploadable(boolean value) {
        bitField0_ |= 0x00000001;
        uploadable_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool uploadable = 1;</code>
       */
      public Builder clearUploadable() {
        bitField0_ = (bitField0_ & ~0x00000001);
        uploadable_ = false;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hadoop.yarn.SCMUploaderCanUploadResponseProto)
    }

    static {
      defaultInstance = new SCMUploaderCanUploadResponseProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.SCMUploaderCanUploadResponseProto)
  }

  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_DistSchedRegisterResponseProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_DistSchedRegisterResponseProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_DistSchedAllocateResponseProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_DistSchedAllocateResponseProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_DistSchedAllocateRequestProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_DistSchedAllocateRequestProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_NodeLabelsProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_NodeLabelsProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_RegisterNodeManagerRequestProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_RegisterNodeManagerRequestProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_RegisterNodeManagerResponseProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_RegisterNodeManagerResponseProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_UnRegisterNodeManagerRequestProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_UnRegisterNodeManagerRequestProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_UnRegisterNodeManagerResponseProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_UnRegisterNodeManagerResponseProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_NodeHeartbeatRequestProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_NodeHeartbeatRequestProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_LogAggregationReportProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_LogAggregationReportProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_NodeHeartbeatResponseProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_NodeHeartbeatResponseProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ContainerQueuingLimitProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ContainerQueuingLimitProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_SystemCredentialsForAppsProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_SystemCredentialsForAppsProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_AppCollectorsMapProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_AppCollectorsMapProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ReportNewCollectorInfoRequestProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ReportNewCollectorInfoRequestProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ReportNewCollectorInfoResponseProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_ReportNewCollectorInfoResponseProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_GetTimelineCollectorContextRequestProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_GetTimelineCollectorContextRequestProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_GetTimelineCollectorContextResponseProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_GetTimelineCollectorContextResponseProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_NMContainerStatusProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_NMContainerStatusProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_SCMUploaderNotifyRequestProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_SCMUploaderNotifyRequestProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_SCMUploaderNotifyResponseProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_SCMUploaderNotifyResponseProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_SCMUploaderCanUploadRequestProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_SCMUploaderCanUploadRequestProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_SCMUploaderCanUploadResponseProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hadoop_yarn_SCMUploaderCanUploadResponseProto_fieldAccessorTable;

  public static com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\'yarn_server_common_service_protos.prot" +
      "o\022\013hadoop.yarn\032\021yarn_protos.proto\032\037yarn_" +
      "server_common_protos.proto\032\031yarn_service" +
      "_protos.proto\"\234\003\n\036DistSchedRegisterRespo" +
      "nseProto\022N\n\021register_response\030\001 \001(\01323.ha" +
      "doop.yarn.RegisterApplicationMasterRespo" +
      "nseProto\0228\n\024max_alloc_capability\030\002 \001(\0132\032" +
      ".hadoop.yarn.ResourceProto\0228\n\024min_alloc_" +
      "capability\030\003 \001(\0132\032.hadoop.yarn.ResourceP" +
      "roto\0229\n\025incr_alloc_capability\030\004 \001(\0132\032.ha",
      "doop.yarn.ResourceProto\022\'\n\037container_tok" +
      "en_expiry_interval\030\005 \001(\005\022\032\n\022container_id" +
      "_start\030\006 \001(\003\0226\n\024nodes_for_scheduling\030\007 \003" +
      "(\0132\030.hadoop.yarn.NodeIdProto\"\227\001\n\036DistSch" +
      "edAllocateResponseProto\022=\n\021allocate_resp" +
      "onse\030\001 \001(\0132\".hadoop.yarn.AllocateRespons" +
      "eProto\0226\n\024nodes_for_scheduling\030\002 \003(\0132\030.h" +
      "adoop.yarn.NodeIdProto\"\227\001\n\035DistSchedAllo" +
      "cateRequestProto\022;\n\020allocate_request\030\001 \001" +
      "(\0132!.hadoop.yarn.AllocateRequestProto\0229\n",
      "\024allocated_containers\030\002 \003(\0132\033.hadoop.yar" +
      "n.ContainerProto\"B\n\017NodeLabelsProto\022/\n\nn" +
      "odeLabels\030\001 \003(\0132\033.hadoop.yarn.NodeLabelP" +
      "roto\"\322\002\n\037RegisterNodeManagerRequestProto" +
      "\022)\n\007node_id\030\001 \001(\0132\030.hadoop.yarn.NodeIdPr" +
      "oto\022\021\n\thttp_port\030\003 \001(\005\022,\n\010resource\030\004 \001(\013" +
      "2\032.hadoop.yarn.ResourceProto\022\022\n\nnm_versi" +
      "on\030\005 \001(\t\022?\n\022container_statuses\030\006 \003(\0132#.h" +
      "adoop.yarn.NMContainerStatusProto\022<\n\023run" +
      "ningApplications\030\007 \003(\0132\037.hadoop.yarn.App",
      "licationIdProto\0220\n\nnodeLabels\030\010 \001(\0132\034.ha" +
      "doop.yarn.NodeLabelsProto\"\357\002\n RegisterNo" +
      "deManagerResponseProto\022?\n\032container_toke" +
      "n_master_key\030\001 \001(\0132\033.hadoop.yarn.MasterK" +
      "eyProto\0228\n\023nm_token_master_key\030\002 \001(\0132\033.h" +
      "adoop.yarn.MasterKeyProto\0220\n\nnodeAction\030" +
      "\003 \001(\0162\034.hadoop.yarn.NodeActionProto\022\025\n\rr" +
      "m_identifier\030\004 \001(\003\022\033\n\023diagnostics_messag" +
      "e\030\005 \001(\t\022\022\n\nrm_version\030\006 \001(\t\022(\n\031areNodeLa" +
      "belsAcceptedByRM\030\007 \001(\010:\005false\022,\n\010resourc",
      "e\030\010 \001(\0132\032.hadoop.yarn.ResourceProto\"N\n!U" +
      "nRegisterNodeManagerRequestProto\022)\n\007node" +
      "_id\030\001 \001(\0132\030.hadoop.yarn.NodeIdProto\"$\n\"U" +
      "nRegisterNodeManagerResponseProto\"\246\003\n\031No" +
      "deHeartbeatRequestProto\0221\n\013node_status\030\001" +
      " \001(\0132\034.hadoop.yarn.NodeStatusProto\022J\n%la" +
      "st_known_container_token_master_key\030\002 \001(" +
      "\0132\033.hadoop.yarn.MasterKeyProto\022C\n\036last_k" +
      "nown_nm_token_master_key\030\003 \001(\0132\033.hadoop." +
      "yarn.MasterKeyProto\0220\n\nnodeLabels\030\004 \001(\0132",
      "\034.hadoop.yarn.NodeLabelsProto\022P\n log_agg" +
      "regation_reports_for_apps\030\005 \003(\0132&.hadoop" +
      ".yarn.LogAggregationReportProto\022A\n\025regis" +
      "tered_collectors\030\006 \003(\0132\".hadoop.yarn.App" +
      "CollectorsMapProto\"\266\001\n\031LogAggregationRep" +
      "ortProto\0227\n\016application_id\030\001 \001(\0132\037.hadoo" +
      "p.yarn.ApplicationIdProto\022F\n\026log_aggrega" +
      "tion_status\030\002 \001(\0162&.hadoop.yarn.LogAggre" +
      "gationStatusProto\022\030\n\013diagnostics\030\003 \001(\t:\003" +
      "N/A\"\233\007\n\032NodeHeartbeatResponseProto\022\023\n\013re",
      "sponse_id\030\001 \001(\005\022?\n\032container_token_maste" +
      "r_key\030\002 \001(\0132\033.hadoop.yarn.MasterKeyProto" +
      "\0228\n\023nm_token_master_key\030\003 \001(\0132\033.hadoop.y" +
      "arn.MasterKeyProto\0220\n\nnodeAction\030\004 \001(\0162\034" +
      ".hadoop.yarn.NodeActionProto\022<\n\025containe" +
      "rs_to_cleanup\030\005 \003(\0132\035.hadoop.yarn.Contai" +
      "nerIdProto\022@\n\027applications_to_cleanup\030\006 " +
      "\003(\0132\037.hadoop.yarn.ApplicationIdProto\022\035\n\025" +
      "nextHeartBeatInterval\030\007 \001(\003\022\033\n\023diagnosti" +
      "cs_message\030\010 \001(\t\022G\n containers_to_be_rem",
      "oved_from_nm\030\t \003(\0132\035.hadoop.yarn.Contain" +
      "erIdProto\022O\n\033system_credentials_for_apps" +
      "\030\n \003(\0132*.hadoop.yarn.SystemCredentialsFo" +
      "rAppsProto\022(\n\031areNodeLabelsAcceptedByRM\030" +
      "\013 \001(\010:\005false\022;\n\026containers_to_decrease\030\014" +
      " \003(\0132\033.hadoop.yarn.ContainerProto\022F\n\024con" +
      "tainers_to_signal\030\r \003(\0132(.hadoop.yarn.Si" +
      "gnalContainerRequestProto\022,\n\010resource\030\016 " +
      "\001(\0132\032.hadoop.yarn.ResourceProto\022H\n\027conta" +
      "iner_queuing_limit\030\017 \001(\0132\'.hadoop.yarn.C",
      "ontainerQueuingLimitProto\022>\n\022app_collect" +
      "ors_map\030\020 \003(\0132\".hadoop.yarn.AppCollector" +
      "sMapProto\"Y\n\032ContainerQueuingLimitProto\022" +
      "\030\n\020max_queue_length\030\001 \001(\005\022!\n\031max_queue_w" +
      "ait_time_in_ms\030\002 \001(\005\"j\n\035SystemCredential" +
      "sForAppsProto\022.\n\005appId\030\001 \001(\0132\037.hadoop.ya" +
      "rn.ApplicationIdProto\022\031\n\021credentialsForA" +
      "pp\030\002 \001(\014\"a\n\025AppCollectorsMapProto\022.\n\005app" +
      "Id\030\001 \001(\0132\037.hadoop.yarn.ApplicationIdProt" +
      "o\022\030\n\020appCollectorAddr\030\002 \001(\t\"`\n\"ReportNew",
      "CollectorInfoRequestProto\022:\n\016app_collect" +
      "ors\030\001 \003(\0132\".hadoop.yarn.AppCollectorsMap" +
      "Proto\"%\n#ReportNewCollectorInfoResponseP" +
      "roto\"Y\n\'GetTimelineCollectorContextReque" +
      "stProto\022.\n\005appId\030\001 \001(\0132\037.hadoop.yarn.App" +
      "licationIdProto\"y\n(GetTimelineCollectorC" +
      "ontextResponseProto\022\017\n\007user_id\030\001 \001(\t\022\021\n\t" +
      "flow_name\030\002 \001(\t\022\024\n\014flow_version\030\003 \001(\t\022\023\n" +
      "\013flow_run_id\030\004 \001(\003\"\321\002\n\026NMContainerStatus" +
      "Proto\0223\n\014container_id\030\001 \001(\0132\035.hadoop.yar",
      "n.ContainerIdProto\0229\n\017container_state\030\002 " +
      "\001(\0162 .hadoop.yarn.ContainerStateProto\022,\n" +
      "\010resource\030\003 \001(\0132\032.hadoop.yarn.ResourcePr" +
      "oto\022,\n\010priority\030\004 \001(\0132\032.hadoop.yarn.Prio" +
      "rityProto\022\030\n\013diagnostics\030\005 \001(\t:\003N/A\022\035\n\025c" +
      "ontainer_exit_status\030\006 \001(\005\022\025\n\rcreation_t" +
      "ime\030\007 \001(\003\022\033\n\023nodeLabelExpression\030\010 \001(\t\"G" +
      "\n\035SCMUploaderNotifyRequestProto\022\024\n\014resou" +
      "rce_key\030\001 \001(\t\022\020\n\010filename\030\002 \001(\t\"2\n\036SCMUp" +
      "loaderNotifyResponseProto\022\020\n\010accepted\030\001 ",
      "\001(\010\"8\n SCMUploaderCanUploadRequestProto\022" +
      "\024\n\014resource_key\030\001 \001(\t\"7\n!SCMUploaderCanU" +
      "ploadResponseProto\022\022\n\nuploadable\030\001 \001(\010BC" +
      "\n\034org.apache.hadoop.yarn.protoB\035YarnServ" +
      "erCommonServiceProtos\210\001\001\240\001\001"
    };
    com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner assigner =
      new com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner() {
        public com.google.protobuf.ExtensionRegistry assignDescriptors(
            com.google.protobuf.Descriptors.FileDescriptor root) {
          descriptor = root;
          internal_static_hadoop_yarn_DistSchedRegisterResponseProto_descriptor =
            getDescriptor().getMessageTypes().get(0);
          internal_static_hadoop_yarn_DistSchedRegisterResponseProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_DistSchedRegisterResponseProto_descriptor,
              new java.lang.String[] { "RegisterResponse", "MaxAllocCapability", "MinAllocCapability", "IncrAllocCapability", "ContainerTokenExpiryInterval", "ContainerIdStart", "NodesForScheduling", });
          internal_static_hadoop_yarn_DistSchedAllocateResponseProto_descriptor =
            getDescriptor().getMessageTypes().get(1);
          internal_static_hadoop_yarn_DistSchedAllocateResponseProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_DistSchedAllocateResponseProto_descriptor,
              new java.lang.String[] { "AllocateResponse", "NodesForScheduling", });
          internal_static_hadoop_yarn_DistSchedAllocateRequestProto_descriptor =
            getDescriptor().getMessageTypes().get(2);
          internal_static_hadoop_yarn_DistSchedAllocateRequestProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_DistSchedAllocateRequestProto_descriptor,
              new java.lang.String[] { "AllocateRequest", "AllocatedContainers", });
          internal_static_hadoop_yarn_NodeLabelsProto_descriptor =
            getDescriptor().getMessageTypes().get(3);
          internal_static_hadoop_yarn_NodeLabelsProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_NodeLabelsProto_descriptor,
              new java.lang.String[] { "NodeLabels", });
          internal_static_hadoop_yarn_RegisterNodeManagerRequestProto_descriptor =
            getDescriptor().getMessageTypes().get(4);
          internal_static_hadoop_yarn_RegisterNodeManagerRequestProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_RegisterNodeManagerRequestProto_descriptor,
              new java.lang.String[] { "NodeId", "HttpPort", "Resource", "NmVersion", "ContainerStatuses", "RunningApplications", "NodeLabels", });
          internal_static_hadoop_yarn_RegisterNodeManagerResponseProto_descriptor =
            getDescriptor().getMessageTypes().get(5);
          internal_static_hadoop_yarn_RegisterNodeManagerResponseProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_RegisterNodeManagerResponseProto_descriptor,
              new java.lang.String[] { "ContainerTokenMasterKey", "NmTokenMasterKey", "NodeAction", "RmIdentifier", "DiagnosticsMessage", "RmVersion", "AreNodeLabelsAcceptedByRM", "Resource", });
          internal_static_hadoop_yarn_UnRegisterNodeManagerRequestProto_descriptor =
            getDescriptor().getMessageTypes().get(6);
          internal_static_hadoop_yarn_UnRegisterNodeManagerRequestProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_UnRegisterNodeManagerRequestProto_descriptor,
              new java.lang.String[] { "NodeId", });
          internal_static_hadoop_yarn_UnRegisterNodeManagerResponseProto_descriptor =
            getDescriptor().getMessageTypes().get(7);
          internal_static_hadoop_yarn_UnRegisterNodeManagerResponseProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_UnRegisterNodeManagerResponseProto_descriptor,
              new java.lang.String[] { });
          internal_static_hadoop_yarn_NodeHeartbeatRequestProto_descriptor =
            getDescriptor().getMessageTypes().get(8);
          internal_static_hadoop_yarn_NodeHeartbeatRequestProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_NodeHeartbeatRequestProto_descriptor,
              new java.lang.String[] { "NodeStatus", "LastKnownContainerTokenMasterKey", "LastKnownNmTokenMasterKey", "NodeLabels", "LogAggregationReportsForApps", "RegisteredCollectors", });
          internal_static_hadoop_yarn_LogAggregationReportProto_descriptor =
            getDescriptor().getMessageTypes().get(9);
          internal_static_hadoop_yarn_LogAggregationReportProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_LogAggregationReportProto_descriptor,
              new java.lang.String[] { "ApplicationId", "LogAggregationStatus", "Diagnostics", });
          internal_static_hadoop_yarn_NodeHeartbeatResponseProto_descriptor =
            getDescriptor().getMessageTypes().get(10);
          internal_static_hadoop_yarn_NodeHeartbeatResponseProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_NodeHeartbeatResponseProto_descriptor,
              new java.lang.String[] { "ResponseId", "ContainerTokenMasterKey", "NmTokenMasterKey", "NodeAction", "ContainersToCleanup", "ApplicationsToCleanup", "NextHeartBeatInterval", "DiagnosticsMessage", "ContainersToBeRemovedFromNm", "SystemCredentialsForApps", "AreNodeLabelsAcceptedByRM", "ContainersToDecrease", "ContainersToSignal", "Resource", "ContainerQueuingLimit", "AppCollectorsMap", });
          internal_static_hadoop_yarn_ContainerQueuingLimitProto_descriptor =
            getDescriptor().getMessageTypes().get(11);
          internal_static_hadoop_yarn_ContainerQueuingLimitProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ContainerQueuingLimitProto_descriptor,
              new java.lang.String[] { "MaxQueueLength", "MaxQueueWaitTimeInMs", });
          internal_static_hadoop_yarn_SystemCredentialsForAppsProto_descriptor =
            getDescriptor().getMessageTypes().get(12);
          internal_static_hadoop_yarn_SystemCredentialsForAppsProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_SystemCredentialsForAppsProto_descriptor,
              new java.lang.String[] { "AppId", "CredentialsForApp", });
          internal_static_hadoop_yarn_AppCollectorsMapProto_descriptor =
            getDescriptor().getMessageTypes().get(13);
          internal_static_hadoop_yarn_AppCollectorsMapProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_AppCollectorsMapProto_descriptor,
              new java.lang.String[] { "AppId", "AppCollectorAddr", });
          internal_static_hadoop_yarn_ReportNewCollectorInfoRequestProto_descriptor =
            getDescriptor().getMessageTypes().get(14);
          internal_static_hadoop_yarn_ReportNewCollectorInfoRequestProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ReportNewCollectorInfoRequestProto_descriptor,
              new java.lang.String[] { "AppCollectors", });
          internal_static_hadoop_yarn_ReportNewCollectorInfoResponseProto_descriptor =
            getDescriptor().getMessageTypes().get(15);
          internal_static_hadoop_yarn_ReportNewCollectorInfoResponseProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_ReportNewCollectorInfoResponseProto_descriptor,
              new java.lang.String[] { });
          internal_static_hadoop_yarn_GetTimelineCollectorContextRequestProto_descriptor =
            getDescriptor().getMessageTypes().get(16);
          internal_static_hadoop_yarn_GetTimelineCollectorContextRequestProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_GetTimelineCollectorContextRequestProto_descriptor,
              new java.lang.String[] { "AppId", });
          internal_static_hadoop_yarn_GetTimelineCollectorContextResponseProto_descriptor =
            getDescriptor().getMessageTypes().get(17);
          internal_static_hadoop_yarn_GetTimelineCollectorContextResponseProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_GetTimelineCollectorContextResponseProto_descriptor,
              new java.lang.String[] { "UserId", "FlowName", "FlowVersion", "FlowRunId", });
          internal_static_hadoop_yarn_NMContainerStatusProto_descriptor =
            getDescriptor().getMessageTypes().get(18);
          internal_static_hadoop_yarn_NMContainerStatusProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_NMContainerStatusProto_descriptor,
              new java.lang.String[] { "ContainerId", "ContainerState", "Resource", "Priority", "Diagnostics", "ContainerExitStatus", "CreationTime", "NodeLabelExpression", });
          internal_static_hadoop_yarn_SCMUploaderNotifyRequestProto_descriptor =
            getDescriptor().getMessageTypes().get(19);
          internal_static_hadoop_yarn_SCMUploaderNotifyRequestProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_SCMUploaderNotifyRequestProto_descriptor,
              new java.lang.String[] { "ResourceKey", "Filename", });
          internal_static_hadoop_yarn_SCMUploaderNotifyResponseProto_descriptor =
            getDescriptor().getMessageTypes().get(20);
          internal_static_hadoop_yarn_SCMUploaderNotifyResponseProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_SCMUploaderNotifyResponseProto_descriptor,
              new java.lang.String[] { "Accepted", });
          internal_static_hadoop_yarn_SCMUploaderCanUploadRequestProto_descriptor =
            getDescriptor().getMessageTypes().get(21);
          internal_static_hadoop_yarn_SCMUploaderCanUploadRequestProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_SCMUploaderCanUploadRequestProto_descriptor,
              new java.lang.String[] { "ResourceKey", });
          internal_static_hadoop_yarn_SCMUploaderCanUploadResponseProto_descriptor =
            getDescriptor().getMessageTypes().get(22);
          internal_static_hadoop_yarn_SCMUploaderCanUploadResponseProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hadoop_yarn_SCMUploaderCanUploadResponseProto_descriptor,
              new java.lang.String[] { "Uploadable", });
          return null;
        }
      };
    com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new com.google.protobuf.Descriptors.FileDescriptor[] {
          org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor(),
          org.apache.hadoop.yarn.proto.YarnServerCommonProtos.getDescriptor(),
          org.apache.hadoop.yarn.proto.YarnServiceProtos.getDescriptor(),
        }, assigner);
  }

  // @@protoc_insertion_point(outer_class_scope)
}
